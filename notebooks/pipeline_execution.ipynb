{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "767382dd",
   "metadata": {},
   "source": [
    "# Credit Risk Modeling Pipeline Execution\n",
    "\n",
    "This notebook executes the complete credit risk modeling pipeline based on the main.py script. It demonstrates the entire end-to-end process from data loading to model stacking and prediction generation for credit risk assessment.\n",
    "\n",
    "## Project Objective\n",
    "The goal is to predict the probability of loan default for credit applicants using advanced machine learning techniques. This is a binary classification problem where we predict whether a customer will have payment difficulties (TARGET = 1) or not (TARGET = 0).\n",
    "\n",
    "## Dataset Information\n",
    "- **Source**: Home Credit Default Risk competition dataset\n",
    "- **Training Data**: Historical loan applications with known outcomes\n",
    "- **Test Data**: New applications requiring default probability predictions\n",
    "- **Features**: Demographic, financial, and historical credit information\n",
    "\n",
    "## Pipeline Overview:\n",
    "\n",
    "### 1. **Data Loading & Preprocessing** \n",
    "- Load raw datasets (application_train.csv, application_test.csv)\n",
    "- Merge with additional data sources (bureau, previous applications, etc.)\n",
    "- Basic data quality checks and initial preprocessing\n",
    "\n",
    "### 2. **Feature Engineering** \n",
    "- Automatic creation of new predictive features\n",
    "- Aggregation of external data sources\n",
    "- Ratio calculations and interaction features\n",
    "- Time-based feature engineering\n",
    "\n",
    "### 3. **Data Quality & Encoding**\n",
    "- Handle missing values using domain knowledge\n",
    "- Target encoding for categorical variables\n",
    "- Data validation and quality checks\n",
    "\n",
    "### 4. **Feature Selection**\n",
    "- SHAP-based feature importance (default)\n",
    "- Variance-based selection (fast alternative)\n",
    "- Correlation filtering to remove redundant features\n",
    "- Select top 50 most predictive features\n",
    "\n",
    "### 5. **Three-Level Stacking Approach**\n",
    "- **L1 (Base Models)**: XGBoost, LightGBM, CatBoost - diverse algorithms for robust predictions\n",
    "- **L2 (Meta Models)**: ExtraTrees, Logistic Regression - combine L1 predictions intelligently\n",
    "- **L3 (Final Ensemble)**: ExtraTrees on L2 outputs + raw features for final prediction\n",
    "\n",
    "### 6. **Model Evaluation & Output**\n",
    "- Cross-validation performance metrics (AUC-ROC)\n",
    "- Out-of-fold predictions for model validation\n",
    "- Final submission file generation\n",
    "\n",
    "## Key Features:\n",
    "- **Modular Design**: Each step can be run independently\n",
    "- **Configurable**: Easy parameter adjustment for different experiments\n",
    "- **Reproducible**: Fixed random seeds for consistent results\n",
    "- **Scalable**: Debug mode for quick testing, full mode for production\n",
    "- **Comprehensive**: Saves all intermediate results and trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd7a1b6",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries and Modules\n",
    "\n",
    "### Library Overview:\n",
    "This section imports all necessary dependencies for the credit risk modeling pipeline.\n",
    "\n",
    "**Core Data Science Libraries:**\n",
    "- `numpy` & `pandas`: Data manipulation and numerical operations\n",
    "- `sklearn`: Machine learning utilities (VarianceThreshold for feature selection)\n",
    "- `pickle` & `json`: Model serialization and configuration storage\n",
    "\n",
    "**Custom Project Modules:**\n",
    "- `src.utils.utils`: Utility functions (random seed, timer, progress tracking)\n",
    "- `src.data_pipeline.processor`: Main data processing orchestrator\n",
    "- `src.processing.*`: Data validation, encoding, and imputation modules\n",
    "- `src.modeling.*`: Feature selection and stacking model implementations\n",
    "\n",
    "### Prerequisites:\n",
    "Ensure all custom modules are properly installed and the project structure is maintained. The pipeline depends on these modules being in the correct relative paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db5ca314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Thêm đường dẫn gốc của project vào sys.path để import được module src\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bab80a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# Import custom modules\n",
    "from src.utils.utils import set_seed, timer, create_progress_bar\n",
    "from src.data_pipeline.processor import DataProcessor\n",
    "from src.processing.data_validator import validate_data\n",
    "from src.processing.encoding import TargetEncoder\n",
    "from src.processing.imputation import SimpleImputer\n",
    "from src.modeling.feature_selector import FeatureSelector\n",
    "from src.modeling.stacking import run_l1_stacking, run_l2_stacking, run_l3_stacking, print_all_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20051b53",
   "metadata": {},
   "source": [
    "## 2. Configuration and Setup\n",
    "\n",
    "### Pipeline Configuration Parameters:\n",
    "\n",
    "**Execution Modes:**\n",
    "- `DEBUG = False`: \n",
    "  - **False**: Full dataset processing (production mode)\n",
    "  - **True**: Limited to 10,000 samples for quick testing and debugging\n",
    "\n",
    "**Reproducibility:**\n",
    "- `SEED = 42`: Fixed random seed ensures consistent results across runs\n",
    "\n",
    "**Data Handling:**\n",
    "- `FORCE_RELOAD = True`: Forces fresh data loading, ignoring cached files\n",
    "- `SKIP_SHAP = False`: \n",
    "  - **False**: Use SHAP for intelligent feature selection (slower, better quality)\n",
    "  - **True**: Use variance-based selection (faster, good for debugging)\n",
    "\n",
    "**Model Training:**\n",
    "- `USE_ENSEMBLE = False`: Reserved for future ensemble extensions\n",
    "- `TUNE_HYPERPARAMS = True`: \n",
    "  - **True**: Perform hyperparameter optimization (recommended for final models)\n",
    "  - **False**: Use default parameters (faster for testing)\n",
    "\n",
    "### Recommendations:\n",
    "- For **development/testing**: Set DEBUG=True, SKIP_SHAP=True, TUNE_HYPERPARAMS=False\n",
    "- For **production runs**: Set DEBUG=False, SKIP_SHAP=False, TUNE_HYPERPARAMS=True\n",
    "- For **quick experiments**: Set DEBUG=True, TUNE_HYPERPARAMS=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaddc2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline Configuration:\n",
      "- Seed: 42\n",
      "- Debug mode: False\n",
      "- Force reload: True\n",
      "- Skip SHAP: False\n",
      "- Use Ensemble: False\n",
      "- Tune Hyperparams: True\n",
      "\n",
      "FULL MODE: Running with complete dataset!\n"
     ]
    }
   ],
   "source": [
    "# Pipeline configuration\n",
    "DEBUG = False  # Set to True for quick testing with subset of data\n",
    "SEED = 42\n",
    "FORCE_RELOAD = True\n",
    "SKIP_SHAP = False  # Set to True to use variance-based feature selection instead of SHAP\n",
    "USE_ENSEMBLE = False\n",
    "TUNE_HYPERPARAMS = True\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "set_seed(SEED)\n",
    "\n",
    "print(f\"Pipeline Configuration:\")\n",
    "print(f\"- Seed: {SEED}\")\n",
    "print(f\"- Debug mode: {DEBUG}\")\n",
    "print(f\"- Force reload: {FORCE_RELOAD}\")\n",
    "print(f\"- Skip SHAP: {SKIP_SHAP}\")\n",
    "print(f\"- Use Ensemble: {USE_ENSEMBLE}\")\n",
    "print(f\"- Tune Hyperparams: {TUNE_HYPERPARAMS}\")\n",
    "\n",
    "if DEBUG:\n",
    "    print(\"\\nDEMO MODE: Running with first 10,000 rows only!\")\n",
    "else:\n",
    "    print(\"\\nFULL MODE: Running with complete dataset!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad360de9",
   "metadata": {},
   "source": [
    "## 2.1. Temporary Output Configuration\n",
    "\n",
    "### Safe Testing Environment:\n",
    "To run the pipeline without affecting existing results, we'll use a temporary output directory.\n",
    "\n",
    "**Benefits:**\n",
    "- **Safe Testing**: Original results remain untouched\n",
    "- **Clean Separation**: Clear distinction between test and production runs\n",
    "- **Easy Cleanup**: Simple to remove test results when done\n",
    "- **Comparison Ready**: Can compare new results with existing ones\n",
    "\n",
    "**Configuration:**\n",
    "- All output files will be saved to `temp_results/` directory\n",
    "- Original file structure is preserved within the temporary directory\n",
    "- Easy to copy results back to main directories if desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76788f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Using temporary output directories under 'temp_results/'\n",
      "✓ Original results will NOT be affected\n",
      "Output directories configured:\n",
      "- Interim data: temp_results/data/interim\n",
      "- Processed data: temp_results/data/processed\n",
      "- L1 models: temp_results/models/l1_stacking\n",
      "- L2 models: temp_results/models/l2_stacking\n",
      "- L3 models: temp_results/models/l3_stacking\n"
     ]
    }
   ],
   "source": [
    "# Configure temporary output directories\n",
    "USE_TEMP_OUTPUT = True  # Set to False to use original directories\n",
    "\n",
    "if USE_TEMP_OUTPUT:\n",
    "    # Create temporary directory structure\n",
    "    TEMP_BASE = 'temp_results'\n",
    "    DATA_INTERIM_DIR = f'{TEMP_BASE}/data/interim'\n",
    "    DATA_PROCESSED_DIR = f'{TEMP_BASE}/data/processed'\n",
    "    MODELS_L1_DIR = f'{TEMP_BASE}/models/l1_stacking'\n",
    "    MODELS_L2_DIR = f'{TEMP_BASE}/models/l2_stacking'\n",
    "    MODELS_L3_DIR = f'{TEMP_BASE}/models/l3_stacking'\n",
    "    \n",
    "    # Create all temporary directories\n",
    "    temp_dirs = [DATA_INTERIM_DIR, DATA_PROCESSED_DIR, MODELS_L1_DIR, MODELS_L2_DIR, MODELS_L3_DIR]\n",
    "    for temp_dir in temp_dirs:\n",
    "        os.makedirs(temp_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"✓ Using temporary output directories under '{TEMP_BASE}/'\")\n",
    "    print(f\"✓ Original results will NOT be affected\")\n",
    "    \n",
    "else:\n",
    "    # Use original directories\n",
    "    DATA_INTERIM_DIR = 'data/interim'\n",
    "    DATA_PROCESSED_DIR = 'data/processed'\n",
    "    MODELS_L1_DIR = 'models/l1_stacking'\n",
    "    MODELS_L2_DIR = 'models/l2_stacking'\n",
    "    MODELS_L3_DIR = 'models/l3_stacking'\n",
    "    \n",
    "    print(f\"⚠️  Using ORIGINAL output directories - existing results may be overwritten!\")\n",
    "\n",
    "print(f\"Output directories configured:\")\n",
    "print(f\"- Interim data: {DATA_INTERIM_DIR}\")\n",
    "print(f\"- Processed data: {DATA_PROCESSED_DIR}\")\n",
    "print(f\"- L1 models: {MODELS_L1_DIR}\")\n",
    "print(f\"- L2 models: {MODELS_L2_DIR}\")\n",
    "print(f\"- L3 models: {MODELS_L3_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad946fff",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Initial Processing\n",
    "\n",
    "### Data Loading Strategy:\n",
    "The `DataProcessor` class handles the complex task of loading and merging multiple data sources:\n",
    "\n",
    "**Primary Datasets:**\n",
    "- `application_train.csv`: Training data with known TARGET values\n",
    "- `application_test.csv`: Test data requiring predictions\n",
    "\n",
    "**External Data Sources (automatically merged):**\n",
    "- `bureau.csv` & `bureau_balance.csv`: Credit bureau information\n",
    "- `previous_application.csv`: Historical loan applications  \n",
    "- `POS_CASH_balance.csv`: Point-of-sale and cash loan balances\n",
    "- `installments_payments.csv`: Payment history data\n",
    "- `credit_card_balance.csv`: Credit card usage patterns\n",
    "\n",
    "### Data Quality Checks:\n",
    "The loading process includes several validation steps:\n",
    "- Automatic schema validation\n",
    "- Missing value assessment\n",
    "- Data type consistency checks\n",
    "- Merge integrity verification\n",
    "\n",
    "### Expected Outcomes:\n",
    "- Successfully merged dataset combining all data sources\n",
    "- Clear separation of training (with TARGET) and test (without TARGET) rows\n",
    "- Comprehensive feature set ready for engineering phase\n",
    "\n",
    "**Note**: The merge process significantly increases the feature count as it aggregates information from multiple sources for each applicant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89933670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed to project root: c:\\Users\\HLC\\OneDrive\\Duong's Documents\\Projects\\Credit Risk Modeling\\pd_modeling_project\n",
      "\n",
      "============================================================\n",
      "STARTING CREDIT RISK MODELING PIPELINE\n",
      "============================================================\n",
      "Loading data...\n",
      "Before merge: (356255, 122)\n",
      "Số dòng test trước merge: 48744\n",
      "Số dòng test sau merge bureau: 48744\n",
      "Số dòng test sau merge prev: 48744\n",
      "Lưu cache merge vào data/interim/cache_merged.feather...\n",
      "Số dòng test sau merge: 48744\n",
      "Dataset shape: (356255, 134)\n",
      "Number of test rows after merge: 48744\n",
      "\n",
      "Dataset Info:\n",
      "- Total rows: 356,255\n",
      "- Total columns: 134\n",
      "- Training rows: 307,511\n",
      "- Test rows: 48,744\n",
      "Data Loading - done in 79s\n"
     ]
    }
   ],
   "source": [
    "# Change to project root if we're in notebooks folder\n",
    "if os.getcwd().endswith('notebooks'):\n",
    "    os.chdir('..')\n",
    "    print(\"Changed to project root:\", os.getcwd())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STARTING CREDIT RISK MODELING PIPELINE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "with timer(\"Data Loading\"):\n",
    "    print('Loading data...')\n",
    "    processor = DataProcessor(debug=DEBUG, seed=SEED, force_reload=FORCE_RELOAD)\n",
    "    df = processor.load_data()\n",
    "    print(f'Dataset shape: {df.shape}')\n",
    "    print('Number of test rows after merge:', df['TARGET'].isnull().sum())\n",
    "    \n",
    "    # Display basic dataset information\n",
    "    print(f\"\\nDataset Info:\")\n",
    "    print(f\"- Total rows: {len(df):,}\")\n",
    "    print(f\"- Total columns: {len(df.columns):,}\")\n",
    "    print(f\"- Training rows: {df['TARGET'].notnull().sum():,}\")\n",
    "    print(f\"- Test rows: {df['TARGET'].isnull().sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bfbb5d",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering\n",
    "\n",
    "### Automated Feature Engineering Process:\n",
    "This step creates new predictive features through sophisticated transformations of the raw data.\n",
    "\n",
    "**Feature Creation Techniques:**\n",
    "\n",
    "1. **Aggregation Features:**\n",
    "   - Statistical summaries (mean, median, std, min, max) of external data\n",
    "   - Count-based features (number of previous loans, credit inquiries)\n",
    "   - Trend analysis (recent vs. historical behavior patterns)\n",
    "\n",
    "2. **Ratio and Interaction Features:**\n",
    "   - Income-to-credit ratios\n",
    "   - Debt-to-income calculations  \n",
    "   - Payment behavior ratios\n",
    "   - Cross-variable interactions\n",
    "\n",
    "3. **Time-Based Features:**\n",
    "   - Days since last application\n",
    "   - Loan duration patterns\n",
    "   - Seasonal payment behaviors\n",
    "   - Application timing features\n",
    "\n",
    "4. **Risk Indicators:**\n",
    "   - Default probability proxies\n",
    "   - Credit utilization patterns\n",
    "   - Payment delay frequencies\n",
    "   - Financial stress indicators\n",
    "\n",
    "### Business Logic Integration:\n",
    "The feature engineering incorporates domain knowledge about credit risk:\n",
    "- **Income Stability**: Regular vs. irregular income patterns\n",
    "- **Credit History**: Length and quality of credit relationships\n",
    "- **Payment Behavior**: Consistency and timeliness of payments\n",
    "- **Financial Burden**: Debt levels relative to income capacity\n",
    "\n",
    "### Expected Impact:\n",
    "Feature engineering typically increases the dataset width significantly (often 2-3x the original feature count) while creating more predictive variables that capture complex relationships in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16d70beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting auto feature engineering...\n",
      "Bắt đầu feature engineering...\n",
      "Lưu cache feature engineering vào data/interim/cache_fe.feather...\n",
      "Dataset shape after feature engineering: (356255, 161)\n",
      "Number of test rows after feature engineering: 48744\n",
      "\n",
      "Feature Engineering Results:\n",
      "- New dataset shape: (356255, 161)\n",
      "Before merge: (356255, 122)\n",
      "Số dòng test trước merge: 48744\n",
      "Số dòng test sau merge bureau: 48744\n",
      "Số dòng test sau merge prev: 48744\n",
      "Lưu cache merge vào data/interim/cache_merged.feather...\n",
      "Số dòng test sau merge: 48744\n",
      "- Features added: 27\n",
      "Feature Engineering - done in 82s\n"
     ]
    }
   ],
   "source": [
    "with timer(\"Feature Engineering\"):\n",
    "    print('Starting auto feature engineering...')\n",
    "    df = processor.auto_feature_engineering(df)\n",
    "    print(f'Dataset shape after feature engineering: {df.shape}')\n",
    "    print('Number of test rows after feature engineering:', df['TARGET'].isnull().sum())\n",
    "    \n",
    "    print(f\"\\nFeature Engineering Results:\")\n",
    "    print(f\"- New dataset shape: {df.shape}\")\n",
    "    print(f\"- Features added: {df.shape[1] - processor.load_data().shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303ed617",
   "metadata": {},
   "source": [
    "## 5. Missing Value Handling\n",
    "\n",
    "### Missing Value Strategy:\n",
    "Credit data often contains missing values due to various reasons. Our approach handles them systematically:\n",
    "\n",
    "**Missing Value Categories:**\n",
    "\n",
    "1. **Informative Missingness:**\n",
    "   - Missing values that indicate \"not applicable\" (e.g., no previous loans)\n",
    "   - These are often replaced with meaningful defaults (0, -1, or \"None\")\n",
    "\n",
    "2. **Random Missingness:**\n",
    "   - Missing values due to data collection issues\n",
    "   - Handled through imputation strategies\n",
    "\n",
    "3. **Systematic Missingness:**\n",
    "   - Missing values following patterns (e.g., certain data not collected for specific loan types)\n",
    "   - Require domain-specific handling\n",
    "\n",
    "**Handling Techniques:**\n",
    "- **Numerical Features**: Median imputation, forward/backward fill for time series\n",
    "- **Categorical Features**: Mode imputation or \"Unknown\" category creation  \n",
    "- **Boolean Features**: Conservative assumptions (e.g., False for unknown flags)\n",
    "- **Special Cases**: Domain knowledge-based replacements\n",
    "\n",
    "### Business Considerations:\n",
    "- **Conservative Approach**: When uncertain, assume higher risk scenario\n",
    "- **Feature Preservation**: Maintain feature distribution patterns\n",
    "- **Regulatory Compliance**: Ensure missing value handling doesn't introduce bias\n",
    "\n",
    "**Post-Processing**: Track missing value patterns as they may be predictive features themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b4320d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling missing values...\n",
      "Number of test rows after handling missing values: 48744\n",
      "\n",
      "Missing values summary:\n",
      "- Columns with missing values: 16\n",
      "- Total missing values: 5392569\n",
      "Missing Value Handling - done in 1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HLC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\HLC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\HLC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\HLC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\HLC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\HLC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\HLC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\HLC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\HLC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\HLC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\HLC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\HLC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\HLC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\HLC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\HLC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
     ]
    }
   ],
   "source": [
    "with timer(\"Missing Value Handling\"):\n",
    "    print('Handling missing values...')\n",
    "    df = processor.handle_missing_values(df)\n",
    "    print('Number of test rows after handling missing values:', df['TARGET'].isnull().sum())\n",
    "    \n",
    "    # Check missing values\n",
    "    missing_counts = df.isnull().sum()\n",
    "    print(f\"\\nMissing values summary:\")\n",
    "    print(f\"- Columns with missing values: {(missing_counts > 0).sum()}\")\n",
    "    print(f\"- Total missing values: {missing_counts.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a978caa",
   "metadata": {},
   "source": [
    "## 6. Data Encoding\n",
    "\n",
    "### Target Encoding for Categorical Variables:\n",
    "Target encoding is particularly effective for credit risk modeling as it captures the relationship between categorical variables and default probability.\n",
    "\n",
    "**Target Encoding Process:**\n",
    "\n",
    "1. **Category-Target Relationship:**\n",
    "   - For each category, calculate the mean TARGET value\n",
    "   - This creates a numerical representation based on historical default rates\n",
    "   - Example: If \"Engineer\" profession has 5% default rate, it gets encoded as 0.05\n",
    "\n",
    "2. **Smoothing and Regularization:**\n",
    "   - Apply smoothing to handle categories with few samples\n",
    "   - Use cross-validation to prevent overfitting\n",
    "   - Add noise to reduce variance in rare categories\n",
    "\n",
    "3. **Advantages over One-Hot Encoding:**\n",
    "   - **Dimensionality**: No explosion of features for high-cardinality categories\n",
    "   - **Information Retention**: Preserves ordinal relationships with target\n",
    "   - **Performance**: Often leads to better model performance\n",
    "\n",
    "**Categories Typically Encoded:**\n",
    "- `NAME_EDUCATION_TYPE`: Education levels and their risk profiles\n",
    "- `OCCUPATION_TYPE`: Job types and associated stability/risk\n",
    "- `NAME_FAMILY_STATUS`: Marital status impact on credit behavior  \n",
    "- `NAME_HOUSING_TYPE`: Housing situation and financial stability\n",
    "- `ORGANIZATION_TYPE`: Employer type and associated risk levels\n",
    "\n",
    "### Train/Test Split Strategy:\n",
    "- Encoding parameters are learned only from training data\n",
    "- Test data is encoded using training-derived mappings\n",
    "- This prevents data leakage and ensures realistic evaluation\n",
    "\n",
    "**Quality Assurance**: Verify that train/test distributions remain consistent after encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5ac89f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting encoding...\n",
      "Train set shape: (307511, 161)\n",
      "Test set shape: (48744, 161)\n",
      "\n",
      "Encoding Results:\n",
      "- Train encoded shape: (307511, 161)\n",
      "- Test encoded shape: (48744, 161)\n",
      "Data Encoding - done in 0s\n"
     ]
    }
   ],
   "source": [
    "with timer(\"Data Encoding\"):\n",
    "    print('Starting encoding...')\n",
    "    categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    target = 'TARGET'\n",
    "    \n",
    "    # Split into train and test sets\n",
    "    train_df = df[df[target].notnull()]\n",
    "    test_df = df[df[target].isnull()]\n",
    "    print(f'Train set shape: {train_df.shape}')\n",
    "    print(f'Test set shape: {test_df.shape}')\n",
    "    \n",
    "    # Target encoding for categorical variables\n",
    "    encoder = TargetEncoder()\n",
    "    train_encoded = encoder.fit_transform(train_df, target, categorical_cols)\n",
    "    test_encoded = encoder.transform(test_df, categorical_cols)\n",
    "    \n",
    "    print(f\"\\nEncoding Results:\")\n",
    "    print(f\"- Train encoded shape: {train_encoded.shape}\")\n",
    "    print(f\"- Test encoded shape: {test_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030d73cf",
   "metadata": {},
   "source": [
    "## 7. Save Interim Data\n",
    "\n",
    "### Data Persistence Strategy:\n",
    "Saving intermediate results serves multiple purposes in the machine learning pipeline:\n",
    "\n",
    "**Benefits of Interim Data Storage:**\n",
    "\n",
    "1. **Pipeline Resilience:**\n",
    "   - Resume processing from this checkpoint if later steps fail\n",
    "   - Skip expensive preprocessing when experimenting with models\n",
    "   - Quick data access for analysis and debugging\n",
    "\n",
    "2. **Reproducibility:**\n",
    "   - Exact same preprocessing can be replicated\n",
    "   - Enables consistent model comparisons\n",
    "   - Facilitates collaboration and code reviews\n",
    "\n",
    "3. **Data Lineage:**\n",
    "   - Track transformation history\n",
    "   - Audit trail for regulatory compliance\n",
    "   - Quality assurance checkpoints\n",
    "\n",
    "**Files Created:**\n",
    "- `data/interim/train_encoded.csv`: Training data with target encoding applied\n",
    "- `data/interim/test_encoded.csv`: Test data with same encoding transformations\n",
    "\n",
    "### Data Quality at This Stage:\n",
    "- All categorical variables converted to numerical representations\n",
    "- Target encoding preserves predictive relationships\n",
    "- Train/test split maintained with proper encoding methodology\n",
    "- Ready for feature selection and model training phases\n",
    "\n",
    "**Next Steps**: These encoded datasets will undergo feature selection to identify the most predictive variables for the final models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d83aa8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interim data saved:\n",
      "- temp_results/data/interim/train_encoded.csv\n",
      "- temp_results/data/interim/test_encoded.csv\n"
     ]
    }
   ],
   "source": [
    "# Save interim data\n",
    "os.makedirs(DATA_INTERIM_DIR, exist_ok=True)\n",
    "train_encoded.to_csv(f'{DATA_INTERIM_DIR}/train_encoded.csv', index=False)\n",
    "test_encoded.to_csv(f'{DATA_INTERIM_DIR}/test_encoded.csv', index=False)\n",
    "\n",
    "print(\"Interim data saved:\")\n",
    "print(f\"- {DATA_INTERIM_DIR}/train_encoded.csv\")\n",
    "print(f\"- {DATA_INTERIM_DIR}/test_encoded.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de43d19b",
   "metadata": {},
   "source": [
    "## 8. Feature Selection\n",
    "\n",
    "### Intelligent Feature Selection Strategy:\n",
    "With hundreds or thousands of features after engineering, selecting the most predictive ones is crucial for model performance and interpretability.\n",
    "\n",
    "**Two-Tier Selection Approach:**\n",
    "\n",
    "### Option A: SHAP-Based Selection (Default - Higher Quality)\n",
    "**SHAP (SHapley Additive exPlanations) Advantages:**\n",
    "- **Model-Agnostic**: Works with any machine learning algorithm\n",
    "- **Theoretically Grounded**: Based on cooperative game theory\n",
    "- **Feature Interactions**: Captures complex feature relationships\n",
    "- **Interpretability**: Provides explanation for feature importance\n",
    "\n",
    "**SHAP Process:**\n",
    "1. **Pre-filtering**: Variance threshold to remove low-variance features\n",
    "2. **SHAP Calculation**: Train lightweight model and compute SHAP values\n",
    "3. **Importance Ranking**: Rank features by absolute SHAP value contribution\n",
    "4. **Correlation Filtering**: Remove highly correlated features (>0.95)\n",
    "5. **Final Selection**: Top 50 features for optimal model complexity\n",
    "\n",
    "### Option B: Variance-Based Selection (Fast Alternative)\n",
    "**When to Use**: Debug mode, quick experiments, or computational constraints\n",
    "- **Speed**: Much faster than SHAP computation\n",
    "- **Simplicity**: Easy to understand and implement\n",
    "- **Baseline**: Good starting point for feature selection\n",
    "\n",
    "### Selection Parameters:\n",
    "- **Target Features**: 50 final features (optimal balance of performance vs. complexity)\n",
    "- **Sample Size**: 5,000 samples for SHAP calculation (computational efficiency)\n",
    "- **Correlation Threshold**: 0.95 (remove redundant features)\n",
    "\n",
    "### Expected Outcomes:\n",
    "- Reduced feature set with highest predictive power\n",
    "- Improved model training speed and performance  \n",
    "- Enhanced model interpretability\n",
    "- Reduced overfitting risk through dimensionality reduction\n",
    "\n",
    "**Business Value**: Selected features represent the most important factors in credit risk assessment, providing clear insights for decision-making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d954c6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (307511, 159)\n",
      "Using SHAP-based feature selection...\n",
      "[SHAP] Reducing features from 159 to 100 for SHAP...\n",
      "[SHAP] After variance selection: 100 features\n",
      "[SHAP] Starting model training for feature selection...\n",
      "[SHAP] Training XGBoost model for SHAP...\n",
      "[SHAP] Using sample size 5000...\n",
      "[SHAP] Starting SHAP values calculation on 5000 rows...\n",
      "[SHAP] SHAP values calculation completed.\n",
      "[SHAP] Calculating feature importance...\n",
      "[SHAP] Selecting top 50 features...\n",
      "[SHAP] Top 50 features selected:\n",
      "   1. [ORIG] EXT_SOURCE_2: 0.3401\n",
      "   2. [ORIG] EXT_SOURCE_3: 0.2952\n",
      "   3. [ORIG] EXT_SOURCE_1: 0.1349\n",
      "   4. [ORIG] CREDIT_TO_ANNUITY: 0.1262\n",
      "   5. [ORIG] CODE_GENDER: 0.1142\n",
      "   6. [ORIG] DAYS_EMPLOYED: 0.0905\n",
      "   7. [ORIG] CREDIT_GOODS_RATIO: 0.0900\n",
      "   8. [ORIG] NAME_EDUCATION_TYPE: 0.0885\n",
      "   9. [ORIG] PREV_NAME_CONTRACT_STATUS__lambda_: 0.0714\n",
      "  10. [ORIG] DAYS_BIRTH: 0.0669\n",
      "  11. [ORIG] AMT_GOODS_PRICE: 0.0632\n",
      "  12. [ORIG] FLAG_OWN_CAR: 0.0585\n",
      "  13. [ORIG] DAYS_ID_PUBLISH: 0.0476\n",
      "  14. [ORIG] GOODS_MINUS_CREDIT: 0.0473\n",
      "  15. [ORIG] BURO_CREDIT_ACTIVE__lambda_: 0.0436\n",
      "  16. [ORIG] AMT_ANNUITY: 0.0428\n",
      "  17. [ORIG] AMT_ANNUITY_DIV_EXTSRC3: 0.0426\n",
      "  18. [ORIG] NAME_FAMILY_STATUS: 0.0399\n",
      "  19. [OTHER] OWN_CAR_AGE: 0.0371\n",
      "  20. [ORIG] BURO_DAYS_CREDIT_mean: 0.0352\n",
      "  21. [ORIG] NAME_INCOME_TYPE: 0.0350\n",
      "  22. [ORIG] FLAG_DOCUMENT_3: 0.0340\n",
      "  23. [ORIG] FLAG_WORK_PHONE: 0.0331\n",
      "  24. [ORIG] BURO_DAYS_CREDIT_max: 0.0327\n",
      "  25. [ORIG] PREV_AMT_CREDIT_sum: 0.0315\n",
      "  26. [ORIG] DEF_30_CNT_SOCIAL_CIRCLE: 0.0273\n",
      "  27. [OTHER] REGION_RATING_CLIENT_W_CITY: 0.0269\n",
      "  28. [ORIG] DAYS_LAST_PHONE_CHANGE: 0.0268\n",
      "  29. [ORIG] ANNUITY_INCOME_RATIO: 0.0263\n",
      "  30. [ORIG] AMT_REQ_CREDIT_BUREAU_QRT: 0.0259\n",
      "  31. [ORIG] BURO_AMT_CREDIT_SUM_max: 0.0247\n",
      "  32. [ORIG] PREV_AMT_CREDIT_max: 0.0238\n",
      "  33. [ORIG] ORGANIZATION_TYPE: 0.0210\n",
      "  34. [ORIG] PREV_AMT_CREDIT_mean: 0.0190\n",
      "  35. [ORIG] BURO_AMT_CREDIT_SUM_sum: 0.0187\n",
      "  36. [OTHER] OCCUPATION_TYPE: 0.0178\n",
      "  37. [ORIG] AMT_CREDIT: 0.0174\n",
      "  38. [OTHER] AGE_YEARS: 0.0156\n",
      "  39. [ORIG] BURO_AMT_CREDIT_SUM_mean: 0.0153\n",
      "  40. [ORIG] CREDIT_INCOME_RATIO: 0.0132\n",
      "  41. [ORIG] NAME_CONTRACT_TYPE: 0.0129\n",
      "  42. [OTHER] REG_CITY_NOT_LIVE_CITY: 0.0125\n",
      "  43. [ORIG] DAYS_REGISTRATION: 0.0117\n",
      "  44. [OTHER] WALLSMATERIAL_MODE: 0.0109\n",
      "  45. [OTHER] WEEKDAY_APPR_PROCESS_START: 0.0093\n",
      "  46. [ORIG] BURO_DAYS_CREDIT_min: 0.0091\n",
      "  47. [OTHER] LIVINGAREA_MEDI: 0.0088\n",
      "  48. [ORIG] DEF_60_CNT_SOCIAL_CIRCLE: 0.0077\n",
      "  49. [OTHER] REGION_CAT: 0.0069\n",
      "  50. [OTHER] ENTRANCES_MODE: 0.0067\n",
      "[SHAP] Summary: 40 original, 10 other\n",
      "[SHAP] Filtering features based on correlation...\n",
      "[SHAP] Removing 2 features with high correlation: ['AMT_CREDIT', 'AGE_YEARS']...\n",
      "[SHAP] Finally selected 48 features\n",
      "Feature Selection - done in 7s\n",
      "\n",
      "Selected Features (48):\n",
      "  1. EXT_SOURCE_2\n",
      "  2. EXT_SOURCE_3\n",
      "  3. EXT_SOURCE_1\n",
      "  4. CREDIT_TO_ANNUITY\n",
      "  5. CODE_GENDER\n",
      "  6. DAYS_EMPLOYED\n",
      "  7. CREDIT_GOODS_RATIO\n",
      "  8. NAME_EDUCATION_TYPE\n",
      "  9. PREV_NAME_CONTRACT_STATUS__lambda_\n",
      "  10. DAYS_BIRTH\n",
      "  ... and 38 more features\n"
     ]
    }
   ],
   "source": [
    "with timer(\"Feature Selection\"):\n",
    "    X_train = train_encoded.drop(columns=[target, 'SK_ID_CURR'])\n",
    "    y_train = train_encoded[target]\n",
    "    print(f'X_train shape: {X_train.shape}')\n",
    "    \n",
    "    if SKIP_SHAP:\n",
    "        print('Using variance-based feature selection...')\n",
    "        # Use variance-based selection for faster processing\n",
    "        selector_var = VarianceThreshold()\n",
    "        selector_var.fit(X_train.fillna(0))\n",
    "        variances = selector_var.variances_\n",
    "        top_idx = np.argsort(variances)[-50:]  # Select top 50 features\n",
    "        selected_features = X_train.columns[top_idx]\n",
    "        print(f'Selected {len(selected_features)} features based on variance')\n",
    "        \n",
    "    else:\n",
    "        print('Using SHAP-based feature selection...')\n",
    "        \n",
    "        # Reduce number of features for SHAP computation\n",
    "        if X_train.shape[1] > 100:\n",
    "            print(f'[SHAP] Reducing features from {X_train.shape[1]} to 100 for SHAP...')\n",
    "            selector_var = VarianceThreshold()\n",
    "            selector_var.fit(X_train.fillna(0))\n",
    "            variances = selector_var.variances_\n",
    "            top_idx = np.argsort(variances)[-100:]\n",
    "            X_train = X_train.iloc[:, top_idx]\n",
    "            test_encoded = test_encoded[X_train.columns]\n",
    "            print(f'[SHAP] After variance selection: {X_train.shape[1]} features')\n",
    "        \n",
    "        # SHAP feature selection\n",
    "        selector = FeatureSelector(\n",
    "            top_k=50,\n",
    "            seed=SEED, \n",
    "            shap_sample=5000,\n",
    "            full_shap=False\n",
    "        )\n",
    "        selected_features = selector.fit(X_train, y_train)\n",
    "        \n",
    "        # Additional feature filtering based on correlation\n",
    "        print('[SHAP] Filtering features based on correlation...')\n",
    "        X_selected = X_train[selected_features]\n",
    "        if not isinstance(X_selected, pd.DataFrame):\n",
    "            X_selected = pd.DataFrame(X_selected, columns=selected_features)\n",
    "        corr_matrix = X_selected.corr().abs()\n",
    "        \n",
    "        # Remove features with high correlation (>0.95)\n",
    "        upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "        to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.95)]\n",
    "        \n",
    "        if to_drop:\n",
    "            print(f'[SHAP] Removing {len(to_drop)} features with high correlation: {to_drop[:5]}...')\n",
    "            selected_features = [f for f in selected_features if f not in to_drop]\n",
    "        \n",
    "        # Limit back to 50 final features\n",
    "        if len(selected_features) > 50:\n",
    "            selected_features = selected_features[:50]\n",
    "        \n",
    "        print(f'[SHAP] Finally selected {len(selected_features)} features')\n",
    "\n",
    "print(f\"\\nSelected Features ({len(selected_features)}):\")\n",
    "for i, feature in enumerate(selected_features[:10]):\n",
    "    print(f\"  {i+1}. {feature}\")\n",
    "if len(selected_features) > 10:\n",
    "    print(f\"  ... and {len(selected_features) - 10} more features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d18574",
   "metadata": {},
   "source": [
    "## 9. Data Imputation\n",
    "\n",
    "### Final Data Preparation - Advanced Imputation:\n",
    "After feature selection, we apply sophisticated imputation techniques to handle any remaining missing values in our selected feature set.\n",
    "\n",
    "**Why Imputation After Feature Selection:**\n",
    "- **Efficiency**: Only impute the features that will actually be used\n",
    "- **Quality**: Focus computational resources on important features\n",
    "- **Consistency**: Ensure imputation strategy aligns with selected features\n",
    "\n",
    "**SimpleImputer Strategy:**\n",
    "The `SimpleImputer` class employs intelligent imputation based on feature types:\n",
    "\n",
    "1. **Numerical Features:**\n",
    "   - **Median Imputation**: Robust to outliers\n",
    "   - **Distribution Preservation**: Maintains feature distribution characteristics\n",
    "   - **Cross-Validation**: Ensures imputation doesn't introduce bias\n",
    "\n",
    "2. **Categorical Features:**\n",
    "   - **Mode Imputation**: Most frequent category\n",
    "   - **Special Categories**: \"Unknown\" for truly missing information\n",
    "   - **Frequency-Based**: Consider category frequency in imputation\n",
    "\n",
    "3. **Business Rules:**\n",
    "   - **Conservative Estimates**: When uncertain, assume higher risk scenario\n",
    "   - **Domain Knowledge**: Use credit industry best practices\n",
    "   - **Regulatory Compliance**: Ensure fairness and non-discrimination\n",
    "\n",
    "### Data Quality Assurance:\n",
    "- **Pre-Imputation**: Record missing value patterns\n",
    "- **Post-Imputation**: Validate data distributions\n",
    "- **Consistency Check**: Ensure train/test imputation alignment\n",
    "\n",
    "### Final Data Preparation:\n",
    "- **Format Consistency**: Ensure DataFrame format for downstream processing\n",
    "- **Column Ordering**: Maintain consistent feature order\n",
    "- **Type Validation**: Verify all features are properly formatted\n",
    "\n",
    "**Result**: Clean, complete dataset ready for machine learning model training with no missing values and optimal feature representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c5a3fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting imputation...\n",
      "Imputation completed\n",
      "Final processed data shapes:\n",
      "- X_train_selected: (307511, 48)\n",
      "- X_test_selected: (48744, 48)\n",
      "Data Imputation - done in 0s\n"
     ]
    }
   ],
   "source": [
    "with timer(\"Data Imputation\"):\n",
    "    X_train_selected = X_train[selected_features]\n",
    "    X_test_selected = test_encoded[selected_features]\n",
    "    \n",
    "    print('Starting imputation...')\n",
    "    imputer = SimpleImputer()\n",
    "    imputer.fit(X_train_selected)\n",
    "    X_train_selected = imputer.transform(X_train_selected)\n",
    "    X_test_selected = imputer.transform(X_test_selected)\n",
    "    print('Imputation completed')\n",
    "    \n",
    "    # Ensure DataFrames\n",
    "    if not isinstance(X_train_selected, pd.DataFrame):\n",
    "        if isinstance(selected_features, pd.Index):\n",
    "            selected_features = selected_features.tolist()\n",
    "        X_train_selected = pd.DataFrame(X_train_selected, columns=selected_features)\n",
    "    if not isinstance(X_test_selected, pd.DataFrame):\n",
    "        if isinstance(selected_features, pd.Index):\n",
    "            selected_features = selected_features.tolist()\n",
    "        X_test_selected = pd.DataFrame(X_test_selected, columns=selected_features)\n",
    "    \n",
    "    print(f\"Final processed data shapes:\")\n",
    "    print(f\"- X_train_selected: {X_train_selected.shape}\")\n",
    "    print(f\"- X_test_selected: {X_test_selected.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d76aa40",
   "metadata": {},
   "source": [
    "## 10. Save Processed Data\n",
    "\n",
    "### Final Data Artifacts - Production Ready:\n",
    "This checkpoint saves the fully processed, model-ready datasets that represent the culmination of all preprocessing steps.\n",
    "\n",
    "**Critical Data Assets Created:**\n",
    "\n",
    "### `data/processed/train_processed.csv`:\n",
    "- **Complete Training Set**: All preprocessing applied + TARGET column\n",
    "- **Model Ready**: Can be directly used for model training\n",
    "- **Feature Complete**: 50 selected features + target variable\n",
    "- **Quality Assured**: No missing values, optimal data types\n",
    "\n",
    "### `data/processed/test_processed.csv`:\n",
    "- **Prediction Ready**: Test set with identical preprocessing\n",
    "- **Consistent Transformation**: Same encoding, selection, and imputation as training\n",
    "- **Production Format**: Ready for final model predictions\n",
    "\n",
    "### Data Validation Process:\n",
    "The `validate_data()` function performs comprehensive quality checks:\n",
    "\n",
    "**Training Data Validation:**\n",
    "- **Target Distribution**: Verify class balance and target variable integrity\n",
    "- **Feature Completeness**: Ensure no missing values remain\n",
    "- **Data Types**: Confirm all features are numerical and model-compatible\n",
    "- **Statistical Sanity**: Check for reasonable value ranges\n",
    "\n",
    "**Test Data Validation:**\n",
    "- **Schema Consistency**: Same features as training data\n",
    "- **Distribution Alignment**: Similar feature distributions to training\n",
    "- **Format Compatibility**: Ready for model inference\n",
    "\n",
    "### Business Impact:\n",
    "- **Reproducibility**: Exact same data can be used across experiments\n",
    "- **Auditability**: Complete preprocessing audit trail\n",
    "- **Efficiency**: Skip preprocessing in future model iterations\n",
    "- **Collaboration**: Standardized data format for team use\n",
    "\n",
    "**Next Phase**: These processed datasets feed directly into the three-level stacking model training pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "979cdb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved:\n",
      "- temp_results/data/processed/train_processed.csv\n",
      "- temp_results/data/processed/test_processed.csv\n",
      "\n",
      "=== Training Data Validation ===\n",
      "NaN values: 0\n",
      "Infinity values: 0\n",
      "Min value: -540000.000000\n",
      "Max value: 1017957888.000000\n",
      "Zero variance features: 0\n",
      "Target distribution: {0.0: 282686, 1.0: 24825}\n",
      "==============================\n",
      "\n",
      "=== Test Data Validation ===\n",
      "NaN values: 0\n",
      "Infinity values: 0\n",
      "Min value: -356400.000000\n",
      "Max value: 609164480.000000\n",
      "Zero variance features: 0\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "# Save fully processed data\n",
    "os.makedirs(DATA_PROCESSED_DIR, exist_ok=True)\n",
    "X_train_processed = X_train_selected.copy()\n",
    "X_train_processed['TARGET'] = y_train.values\n",
    "X_train_processed.to_csv(f'{DATA_PROCESSED_DIR}/train_processed.csv', index=False)\n",
    "X_test_selected.to_csv(f'{DATA_PROCESSED_DIR}/test_processed.csv', index=False)\n",
    "\n",
    "print(\"Processed data saved:\")\n",
    "print(f\"- {DATA_PROCESSED_DIR}/train_processed.csv\")\n",
    "print(f\"- {DATA_PROCESSED_DIR}/test_processed.csv\")\n",
    "\n",
    "# Data quality validation\n",
    "validate_data(X_train_selected, y_train, \"Training Data\")\n",
    "validate_data(X_test_selected, None, \"Test Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19834846",
   "metadata": {},
   "source": [
    "## 11. Level 1 Stacking (Base Models)\n",
    "\n",
    "### Foundation Layer - Diverse Base Model Ensemble:\n",
    "Level 1 represents the foundation of our stacking approach, employing three complementary algorithms that capture different aspects of the data.\n",
    "\n",
    "**Base Model Architecture:**\n",
    "\n",
    "### XGBoost (Extreme Gradient Boosting):\n",
    "- **Strengths**: Excellent handling of missing values, built-in regularization\n",
    "- **Best For**: Non-linear relationships, feature interactions\n",
    "- **Credit Risk Advantage**: Robust to outliers, handles mixed data types well\n",
    "- **Hyperparameter Focus**: Learning rate, max depth, regularization parameters\n",
    "\n",
    "### LightGBM (Light Gradient Boosting Machine):\n",
    "- **Strengths**: Fast training, memory efficient, high accuracy\n",
    "- **Best For**: Large datasets, categorical features\n",
    "- **Credit Risk Advantage**: Efficient handling of high-cardinality categorical variables\n",
    "- **Hyperparameter Focus**: Number of leaves, feature fraction, bagging parameters\n",
    "\n",
    "### CatBoost (Categorical Boosting):\n",
    "- **Strengths**: Superior categorical feature handling, minimal hyperparameter tuning\n",
    "- **Best For**: Datasets with many categorical features, robust performance\n",
    "- **Credit Risk Advantage**: Built-in categorical encoding, reduces preprocessing needs\n",
    "- **Hyperparameter Focus**: Iterations, depth, learning rate\n",
    "\n",
    "### Cross-Validation Strategy:\n",
    "- **5-Fold Stratified CV**: Maintains class distribution across folds\n",
    "- **Out-of-Fold Predictions**: Generate unbiased predictions for meta-learning\n",
    "- **Performance Tracking**: Individual model AUC scores for model selection\n",
    "\n",
    "### Output Artifacts:\n",
    "- **Trained Models**: Serialized models for each algorithm (.pkl files)\n",
    "- **OOF Predictions**: Out-of-fold predictions for Level 2 training\n",
    "- **Test Predictions**: Base predictions for final ensemble\n",
    "- **Performance Metrics**: AUC, accuracy, and other evaluation metrics\n",
    "\n",
    "### Ensemble Benefit:\n",
    "Combining diverse algorithms reduces overfitting and captures different data patterns:\n",
    "- **XGBoost**: Captures complex interactions\n",
    "- **LightGBM**: Efficient pattern recognition  \n",
    "- **CatBoost**: Robust categorical handling\n",
    "\n",
    "**Expected Performance**: Each base model should achieve competitive individual performance, with the ensemble providing superior results through diversity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8fe6a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-30 10:54:11,162] A new study created in memory with name: no-name-a70fb72f-50b4-4fc1-b735-82bcf04ff164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "LEVEL 1 STACKING - BASE MODELS\n",
      "==================================================\n",
      "\n",
      "=== Generating L1 OOF predictions for stacking ===\n",
      "Running xgb ...\n",
      "[XGB] Optuna tuning fold 1/5...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "166bd1a53ba6459aae0bc458e4b6785f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-30 10:55:13,098] Trial 0 finished with value: 0.7378561660488391 and parameters: {'max_depth': 8, 'learning_rate': 0.13199145379661492, 'n_estimators': 969, 'subsample': 0.8802345258270485, 'colsample_bytree': 0.8488091349321845, 'min_child_weight': 4, 'gamma': 0.13135259781592332, 'reg_alpha': 0.4397681273652026, 'reg_lambda': 0.44932162449963253}. Best is trial 0 with value: 0.7378561660488391.\n",
      "[I 2025-07-30 10:56:18,006] Trial 1 finished with value: 0.7448878983155223 and parameters: {'max_depth': 6, 'learning_rate': 0.11832992732557608, 'n_estimators': 1241, 'subsample': 0.8668422223989893, 'colsample_bytree': 0.8158210260380283, 'min_child_weight': 5, 'gamma': 0.19229365677648733, 'reg_alpha': 0.47645695794644216, 'reg_lambda': 0.48818850063083213}. Best is trial 1 with value: 0.7448878983155223.\n",
      "[I 2025-07-30 10:57:27,931] Trial 2 finished with value: 0.7351615324774344 and parameters: {'max_depth': 6, 'learning_rate': 0.1469997773977799, 'n_estimators': 1290, 'subsample': 0.7801192253150881, 'colsample_bytree': 0.8293138746177418, 'min_child_weight': 1, 'gamma': 0.045052097956110676, 'reg_alpha': 0.3071695356578865, 'reg_lambda': 0.42911576330683643}. Best is trial 1 with value: 0.7448878983155223.\n",
      "[I 2025-07-30 10:58:12,325] Trial 3 finished with value: 0.7307165970165587 and parameters: {'max_depth': 7, 'learning_rate': 0.16491380527257582, 'n_estimators': 736, 'subsample': 0.7727967206690364, 'colsample_bytree': 0.7397990269269186, 'min_child_weight': 4, 'gamma': 0.09056324872058824, 'reg_alpha': 0.42830738771955296, 'reg_lambda': 0.08795741692887793}. Best is trial 1 with value: 0.7448878983155223.\n",
      "[I 2025-07-30 10:58:40,102] Trial 4 finished with value: 0.7702419168804266 and parameters: {'max_depth': 5, 'learning_rate': 0.054805794929773145, 'n_estimators': 549, 'subsample': 0.7535510113511565, 'colsample_bytree': 0.7090109025822542, 'min_child_weight': 4, 'gamma': 0.05215678241679869, 'reg_alpha': 0.4481296436224602, 'reg_lambda': 0.033309824873612726}. Best is trial 4 with value: 0.7702419168804266.\n",
      "[I 2025-07-30 10:59:24,302] Trial 5 finished with value: 0.7721211135366204 and parameters: {'max_depth': 4, 'learning_rate': 0.03251287407355267, 'n_estimators': 937, 'subsample': 0.7448392115565093, 'colsample_bytree': 0.736812419173677, 'min_child_weight': 4, 'gamma': 0.17836558550436366, 'reg_alpha': 0.4076830453786642, 'reg_lambda': 0.1498792886284065}. Best is trial 5 with value: 0.7721211135366204.\n",
      "[I 2025-07-30 11:00:24,976] Trial 6 finished with value: 0.7627041025769841 and parameters: {'max_depth': 6, 'learning_rate': 0.04834066181891207, 'n_estimators': 1130, 'subsample': 0.738325184261093, 'colsample_bytree': 0.8903091592881053, 'min_child_weight': 1, 'gamma': 0.05490389155886899, 'reg_alpha': 0.036001899670468684, 'reg_lambda': 0.09237998136474657}. Best is trial 5 with value: 0.7721211135366204.\n",
      "[I 2025-07-30 11:01:46,138] Trial 7 finished with value: 0.7317633906314159 and parameters: {'max_depth': 6, 'learning_rate': 0.14453186797920362, 'n_estimators': 1468, 'subsample': 0.7453042941405844, 'colsample_bytree': 0.7711949773880012, 'min_child_weight': 2, 'gamma': 0.07965088238785592, 'reg_alpha': 0.17753765213504513, 'reg_lambda': 0.28509233085705854}. Best is trial 5 with value: 0.7721211135366204.\n",
      "[I 2025-07-30 11:03:23,560] Trial 8 finished with value: 0.7437917029327926 and parameters: {'max_depth': 8, 'learning_rate': 0.07912275376752967, 'n_estimators': 1423, 'subsample': 0.8422858424844893, 'colsample_bytree': 0.8315796504927169, 'min_child_weight': 1, 'gamma': 0.11106762258060893, 'reg_alpha': 0.27061382995670813, 'reg_lambda': 0.49596327446278937}. Best is trial 5 with value: 0.7721211135366204.\n",
      "[I 2025-07-30 11:03:56,710] Trial 9 finished with value: 0.7550642025990353 and parameters: {'max_depth': 4, 'learning_rate': 0.19402653351660618, 'n_estimators': 701, 'subsample': 0.7661256980236192, 'colsample_bytree': 0.7579885639893195, 'min_child_weight': 5, 'gamma': 0.09953036058938516, 'reg_alpha': 0.08906101324632387, 'reg_lambda': 0.17555153666293666}. Best is trial 5 with value: 0.7721211135366204.\n",
      "[I 2025-07-30 11:04:41,526] Trial 10 finished with value: 0.7666497091092852 and parameters: {'max_depth': 4, 'learning_rate': 0.012746082314338252, 'n_estimators': 937, 'subsample': 0.700204316965622, 'colsample_bytree': 0.7049381450052616, 'min_child_weight': 3, 'gamma': 0.1999970421407135, 'reg_alpha': 0.35070915699617716, 'reg_lambda': 0.29116461044567415}. Best is trial 5 with value: 0.7721211135366204.\n",
      "[I 2025-07-30 11:05:08,548] Trial 11 finished with value: 0.7701543490944305 and parameters: {'max_depth': 5, 'learning_rate': 0.05721838031924918, 'n_estimators': 536, 'subsample': 0.8151588349248344, 'colsample_bytree': 0.7022328679447851, 'min_child_weight': 4, 'gamma': 0.0018008323258421888, 'reg_alpha': 0.3745535543694465, 'reg_lambda': 0.009536307737342098}. Best is trial 5 with value: 0.7721211135366204.\n",
      "[I 2025-07-30 11:05:36,149] Trial 12 finished with value: 0.7620959784285913 and parameters: {'max_depth': 5, 'learning_rate': 0.01049173408229602, 'n_estimators': 529, 'subsample': 0.7111775502528971, 'colsample_bytree': 0.7304907787447382, 'min_child_weight': 3, 'gamma': 0.1489808444218331, 'reg_alpha': 0.19787361602748382, 'reg_lambda': 0.18011389223611646}. Best is trial 5 with value: 0.7721211135366204.\n",
      "[I 2025-07-30 11:06:13,504] Trial 13 finished with value: 0.7628485286445779 and parameters: {'max_depth': 5, 'learning_rate': 0.0896553289518966, 'n_estimators': 749, 'subsample': 0.8153749527822797, 'colsample_bytree': 0.7842472720613247, 'min_child_weight': 3, 'gamma': 0.017193903388353755, 'reg_alpha': 0.49861488554695554, 'reg_lambda': 0.0033701854643916687}. Best is trial 5 with value: 0.7721211135366204.\n",
      "[I 2025-07-30 11:06:53,022] Trial 14 finished with value: 0.7720406217762382 and parameters: {'max_depth': 4, 'learning_rate': 0.04029891761738113, 'n_estimators': 829, 'subsample': 0.7328451868511746, 'colsample_bytree': 0.7304202762281007, 'min_child_weight': 4, 'gamma': 0.16118833330042384, 'reg_alpha': 0.39472651972444917, 'reg_lambda': 0.11179564185241392}. Best is trial 5 with value: 0.7721211135366204.\n",
      "[I 2025-07-30 11:07:34,246] Trial 15 finished with value: 0.7718797858177507 and parameters: {'max_depth': 4, 'learning_rate': 0.03344718665347175, 'n_estimators': 874, 'subsample': 0.7343188189647417, 'colsample_bytree': 0.740619285915476, 'min_child_weight': 5, 'gamma': 0.16130025972626746, 'reg_alpha': 0.3684215775757407, 'reg_lambda': 0.19500555608853656}. Best is trial 5 with value: 0.7721211135366204.\n",
      "[I 2025-07-30 11:08:24,003] Trial 16 finished with value: 0.7656191454058362 and parameters: {'max_depth': 4, 'learning_rate': 0.08935234899881246, 'n_estimators': 1064, 'subsample': 0.7239753062727976, 'colsample_bytree': 0.7846866561919241, 'min_child_weight': 3, 'gamma': 0.17213030344596747, 'reg_alpha': 0.30026946056029663, 'reg_lambda': 0.12180466503667708}. Best is trial 5 with value: 0.7721211135366204.\n",
      "[I 2025-07-30 11:09:04,441] Trial 17 finished with value: 0.7713576921449202 and parameters: {'max_depth': 4, 'learning_rate': 0.033979205028328345, 'n_estimators': 857, 'subsample': 0.7859981198967102, 'colsample_bytree': 0.7288764761965454, 'min_child_weight': 2, 'gamma': 0.13099602494784843, 'reg_alpha': 0.2143205554556896, 'reg_lambda': 0.33874234812577975}. Best is trial 5 with value: 0.7721211135366204.\n",
      "[I 2025-07-30 11:10:07,510] Trial 18 finished with value: 0.7536410813350355 and parameters: {'max_depth': 7, 'learning_rate': 0.06698400695777834, 'n_estimators': 1106, 'subsample': 0.8034269138827783, 'colsample_bytree': 0.7550206376728851, 'min_child_weight': 4, 'gamma': 0.17773883746562966, 'reg_alpha': 0.39318668610539825, 'reg_lambda': 0.14330332096693082}. Best is trial 5 with value: 0.7721211135366204.\n",
      "[I 2025-07-30 11:10:48,311] Trial 19 finished with value: 0.7717489576294096 and parameters: {'max_depth': 5, 'learning_rate': 0.030707005631044646, 'n_estimators': 813, 'subsample': 0.7162064007558414, 'colsample_bytree': 0.8030487801559064, 'min_child_weight': 2, 'gamma': 0.14385763770111498, 'reg_alpha': 0.3260848748940281, 'reg_lambda': 0.23023890980299835}. Best is trial 5 with value: 0.7721211135366204.\n",
      "Best params: {'max_depth': 4, 'learning_rate': 0.03251287407355267, 'n_estimators': 937, 'subsample': 0.7448392115565093, 'colsample_bytree': 0.736812419173677, 'min_child_weight': 4, 'gamma': 0.17836558550436366, 'reg_alpha': 0.4076830453786642, 'reg_lambda': 0.1498792886284065}\n",
      "Best AUC: 0.7721211135366204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-30 11:10:58,273] A new study created in memory with name: no-name-08834e66-8de9-49ab-81fd-0d6f34332176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[XGB] Fold 1/5 done.\n",
      "[XGB] Optuna tuning fold 2/5...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29bf2f20618c47148511018e31156876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-30 11:11:41,231] Trial 0 finished with value: 0.7693059543971752 and parameters: {'max_depth': 4, 'learning_rate': 0.033205179009134445, 'n_estimators': 912, 'subsample': 0.750021415454905, 'colsample_bytree': 0.7699061118853854, 'min_child_weight': 2, 'gamma': 0.16019346778588428, 'reg_alpha': 0.45290234456061684, 'reg_lambda': 0.11780435113937143}. Best is trial 0 with value: 0.7693059543971752.\n",
      "[I 2025-07-30 11:12:29,863] Trial 1 finished with value: 0.7660181112179885 and parameters: {'max_depth': 6, 'learning_rate': 0.04143813074877811, 'n_estimators': 906, 'subsample': 0.7454042985278411, 'colsample_bytree': 0.7410432618875985, 'min_child_weight': 5, 'gamma': 0.022289662684283097, 'reg_alpha': 0.4660705245654982, 'reg_lambda': 0.16389054386158547}. Best is trial 0 with value: 0.7693059543971752.\n",
      "[I 2025-07-30 11:13:54,806] Trial 2 finished with value: 0.7229687335244673 and parameters: {'max_depth': 7, 'learning_rate': 0.18171066009455528, 'n_estimators': 1448, 'subsample': 0.7566866492804778, 'colsample_bytree': 0.756844857550983, 'min_child_weight': 5, 'gamma': 0.1134393868560194, 'reg_alpha': 0.40291768427795954, 'reg_lambda': 0.20312335236066303}. Best is trial 0 with value: 0.7693059543971752.\n",
      "[I 2025-07-30 11:14:28,722] Trial 3 finished with value: 0.768707328266145 and parameters: {'max_depth': 6, 'learning_rate': 0.0271061016999274, 'n_estimators': 622, 'subsample': 0.7989594768616934, 'colsample_bytree': 0.7636200413722526, 'min_child_weight': 1, 'gamma': 0.1768540367166862, 'reg_alpha': 0.22221772782087007, 'reg_lambda': 0.13876731445252855}. Best is trial 0 with value: 0.7693059543971752.\n",
      "[I 2025-07-30 11:15:00,486] Trial 4 finished with value: 0.7487740113030578 and parameters: {'max_depth': 8, 'learning_rate': 0.09769401582245618, 'n_estimators': 506, 'subsample': 0.8727449335811688, 'colsample_bytree': 0.7824931303554835, 'min_child_weight': 5, 'gamma': 0.07967601983836342, 'reg_alpha': 0.3185266657663082, 'reg_lambda': 0.20310200757157015}. Best is trial 0 with value: 0.7693059543971752.\n",
      "[I 2025-07-30 11:15:34,998] Trial 5 finished with value: 0.7486637709739772 and parameters: {'max_depth': 5, 'learning_rate': 0.16773160199964623, 'n_estimators': 699, 'subsample': 0.8734901892930181, 'colsample_bytree': 0.8968880876499491, 'min_child_weight': 5, 'gamma': 0.11727209621892681, 'reg_alpha': 0.31790702530441106, 'reg_lambda': 0.010628619151531626}. Best is trial 0 with value: 0.7693059543971752.\n",
      "[I 2025-07-30 11:16:38,438] Trial 6 finished with value: 0.7449810149763706 and parameters: {'max_depth': 4, 'learning_rate': 0.1797736436427872, 'n_estimators': 1368, 'subsample': 0.8011698427061213, 'colsample_bytree': 0.8091866924896087, 'min_child_weight': 3, 'gamma': 0.08058829273078422, 'reg_alpha': 0.36500127203695576, 'reg_lambda': 0.13963475555714638}. Best is trial 0 with value: 0.7693059543971752.\n",
      "[I 2025-07-30 11:17:39,188] Trial 7 finished with value: 0.7669924872005423 and parameters: {'max_depth': 4, 'learning_rate': 0.05617702801830399, 'n_estimators': 1301, 'subsample': 0.7199677909975563, 'colsample_bytree': 0.8089502498809829, 'min_child_weight': 3, 'gamma': 0.10729921937870211, 'reg_alpha': 0.17357165876821118, 'reg_lambda': 0.4483113564557417}. Best is trial 0 with value: 0.7693059543971752.\n",
      "[I 2025-07-30 11:18:24,136] Trial 8 finished with value: 0.7296081037340847 and parameters: {'max_depth': 8, 'learning_rate': 0.18367018317392275, 'n_estimators': 700, 'subsample': 0.897422506740599, 'colsample_bytree': 0.8642492869680225, 'min_child_weight': 4, 'gamma': 0.10898065680041075, 'reg_alpha': 0.4021742747989121, 'reg_lambda': 0.48576596498693964}. Best is trial 0 with value: 0.7693059543971752.\n",
      "[I 2025-07-30 11:19:39,289] Trial 9 finished with value: 0.76836092135283 and parameters: {'max_depth': 7, 'learning_rate': 0.017280460581361255, 'n_estimators': 1293, 'subsample': 0.7292158713211849, 'colsample_bytree': 0.8467246294760772, 'min_child_weight': 3, 'gamma': 0.10474868630021686, 'reg_alpha': 0.20134038188817538, 'reg_lambda': 0.21684338042227297}. Best is trial 0 with value: 0.7693059543971752.\n",
      "[I 2025-07-30 11:20:31,853] Trial 10 finished with value: 0.7590386559571004 and parameters: {'max_depth': 5, 'learning_rate': 0.08547378655234406, 'n_estimators': 1070, 'subsample': 0.7879875502561039, 'colsample_bytree': 0.7137913371344977, 'min_child_weight': 1, 'gamma': 0.16951105646624515, 'reg_alpha': 0.030071759641796036, 'reg_lambda': 0.34268529898344713}. Best is trial 0 with value: 0.7693059543971752.\n",
      "[I 2025-07-30 11:21:18,293] Trial 11 finished with value: 0.7691578279828052 and parameters: {'max_depth': 5, 'learning_rate': 0.027007858522690012, 'n_estimators': 935, 'subsample': 0.8099070514988629, 'colsample_bytree': 0.7654655105099243, 'min_child_weight': 1, 'gamma': 0.18351607099694126, 'reg_alpha': 0.1465078548755669, 'reg_lambda': 0.058810472848337486}. Best is trial 0 with value: 0.7693059543971752.\n",
      "[I 2025-07-30 11:22:04,676] Trial 12 finished with value: 0.764468811160901 and parameters: {'max_depth': 5, 'learning_rate': 0.06684391667346395, 'n_estimators': 946, 'subsample': 0.8308197408700123, 'colsample_bytree': 0.7021687327698527, 'min_child_weight': 2, 'gamma': 0.19165960449245484, 'reg_alpha': 0.09785990738412412, 'reg_lambda': 0.02244701632650814}. Best is trial 0 with value: 0.7693059543971752.\n",
      "[I 2025-07-30 11:22:56,407] Trial 13 finished with value: 0.7545663809140937 and parameters: {'max_depth': 4, 'learning_rate': 0.1349234525655962, 'n_estimators': 1102, 'subsample': 0.701106138947006, 'colsample_bytree': 0.790175534901165, 'min_child_weight': 2, 'gamma': 0.14852434216329058, 'reg_alpha': 0.1178307269279168, 'reg_lambda': 0.07195125853012639}. Best is trial 0 with value: 0.7693059543971752.\n",
      "[I 2025-07-30 11:23:39,712] Trial 14 finished with value: 0.7498920060042761 and parameters: {'max_depth': 5, 'learning_rate': 0.13167323705596318, 'n_estimators': 874, 'subsample': 0.7718884992046581, 'colsample_bytree': 0.7390382594240196, 'min_child_weight': 2, 'gamma': 0.14380269247458832, 'reg_alpha': 0.49593364416277397, 'reg_lambda': 0.30115328935587793}. Best is trial 0 with value: 0.7693059543971752.\n",
      "[I 2025-07-30 11:24:36,451] Trial 15 finished with value: 0.7663527637895712 and parameters: {'max_depth': 4, 'learning_rate': 0.01314442701062938, 'n_estimators': 1168, 'subsample': 0.8317855840490981, 'colsample_bytree': 0.8336145575477495, 'min_child_weight': 1, 'gamma': 0.19571049545781388, 'reg_alpha': 0.2667972123628858, 'reg_lambda': 0.0669388286376229}. Best is trial 0 with value: 0.7693059543971752.\n",
      "[I 2025-07-30 11:25:21,950] Trial 16 finished with value: 0.7587485032292762 and parameters: {'max_depth': 6, 'learning_rate': 0.07041209398255789, 'n_estimators': 863, 'subsample': 0.8269385907785662, 'colsample_bytree': 0.7697830846628925, 'min_child_weight': 2, 'gamma': 0.14169873039230207, 'reg_alpha': 0.021714742730395087, 'reg_lambda': 0.08710531030522745}. Best is trial 0 with value: 0.7693059543971752.\n",
      "[I 2025-07-30 11:26:01,767] Trial 17 finished with value: 0.7689795283619058 and parameters: {'max_depth': 5, 'learning_rate': 0.040341750043408606, 'n_estimators': 776, 'subsample': 0.7729231056320359, 'colsample_bytree': 0.7305762246174399, 'min_child_weight': 1, 'gamma': 0.1628211850598805, 'reg_alpha': 0.1269913430679746, 'reg_lambda': 0.29235967795793794}. Best is trial 0 with value: 0.7693059543971752.\n",
      "[I 2025-07-30 11:26:49,489] Trial 18 finished with value: 0.7606725839348837 and parameters: {'max_depth': 4, 'learning_rate': 0.11647826447579498, 'n_estimators': 1028, 'subsample': 0.8164719483112481, 'colsample_bytree': 0.8198683902251273, 'min_child_weight': 2, 'gamma': 0.009743344090816897, 'reg_alpha': 0.28182722850314207, 'reg_lambda': 0.10125936462629448}. Best is trial 0 with value: 0.7693059543971752.\n",
      "[I 2025-07-30 11:27:51,979] Trial 19 finished with value: 0.7637451722034609 and parameters: {'max_depth': 6, 'learning_rate': 0.041668224532341765, 'n_estimators': 1184, 'subsample': 0.7464448472505176, 'colsample_bytree': 0.7848100481745007, 'min_child_weight': 4, 'gamma': 0.19885605666749118, 'reg_alpha': 0.1622315200220183, 'reg_lambda': 0.03965106509974664}. Best is trial 0 with value: 0.7693059543971752.\n",
      "Best params: {'max_depth': 4, 'learning_rate': 0.033205179009134445, 'n_estimators': 912, 'subsample': 0.750021415454905, 'colsample_bytree': 0.7699061118853854, 'min_child_weight': 2, 'gamma': 0.16019346778588428, 'reg_alpha': 0.45290234456061684, 'reg_lambda': 0.11780435113937143}\n",
      "Best AUC: 0.7693059543971752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-30 11:28:01,642] A new study created in memory with name: no-name-f07585d4-3006-4647-892e-47918fe93113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[XGB] Fold 2/5 done.\n",
      "[XGB] Optuna tuning fold 3/5...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "876cfbf57ce34aca823e7b2933b93f5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-30 11:28:39,221] Trial 0 finished with value: 0.7346310250177414 and parameters: {'max_depth': 8, 'learning_rate': 0.15363527786997103, 'n_estimators': 581, 'subsample': 0.7500432709717348, 'colsample_bytree': 0.8726743814254998, 'min_child_weight': 4, 'gamma': 0.16322103772093344, 'reg_alpha': 0.22467063629065054, 'reg_lambda': 0.256202186975121}. Best is trial 0 with value: 0.7346310250177414.\n",
      "[I 2025-07-30 11:29:30,279] Trial 1 finished with value: 0.7548356236381814 and parameters: {'max_depth': 7, 'learning_rate': 0.081737691067035, 'n_estimators': 903, 'subsample': 0.8751244097547246, 'colsample_bytree': 0.8149608253169849, 'min_child_weight': 4, 'gamma': 0.013208579066475924, 'reg_alpha': 0.13621516893828806, 'reg_lambda': 0.4952522346847284}. Best is trial 1 with value: 0.7548356236381814.\n",
      "[I 2025-07-30 11:30:12,357] Trial 2 finished with value: 0.7666412676699701 and parameters: {'max_depth': 6, 'learning_rate': 0.055788807660643765, 'n_estimators': 797, 'subsample': 0.86934193218242, 'colsample_bytree': 0.8584629968786422, 'min_child_weight': 2, 'gamma': 0.0631319500540682, 'reg_alpha': 0.06014841566305057, 'reg_lambda': 0.13602541151251912}. Best is trial 2 with value: 0.7666412676699701.\n",
      "[I 2025-07-30 11:30:59,624] Trial 3 finished with value: 0.7721707808766402 and parameters: {'max_depth': 4, 'learning_rate': 0.04008052325388479, 'n_estimators': 1011, 'subsample': 0.8365691284810448, 'colsample_bytree': 0.8395401979742422, 'min_child_weight': 4, 'gamma': 0.06168594063651605, 'reg_alpha': 0.32523011032711924, 'reg_lambda': 0.4060535828319063}. Best is trial 3 with value: 0.7721707808766402.\n",
      "[I 2025-07-30 11:31:32,145] Trial 4 finished with value: 0.7486762694178086 and parameters: {'max_depth': 6, 'learning_rate': 0.15071450354877752, 'n_estimators': 615, 'subsample': 0.7932867698060988, 'colsample_bytree': 0.7094486591787076, 'min_child_weight': 5, 'gamma': 0.1996392504867396, 'reg_alpha': 0.3063608397906531, 'reg_lambda': 0.270842149325845}. Best is trial 3 with value: 0.7721707808766402.\n",
      "[I 2025-07-30 11:32:23,269] Trial 5 finished with value: 0.7530394804008517 and parameters: {'max_depth': 8, 'learning_rate': 0.07320900995454087, 'n_estimators': 805, 'subsample': 0.8817034906353864, 'colsample_bytree': 0.7006863910713371, 'min_child_weight': 2, 'gamma': 0.11595640563080212, 'reg_alpha': 0.1842922033786325, 'reg_lambda': 0.1581460421831808}. Best is trial 3 with value: 0.7721707808766402.\n",
      "[I 2025-07-30 11:33:31,053] Trial 6 finished with value: 0.772000530449947 and parameters: {'max_depth': 5, 'learning_rate': 0.029679938326978572, 'n_estimators': 1382, 'subsample': 0.8452011349076997, 'colsample_bytree': 0.7353233083594828, 'min_child_weight': 3, 'gamma': 0.1558096193238352, 'reg_alpha': 0.27447342221945775, 'reg_lambda': 0.1100670065098896}. Best is trial 3 with value: 0.7721707808766402.\n",
      "[I 2025-07-30 11:34:26,818] Trial 7 finished with value: 0.7285431941048838 and parameters: {'max_depth': 8, 'learning_rate': 0.1698215006403316, 'n_estimators': 855, 'subsample': 0.7597262922510424, 'colsample_bytree': 0.8397759978797241, 'min_child_weight': 2, 'gamma': 0.05275337626933155, 'reg_alpha': 0.02097866812664756, 'reg_lambda': 0.28482669281071155}. Best is trial 3 with value: 0.7721707808766402.\n",
      "[I 2025-07-30 11:35:44,429] Trial 8 finished with value: 0.7591935240433617 and parameters: {'max_depth': 7, 'learning_rate': 0.0477149327857659, 'n_estimators': 1377, 'subsample': 0.8960256483458791, 'colsample_bytree': 0.7154814500354758, 'min_child_weight': 4, 'gamma': 0.027744888933527046, 'reg_alpha': 0.010930440215405346, 'reg_lambda': 0.3148868986147971}. Best is trial 3 with value: 0.7721707808766402.\n",
      "[I 2025-07-30 11:36:57,216] Trial 9 finished with value: 0.7365028095064293 and parameters: {'max_depth': 6, 'learning_rate': 0.15182977888899066, 'n_estimators': 1365, 'subsample': 0.8593769709878296, 'colsample_bytree': 0.8404190473592573, 'min_child_weight': 1, 'gamma': 0.11428147260266526, 'reg_alpha': 0.08429033589168211, 'reg_lambda': 0.44011173884601207}. Best is trial 3 with value: 0.7721707808766402.\n",
      "[I 2025-07-30 11:37:49,904] Trial 10 finished with value: 0.7644761028939039 and parameters: {'max_depth': 4, 'learning_rate': 0.10503094427844717, 'n_estimators': 1136, 'subsample': 0.8168825846010775, 'colsample_bytree': 0.7746524726765072, 'min_child_weight': 5, 'gamma': 0.07891881488732369, 'reg_alpha': 0.45817617410409683, 'reg_lambda': 0.39363753038697347}. Best is trial 3 with value: 0.7721707808766402.\n",
      "[I 2025-07-30 11:38:44,629] Trial 11 finished with value: 0.76757985361067 and parameters: {'max_depth': 4, 'learning_rate': 0.011315124245496036, 'n_estimators': 1154, 'subsample': 0.8277731709765064, 'colsample_bytree': 0.7592315489556429, 'min_child_weight': 3, 'gamma': 0.14412152348737667, 'reg_alpha': 0.3324873579722654, 'reg_lambda': 0.022690624249605496}. Best is trial 3 with value: 0.7721707808766402.\n",
      "[I 2025-07-30 11:39:44,105] Trial 12 finished with value: 0.771830733230861 and parameters: {'max_depth': 5, 'learning_rate': 0.014255784842373128, 'n_estimators': 1181, 'subsample': 0.7050046694414095, 'colsample_bytree': 0.8967240261930968, 'min_child_weight': 3, 'gamma': 0.15777376683695363, 'reg_alpha': 0.3825150416669602, 'reg_lambda': 0.13633194560495038}. Best is trial 3 with value: 0.7721707808766402.\n",
      "[I 2025-07-30 11:40:56,903] Trial 13 finished with value: 0.7701179538090005 and parameters: {'max_depth': 5, 'learning_rate': 0.03693281164548572, 'n_estimators': 1485, 'subsample': 0.8365448972326044, 'colsample_bytree': 0.7537039716471214, 'min_child_weight': 3, 'gamma': 0.09268663747913797, 'reg_alpha': 0.27944690097658403, 'reg_lambda': 0.056559652662011295}. Best is trial 3 with value: 0.7721707808766402.\n",
      "[I 2025-07-30 11:41:47,518] Trial 14 finished with value: 0.7572849158521388 and parameters: {'max_depth': 5, 'learning_rate': 0.10398348092630426, 'n_estimators': 1026, 'subsample': 0.783820422341239, 'colsample_bytree': 0.8062073724652662, 'min_child_weight': 4, 'gamma': 0.1992693801385627, 'reg_alpha': 0.4026550938778497, 'reg_lambda': 0.36113561513141623}. Best is trial 3 with value: 0.7721707808766402.\n",
      "[I 2025-07-30 11:42:47,538] Trial 15 finished with value: 0.7727889012803487 and parameters: {'max_depth': 4, 'learning_rate': 0.03163007115154362, 'n_estimators': 1272, 'subsample': 0.8426157089272099, 'colsample_bytree': 0.7807691092366762, 'min_child_weight': 5, 'gamma': 0.04098964989860348, 'reg_alpha': 0.49831122729851196, 'reg_lambda': 0.19245288790654214}. Best is trial 15 with value: 0.7727889012803487.\n",
      "[I 2025-07-30 11:43:34,206] Trial 16 finished with value: 0.7702976421087726 and parameters: {'max_depth': 4, 'learning_rate': 0.07045639236771167, 'n_estimators': 1001, 'subsample': 0.8091406541948425, 'colsample_bytree': 0.7816830923910673, 'min_child_weight': 5, 'gamma': 0.04440229735516998, 'reg_alpha': 0.49887733752715496, 'reg_lambda': 0.2267376407526325}. Best is trial 15 with value: 0.7727889012803487.\n",
      "[I 2025-07-30 11:44:30,778] Trial 17 finished with value: 0.7658078709810856 and parameters: {'max_depth': 4, 'learning_rate': 0.08855797728587653, 'n_estimators': 1220, 'subsample': 0.8517139125161008, 'colsample_bytree': 0.8199999485483986, 'min_child_weight': 5, 'gamma': 0.014899507923958881, 'reg_alpha': 0.39912983449807815, 'reg_lambda': 0.19956159117479846}. Best is trial 15 with value: 0.7727889012803487.\n",
      "[I 2025-07-30 11:45:29,336] Trial 18 finished with value: 0.7595444633667249 and parameters: {'max_depth': 4, 'learning_rate': 0.1201130656568422, 'n_estimators': 1255, 'subsample': 0.7786169920624042, 'colsample_bytree': 0.7810822920447473, 'min_child_weight': 4, 'gamma': 0.03781857977120895, 'reg_alpha': 0.4704562545809473, 'reg_lambda': 0.35845486255603803}. Best is trial 15 with value: 0.7727889012803487.\n",
      "[I 2025-07-30 11:46:21,664] Trial 19 finished with value: 0.7683633029471159 and parameters: {'max_depth': 5, 'learning_rate': 0.05601640817989387, 'n_estimators': 1065, 'subsample': 0.8244931195435736, 'colsample_bytree': 0.8366541352727704, 'min_child_weight': 5, 'gamma': 0.0015773335476100062, 'reg_alpha': 0.3324090758143603, 'reg_lambda': 0.48281350082000735}. Best is trial 15 with value: 0.7727889012803487.\n",
      "Best params: {'max_depth': 4, 'learning_rate': 0.03163007115154362, 'n_estimators': 1272, 'subsample': 0.8426157089272099, 'colsample_bytree': 0.7807691092366762, 'min_child_weight': 5, 'gamma': 0.04098964989860348, 'reg_alpha': 0.49831122729851196, 'reg_lambda': 0.19245288790654214}\n",
      "Best AUC: 0.7727889012803487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-30 11:46:34,700] A new study created in memory with name: no-name-a157a238-845b-42cb-9643-bb043d8a815c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[XGB] Fold 3/5 done.\n",
      "[XGB] Optuna tuning fold 4/5...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5084c0aea424d75a047484e5d6774b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-30 11:47:47,399] Trial 0 finished with value: 0.7628683871482801 and parameters: {'max_depth': 8, 'learning_rate': 0.02979083894843277, 'n_estimators': 1147, 'subsample': 0.7410687869536677, 'colsample_bytree': 0.7623177737157435, 'min_child_weight': 5, 'gamma': 0.11507815107327442, 'reg_alpha': 0.48263419806844937, 'reg_lambda': 0.2803345097475983}. Best is trial 0 with value: 0.7628683871482801.\n",
      "[I 2025-07-30 11:48:44,741] Trial 1 finished with value: 0.745573824219492 and parameters: {'max_depth': 4, 'learning_rate': 0.17881535471673726, 'n_estimators': 1217, 'subsample': 0.7293219247263228, 'colsample_bytree': 0.7732460859401138, 'min_child_weight': 1, 'gamma': 0.13238030675809828, 'reg_alpha': 0.3156806515895114, 'reg_lambda': 0.09840622132537791}. Best is trial 0 with value: 0.7628683871482801.\n",
      "[I 2025-07-30 11:49:43,101] Trial 2 finished with value: 0.7357527191888661 and parameters: {'max_depth': 6, 'learning_rate': 0.15178053690511056, 'n_estimators': 1095, 'subsample': 0.8582287161629734, 'colsample_bytree': 0.8624409636981327, 'min_child_weight': 5, 'gamma': 0.01563294292346389, 'reg_alpha': 0.027849097849536042, 'reg_lambda': 0.3126834804626975}. Best is trial 0 with value: 0.7628683871482801.\n",
      "[I 2025-07-30 11:50:55,545] Trial 3 finished with value: 0.733170564004944 and parameters: {'max_depth': 5, 'learning_rate': 0.17825304823099708, 'n_estimators': 1383, 'subsample': 0.7341295165971372, 'colsample_bytree': 0.8789908094479278, 'min_child_weight': 1, 'gamma': 0.10657807096756106, 'reg_alpha': 0.2267943621300188, 'reg_lambda': 0.4827743784596643}. Best is trial 0 with value: 0.7628683871482801.\n",
      "[I 2025-07-30 11:51:23,832] Trial 4 finished with value: 0.7684330384725233 and parameters: {'max_depth': 6, 'learning_rate': 0.04431980926372533, 'n_estimators': 515, 'subsample': 0.8799553403018892, 'colsample_bytree': 0.8027801361921384, 'min_child_weight': 1, 'gamma': 0.005306323053524609, 'reg_alpha': 0.1823903461029011, 'reg_lambda': 0.49128547290180336}. Best is trial 4 with value: 0.7684330384725233.\n",
      "[I 2025-07-30 11:52:35,291] Trial 5 finished with value: 0.7393823567166952 and parameters: {'max_depth': 7, 'learning_rate': 0.10779854998389184, 'n_estimators': 1227, 'subsample': 0.8795674540901592, 'colsample_bytree': 0.8392185211700275, 'min_child_weight': 3, 'gamma': 0.02337631549465882, 'reg_alpha': 0.4313873832611913, 'reg_lambda': 0.3537130929773675}. Best is trial 4 with value: 0.7684330384725233.\n",
      "[I 2025-07-30 11:53:43,874] Trial 6 finished with value: 0.7305955632892299 and parameters: {'max_depth': 5, 'learning_rate': 0.17481724253426043, 'n_estimators': 1354, 'subsample': 0.7105732590790268, 'colsample_bytree': 0.8592552440572294, 'min_child_weight': 2, 'gamma': 0.05464983755412989, 'reg_alpha': 0.46693075893462804, 'reg_lambda': 0.2990093018161592}. Best is trial 4 with value: 0.7684330384725233.\n",
      "[I 2025-07-30 11:54:40,029] Trial 7 finished with value: 0.7577562517634853 and parameters: {'max_depth': 8, 'learning_rate': 0.044179668546195046, 'n_estimators': 880, 'subsample': 0.7117659546371442, 'colsample_bytree': 0.7408924199196576, 'min_child_weight': 4, 'gamma': 0.01428400941158694, 'reg_alpha': 0.29953156428635075, 'reg_lambda': 0.3420671787320401}. Best is trial 4 with value: 0.7684330384725233.\n",
      "[I 2025-07-30 11:55:30,627] Trial 8 finished with value: 0.7475312849845714 and parameters: {'max_depth': 6, 'learning_rate': 0.10000320286702286, 'n_estimators': 930, 'subsample': 0.757249607774262, 'colsample_bytree': 0.8907571607188829, 'min_child_weight': 1, 'gamma': 0.12247436905469491, 'reg_alpha': 0.4874656448432194, 'reg_lambda': 0.15277754528336945}. Best is trial 4 with value: 0.7684330384725233.\n",
      "[I 2025-07-30 11:56:02,744] Trial 9 finished with value: 0.751976750309487 and parameters: {'max_depth': 6, 'learning_rate': 0.12427051000312764, 'n_estimators': 601, 'subsample': 0.8965229802133957, 'colsample_bytree': 0.8445075502194398, 'min_child_weight': 2, 'gamma': 0.19855430200833005, 'reg_alpha': 0.2861639267459082, 'reg_lambda': 0.4300477971499829}. Best is trial 4 with value: 0.7684330384725233.\n",
      "[I 2025-07-30 11:56:27,768] Trial 10 finished with value: 0.7692784640327295 and parameters: {'max_depth': 4, 'learning_rate': 0.06541225746756227, 'n_estimators': 526, 'subsample': 0.8310045383515792, 'colsample_bytree': 0.7038785396333662, 'min_child_weight': 3, 'gamma': 0.0689533061657401, 'reg_alpha': 0.11199741146909337, 'reg_lambda': 0.1772614567194924}. Best is trial 10 with value: 0.7692784640327295.\n",
      "[I 2025-07-30 11:56:52,057] Trial 11 finished with value: 0.7691759906867807 and parameters: {'max_depth': 4, 'learning_rate': 0.06758188987813857, 'n_estimators': 511, 'subsample': 0.8308814360056977, 'colsample_bytree': 0.7005473708159575, 'min_child_weight': 3, 'gamma': 0.058837961511482156, 'reg_alpha': 0.10640467886789151, 'reg_lambda': 0.20024903857148052}. Best is trial 10 with value: 0.7692784640327295.\n",
      "[I 2025-07-30 11:57:25,050] Trial 12 finished with value: 0.7684221695054161 and parameters: {'max_depth': 4, 'learning_rate': 0.06985817574962574, 'n_estimators': 702, 'subsample': 0.8229849432897588, 'colsample_bytree': 0.7001165444068664, 'min_child_weight': 3, 'gamma': 0.06346571825005536, 'reg_alpha': 0.07735774145327057, 'reg_lambda': 0.17512647368741627}. Best is trial 10 with value: 0.7692784640327295.\n",
      "[I 2025-07-30 11:58:03,046] Trial 13 finished with value: 0.7670527624763713 and parameters: {'max_depth': 4, 'learning_rate': 0.08353153445078422, 'n_estimators': 778, 'subsample': 0.8067732742707676, 'colsample_bytree': 0.7003963944195433, 'min_child_weight': 4, 'gamma': 0.06887750623302324, 'reg_alpha': 0.1065403895430397, 'reg_lambda': 0.20006987997488213}. Best is trial 10 with value: 0.7692784640327295.\n",
      "[I 2025-07-30 11:58:28,902] Trial 14 finished with value: 0.7678502989881052 and parameters: {'max_depth': 5, 'learning_rate': 0.06435688164138098, 'n_estimators': 515, 'subsample': 0.8425215442396281, 'colsample_bytree': 0.7314852389515574, 'min_child_weight': 4, 'gamma': 0.0831708455723054, 'reg_alpha': 0.14090031666723937, 'reg_lambda': 0.04721455488497217}. Best is trial 10 with value: 0.7692784640327295.\n",
      "[I 2025-07-30 11:59:01,481] Trial 15 finished with value: 0.7668736733324187 and parameters: {'max_depth': 4, 'learning_rate': 0.023246591527892997, 'n_estimators': 677, 'subsample': 0.7803709852789849, 'colsample_bytree': 0.7339954101896793, 'min_child_weight': 2, 'gamma': 0.03777121725978795, 'reg_alpha': 0.01219195890750785, 'reg_lambda': 0.2159384443174337}. Best is trial 10 with value: 0.7692784640327295.\n",
      "[I 2025-07-30 11:59:42,954] Trial 16 finished with value: 0.7645108826535093 and parameters: {'max_depth': 5, 'learning_rate': 0.010341999480851294, 'n_estimators': 808, 'subsample': 0.7902789710075252, 'colsample_bytree': 0.7941347048154956, 'min_child_weight': 3, 'gamma': 0.15432305661336107, 'reg_alpha': 0.17730699089859484, 'reg_lambda': 0.10897511613791755}. Best is trial 10 with value: 0.7692784640327295.\n",
      "[I 2025-07-30 12:00:12,780] Trial 17 finished with value: 0.7637156696239581 and parameters: {'max_depth': 4, 'learning_rate': 0.12544587135125163, 'n_estimators': 633, 'subsample': 0.8334446241509367, 'colsample_bytree': 0.7208901468785834, 'min_child_weight': 3, 'gamma': 0.09438205586283571, 'reg_alpha': 0.06490940901582531, 'reg_lambda': 0.029745095283732426}. Best is trial 10 with value: 0.7692784640327295.\n",
      "[I 2025-07-30 12:01:09,745] Trial 18 finished with value: 0.754599218927916 and parameters: {'max_depth': 7, 'learning_rate': 0.062206879437050985, 'n_estimators': 1001, 'subsample': 0.8170767853850555, 'colsample_bytree': 0.7665965411688972, 'min_child_weight': 4, 'gamma': 0.04191109123961449, 'reg_alpha': 0.2275441985972615, 'reg_lambda': 0.2477512742004892}. Best is trial 10 with value: 0.7692784640327295.\n",
      "[I 2025-07-30 12:01:35,162] Trial 19 finished with value: 0.7641063108688376 and parameters: {'max_depth': 5, 'learning_rate': 0.0923200875702788, 'n_estimators': 509, 'subsample': 0.8548010750876429, 'colsample_bytree': 0.7170838091513793, 'min_child_weight': 2, 'gamma': 0.07953428381090874, 'reg_alpha': 0.13231570870217413, 'reg_lambda': 0.12244024967795711}. Best is trial 10 with value: 0.7692784640327295.\n",
      "Best params: {'max_depth': 4, 'learning_rate': 0.06541225746756227, 'n_estimators': 526, 'subsample': 0.8310045383515792, 'colsample_bytree': 0.7038785396333662, 'min_child_weight': 3, 'gamma': 0.0689533061657401, 'reg_alpha': 0.11199741146909337, 'reg_lambda': 0.1772614567194924}\n",
      "Best AUC: 0.7692784640327295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-30 12:01:40,815] A new study created in memory with name: no-name-35048322-dd94-43af-9a0a-1090fd76c86a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[XGB] Fold 4/5 done.\n",
      "[XGB] Optuna tuning fold 5/5...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db35a3c2c60c49d8bd9bb4d5fe5cee9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-30 12:02:18,124] Trial 0 finished with value: 0.7291859593838614 and parameters: {'max_depth': 8, 'learning_rate': 0.17711747723436974, 'n_estimators': 534, 'subsample': 0.7114371985057122, 'colsample_bytree': 0.8186012698535128, 'min_child_weight': 1, 'gamma': 0.09483324901494534, 'reg_alpha': 0.4376090216684165, 'reg_lambda': 0.490549177307321}. Best is trial 0 with value: 0.7291859593838614.\n",
      "[I 2025-07-30 12:03:13,380] Trial 1 finished with value: 0.7574816901120948 and parameters: {'max_depth': 5, 'learning_rate': 0.10110137897106967, 'n_estimators': 1117, 'subsample': 0.8199925403176247, 'colsample_bytree': 0.7371644844362216, 'min_child_weight': 3, 'gamma': 0.183029996615398, 'reg_alpha': 0.40055150519286453, 'reg_lambda': 0.23681889387539906}. Best is trial 1 with value: 0.7574816901120948.\n",
      "[I 2025-07-30 12:04:02,443] Trial 2 finished with value: 0.7304844749910157 and parameters: {'max_depth': 8, 'learning_rate': 0.1891779200986231, 'n_estimators': 741, 'subsample': 0.8435636998256464, 'colsample_bytree': 0.8734928543173799, 'min_child_weight': 3, 'gamma': 0.1326373989253032, 'reg_alpha': 0.47144937341152177, 'reg_lambda': 0.4598499978527641}. Best is trial 1 with value: 0.7574816901120948.\n",
      "[I 2025-07-30 12:04:38,034] Trial 3 finished with value: 0.7639466241537224 and parameters: {'max_depth': 4, 'learning_rate': 0.14297535911105386, 'n_estimators': 760, 'subsample': 0.8673610445602872, 'colsample_bytree': 0.7370487135401333, 'min_child_weight': 3, 'gamma': 0.14145836657989974, 'reg_alpha': 0.46926684003509983, 'reg_lambda': 0.4639383554461035}. Best is trial 3 with value: 0.7639466241537224.\n",
      "[I 2025-07-30 12:05:03,596] Trial 4 finished with value: 0.7679930012722277 and parameters: {'max_depth': 5, 'learning_rate': 0.07833597724189739, 'n_estimators': 509, 'subsample': 0.8157579894153726, 'colsample_bytree': 0.7878040336703475, 'min_child_weight': 3, 'gamma': 0.01574650443710357, 'reg_alpha': 0.25581569175297364, 'reg_lambda': 0.05968993802606809}. Best is trial 4 with value: 0.7679930012722277.\n",
      "[I 2025-07-30 12:06:05,798] Trial 5 finished with value: 0.7551929349202293 and parameters: {'max_depth': 5, 'learning_rate': 0.09897198813712435, 'n_estimators': 1260, 'subsample': 0.7943284557707173, 'colsample_bytree': 0.8483518473192312, 'min_child_weight': 1, 'gamma': 0.12236856691670361, 'reg_alpha': 0.4538542437790758, 'reg_lambda': 0.3113269086989016}. Best is trial 4 with value: 0.7679930012722277.\n",
      "[I 2025-07-30 12:07:10,816] Trial 6 finished with value: 0.7647070554198026 and parameters: {'max_depth': 4, 'learning_rate': 0.08126173960304234, 'n_estimators': 1405, 'subsample': 0.8197650328666761, 'colsample_bytree': 0.8670802912770018, 'min_child_weight': 3, 'gamma': 0.16177874847759965, 'reg_alpha': 0.1309381406793208, 'reg_lambda': 0.08406712809050104}. Best is trial 4 with value: 0.7679930012722277.\n",
      "[I 2025-07-30 12:08:40,876] Trial 7 finished with value: 0.7422780236899397 and parameters: {'max_depth': 8, 'learning_rate': 0.07525220960831155, 'n_estimators': 1383, 'subsample': 0.7146627341178784, 'colsample_bytree': 0.8924495181802006, 'min_child_weight': 3, 'gamma': 0.13472140849252257, 'reg_alpha': 0.25777397597656637, 'reg_lambda': 0.2757963783740255}. Best is trial 4 with value: 0.7679930012722277.\n",
      "[I 2025-07-30 12:09:20,901] Trial 8 finished with value: 0.7708106287009477 and parameters: {'max_depth': 4, 'learning_rate': 0.06361050353090889, 'n_estimators': 847, 'subsample': 0.7498911877673414, 'colsample_bytree': 0.7294528282316863, 'min_child_weight': 4, 'gamma': 0.13089785922423194, 'reg_alpha': 0.3343953743166042, 'reg_lambda': 0.3200021771769419}. Best is trial 8 with value: 0.7708106287009477.\n",
      "[I 2025-07-30 12:10:05,824] Trial 9 finished with value: 0.7535034143665863 and parameters: {'max_depth': 5, 'learning_rate': 0.12551737183268027, 'n_estimators': 900, 'subsample': 0.7051283709157837, 'colsample_bytree': 0.7593834055702682, 'min_child_weight': 3, 'gamma': 0.04362394132222383, 'reg_alpha': 0.2687745326502658, 'reg_lambda': 0.3481291459522561}. Best is trial 8 with value: 0.7708106287009477.\n",
      "[I 2025-07-30 12:11:03,832] Trial 10 finished with value: 0.7708628290662952 and parameters: {'max_depth': 7, 'learning_rate': 0.020146342025734808, 'n_estimators': 1003, 'subsample': 0.764060078172747, 'colsample_bytree': 0.703151570777038, 'min_child_weight': 5, 'gamma': 0.08149142013443471, 'reg_alpha': 0.02060875300298154, 'reg_lambda': 0.15728202774237252}. Best is trial 10 with value: 0.7708628290662952.\n",
      "[I 2025-07-30 12:12:02,512] Trial 11 finished with value: 0.7716821258887429 and parameters: {'max_depth': 7, 'learning_rate': 0.012610027316851168, 'n_estimators': 1001, 'subsample': 0.766883681248909, 'colsample_bytree': 0.7002574331012817, 'min_child_weight': 5, 'gamma': 0.0816871855543535, 'reg_alpha': 0.008311501619832988, 'reg_lambda': 0.16561955975564624}. Best is trial 11 with value: 0.7716821258887429.\n",
      "[I 2025-07-30 12:13:07,184] Trial 12 finished with value: 0.7717359684219635 and parameters: {'max_depth': 7, 'learning_rate': 0.011285608482807685, 'n_estimators': 1078, 'subsample': 0.7631090216575086, 'colsample_bytree': 0.700446255813952, 'min_child_weight': 5, 'gamma': 0.07653222544188593, 'reg_alpha': 0.000610549671711879, 'reg_lambda': 0.14937715444832403}. Best is trial 12 with value: 0.7717359684219635.\n",
      "[I 2025-07-30 12:14:15,031] Trial 13 finished with value: 0.7719666083448259 and parameters: {'max_depth': 7, 'learning_rate': 0.012157648680655494, 'n_estimators': 1154, 'subsample': 0.7650242415841106, 'colsample_bytree': 0.7014524660010972, 'min_child_weight': 5, 'gamma': 0.06285741275781255, 'reg_alpha': 0.004035928095890697, 'reg_lambda': 0.17201401988624196}. Best is trial 13 with value: 0.7719666083448259.\n",
      "[I 2025-07-30 12:15:22,416] Trial 14 finished with value: 0.7664069279432234 and parameters: {'max_depth': 7, 'learning_rate': 0.03124724309277106, 'n_estimators': 1184, 'subsample': 0.7405051250547023, 'colsample_bytree': 0.7808759570540927, 'min_child_weight': 5, 'gamma': 0.05067689571149683, 'reg_alpha': 0.10868756645283259, 'reg_lambda': 0.15032263575914934}. Best is trial 13 with value: 0.7719666083448259.\n",
      "[I 2025-07-30 12:16:29,469] Trial 15 finished with value: 0.7633732811291606 and parameters: {'max_depth': 6, 'learning_rate': 0.047832619470947434, 'n_estimators': 1279, 'subsample': 0.7881011339632479, 'colsample_bytree': 0.7170289351512896, 'min_child_weight': 4, 'gamma': 0.05387079389937931, 'reg_alpha': 0.11687224111196326, 'reg_lambda': 0.021873958593211312}. Best is trial 13 with value: 0.7719666083448259.\n",
      "[I 2025-07-30 12:17:48,286] Trial 16 finished with value: 0.7633606293896095 and parameters: {'max_depth': 6, 'learning_rate': 0.04254189041396058, 'n_estimators': 1492, 'subsample': 0.7408472804417849, 'colsample_bytree': 0.7699359470545957, 'min_child_weight': 4, 'gamma': 0.005532480759177463, 'reg_alpha': 0.06107327196616047, 'reg_lambda': 0.23863292474859424}. Best is trial 13 with value: 0.7719666083448259.\n",
      "[I 2025-07-30 12:18:48,838] Trial 17 finished with value: 0.7706195781491493 and parameters: {'max_depth': 6, 'learning_rate': 0.010308240344390271, 'n_estimators': 1099, 'subsample': 0.8872615746520404, 'colsample_bytree': 0.8136162649471765, 'min_child_weight': 2, 'gamma': 0.03155829186949249, 'reg_alpha': 0.16712311715536257, 'reg_lambda': 0.11373378191902633}. Best is trial 13 with value: 0.7719666083448259.\n",
      "[I 2025-07-30 12:19:52,991] Trial 18 finished with value: 0.7595585842737508 and parameters: {'max_depth': 7, 'learning_rate': 0.04953074104157416, 'n_estimators': 1133, 'subsample': 0.7770973861539844, 'colsample_bytree': 0.749582272199621, 'min_child_weight': 5, 'gamma': 0.06949313226483483, 'reg_alpha': 0.1917791809359337, 'reg_lambda': 0.21180644894296866}. Best is trial 13 with value: 0.7719666083448259.\n",
      "[I 2025-07-30 12:21:06,390] Trial 19 finished with value: 0.7305876420084457 and parameters: {'max_depth': 7, 'learning_rate': 0.1461470133937766, 'n_estimators': 1272, 'subsample': 0.7340151161407261, 'colsample_bytree': 0.7187994194858569, 'min_child_weight': 4, 'gamma': 0.10390193316340163, 'reg_alpha': 0.06405928793575079, 'reg_lambda': 0.0023465170691178983}. Best is trial 13 with value: 0.7719666083448259.\n",
      "Best params: {'max_depth': 7, 'learning_rate': 0.012157648680655494, 'n_estimators': 1154, 'subsample': 0.7650242415841106, 'colsample_bytree': 0.7014524660010972, 'min_child_weight': 5, 'gamma': 0.06285741275781255, 'reg_alpha': 0.004035928095890697, 'reg_lambda': 0.17201401988624196}\n",
      "Best AUC: 0.7719666083448259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-30 12:21:25,064] A new study created in memory with name: no-name-0183ae23-fe1a-4a04-8b77-4df96da64a47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[XGB] Fold 5/5 done.\n",
      "[XGB] OOF and test predictions generated for xgb.\n",
      "Running lgbm ...\n",
      "[LGBM] Optuna tuning fold 1/5...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29f0a729554e44ad917f6ecde348004d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's binary_logloss: 0.243919\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's binary_logloss: 0.245575\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[85]\tvalid_0's binary_logloss: 0.244765\n",
      "[I 2025-07-30 12:21:28,025] Trial 0 finished with value: 0.7638575234955454 and parameters: {'n_estimators': 945, 'learning_rate': 0.19397482397251656, 'max_depth': 8, 'num_leaves': 31, 'subsample': 0.8066238260819807, 'colsample_bytree': 0.8106107833359676, 'min_child_samples': 32, 'reg_alpha': 0.42206781863328213, 'reg_lambda': 0.18844920065411475}. Best is trial 0 with value: 0.7638575234955454.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[132]\tvalid_0's binary_logloss: 0.243219\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[111]\tvalid_0's binary_logloss: 0.244619\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[190]\tvalid_0's binary_logloss: 0.242598\n",
      "[I 2025-07-30 12:21:32,086] Trial 1 finished with value: 0.7672314426503103 and parameters: {'n_estimators': 254, 'learning_rate': 0.15085538612797295, 'max_depth': 5, 'num_leaves': 82, 'subsample': 0.7637333205573182, 'colsample_bytree': 0.7706920142509723, 'min_child_samples': 13, 'reg_alpha': 0.14798887705618324, 'reg_lambda': 0.2770195221789945}. Best is trial 1 with value: 0.7672314426503103.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[137]\tvalid_0's binary_logloss: 0.243255\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[97]\tvalid_0's binary_logloss: 0.245405\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's binary_logloss: 0.243492\n",
      "[I 2025-07-30 12:21:36,014] Trial 2 finished with value: 0.7656902627780187 and parameters: {'n_estimators': 725, 'learning_rate': 0.13427036852607924, 'max_depth': 6, 'num_leaves': 69, 'subsample': 0.7176562262517207, 'colsample_bytree': 0.7140561939032384, 'min_child_samples': 39, 'reg_alpha': 0.11049208075545747, 'reg_lambda': 0.15882226141401762}. Best is trial 1 with value: 0.7672314426503103.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[472]\tvalid_0's binary_logloss: 0.241793\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[340]\tvalid_0's binary_logloss: 0.243859\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[503]\tvalid_0's binary_logloss: 0.24205\n",
      "[I 2025-07-30 12:21:44,860] Trial 3 finished with value: 0.7700733782017789 and parameters: {'n_estimators': 934, 'learning_rate': 0.05790853169545227, 'max_depth': 5, 'num_leaves': 55, 'subsample': 0.7709206672235585, 'colsample_bytree': 0.7482329650347851, 'min_child_samples': 41, 'reg_alpha': 0.2345338008535613, 'reg_lambda': 0.4938867049996884}. Best is trial 3 with value: 0.7700733782017789.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[332]\tvalid_0's binary_logloss: 0.242727\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[290]\tvalid_0's binary_logloss: 0.244294\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[277]\tvalid_0's binary_logloss: 0.243017\n",
      "[I 2025-07-30 12:21:55,600] Trial 4 finished with value: 0.7681218597805378 and parameters: {'n_estimators': 782, 'learning_rate': 0.037088335413707284, 'max_depth': 10, 'num_leaves': 95, 'subsample': 0.7781169491052146, 'colsample_bytree': 0.7984631530869487, 'min_child_samples': 24, 'reg_alpha': 0.4927295413500223, 'reg_lambda': 0.26700820261934094}. Best is trial 3 with value: 0.7700733782017789.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's binary_logloss: 0.244468\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's binary_logloss: 0.246155\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\tvalid_0's binary_logloss: 0.245213\n",
      "[I 2025-07-30 12:21:58,291] Trial 5 finished with value: 0.7626810314784339 and parameters: {'n_estimators': 829, 'learning_rate': 0.18270980372455586, 'max_depth': 10, 'num_leaves': 42, 'subsample': 0.7196774392462316, 'colsample_bytree': 0.7026430699112621, 'min_child_samples': 16, 'reg_alpha': 0.4335239589620471, 'reg_lambda': 0.016728739424442696}. Best is trial 3 with value: 0.7700733782017789.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[201]\tvalid_0's binary_logloss: 0.242099\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[148]\tvalid_0's binary_logloss: 0.244318\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[212]\tvalid_0's binary_logloss: 0.242423\n",
      "[I 2025-07-30 12:22:02,464] Trial 6 finished with value: 0.7689005923597699 and parameters: {'n_estimators': 736, 'learning_rate': 0.15797091301963948, 'max_depth': 4, 'num_leaves': 99, 'subsample': 0.824927619932903, 'colsample_bytree': 0.864408643973666, 'min_child_samples': 43, 'reg_alpha': 0.4167991229329292, 'reg_lambda': 0.06142983350191439}. Best is trial 3 with value: 0.7700733782017789.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[119]\tvalid_0's binary_logloss: 0.242712\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[140]\tvalid_0's binary_logloss: 0.244662\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[165]\tvalid_0's binary_logloss: 0.243126\n",
      "[I 2025-07-30 12:22:06,347] Trial 7 finished with value: 0.7675873059637551 and parameters: {'n_estimators': 846, 'learning_rate': 0.15925215508540388, 'max_depth': 5, 'num_leaves': 57, 'subsample': 0.7186486015355026, 'colsample_bytree': 0.7164832097388995, 'min_child_samples': 45, 'reg_alpha': 0.11546624134905098, 'reg_lambda': 0.37477468374801864}. Best is trial 3 with value: 0.7700733782017789.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[174]\tvalid_0's binary_logloss: 0.243238\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[141]\tvalid_0's binary_logloss: 0.244857\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[143]\tvalid_0's binary_logloss: 0.242959\n",
      "[I 2025-07-30 12:22:11,781] Trial 8 finished with value: 0.7671303705498246 and parameters: {'n_estimators': 583, 'learning_rate': 0.08638451918559716, 'max_depth': 8, 'num_leaves': 60, 'subsample': 0.8426173859341454, 'colsample_bytree': 0.8788020181354113, 'min_child_samples': 26, 'reg_alpha': 0.07628350159678882, 'reg_lambda': 0.48476065308898797}. Best is trial 3 with value: 0.7700733782017789.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[175]\tvalid_0's binary_logloss: 0.2423\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[171]\tvalid_0's binary_logloss: 0.244498\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[203]\tvalid_0's binary_logloss: 0.242523\n",
      "[I 2025-07-30 12:22:16,478] Trial 9 finished with value: 0.7684927259452105 and parameters: {'n_estimators': 445, 'learning_rate': 0.12112352127191245, 'max_depth': 5, 'num_leaves': 75, 'subsample': 0.7769521319505062, 'colsample_bytree': 0.8506233493220355, 'min_child_samples': 47, 'reg_alpha': 0.31928868531772253, 'reg_lambda': 0.31665672386232285}. Best is trial 3 with value: 0.7700733782017789.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[981]\tvalid_0's binary_logloss: 0.242065\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[868]\tvalid_0's binary_logloss: 0.243883\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[978]\tvalid_0's binary_logloss: 0.242252\n",
      "[I 2025-07-30 12:22:42,688] Trial 10 finished with value: 0.7695733105431461 and parameters: {'n_estimators': 996, 'learning_rate': 0.013484501106403271, 'max_depth': 7, 'num_leaves': 127, 'subsample': 0.8766836903259494, 'colsample_bytree': 0.7553082319922017, 'min_child_samples': 35, 'reg_alpha': 0.23521047506795292, 'reg_lambda': 0.4619539957398784}. Best is trial 3 with value: 0.7700733782017789.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[940]\tvalid_0's binary_logloss: 0.242243\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[936]\tvalid_0's binary_logloss: 0.243994\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[940]\tvalid_0's binary_logloss: 0.242424\n",
      "[I 2025-07-30 12:23:08,999] Trial 11 finished with value: 0.7691084794608655 and parameters: {'n_estimators': 940, 'learning_rate': 0.01147690817217921, 'max_depth': 7, 'num_leaves': 126, 'subsample': 0.8969295606383949, 'colsample_bytree': 0.7598081135006537, 'min_child_samples': 35, 'reg_alpha': 0.2473725845090877, 'reg_lambda': 0.481925801907532}. Best is trial 3 with value: 0.7700733782017789.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[220]\tvalid_0's binary_logloss: 0.242703\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[184]\tvalid_0's binary_logloss: 0.244576\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[197]\tvalid_0's binary_logloss: 0.24308\n",
      "[I 2025-07-30 12:23:15,812] Trial 12 finished with value: 0.7675125853114023 and parameters: {'n_estimators': 987, 'learning_rate': 0.06729382607476213, 'max_depth': 7, 'num_leaves': 127, 'subsample': 0.8775514570559124, 'colsample_bytree': 0.7432716379020471, 'min_child_samples': 38, 'reg_alpha': 0.2333581128526111, 'reg_lambda': 0.40343660624049077}. Best is trial 3 with value: 0.7700733782017789.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[588]\tvalid_0's binary_logloss: 0.241892\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[582]\tvalid_0's binary_logloss: 0.244017\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[588]\tvalid_0's binary_logloss: 0.242466\n",
      "[I 2025-07-30 12:23:25,371] Trial 13 finished with value: 0.7694407933013978 and parameters: {'n_estimators': 588, 'learning_rate': 0.03963827069329527, 'max_depth': 4, 'num_leaves': 110, 'subsample': 0.8632857396686273, 'colsample_bytree': 0.7944883449534881, 'min_child_samples': 28, 'reg_alpha': 0.00038181348199972653, 'reg_lambda': 0.40633654133086927}. Best is trial 3 with value: 0.7700733782017789.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[997]\tvalid_0's binary_logloss: 0.241991\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[997]\tvalid_0's binary_logloss: 0.243812\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[997]\tvalid_0's binary_logloss: 0.242413\n",
      "[I 2025-07-30 12:23:50,676] Trial 14 finished with value: 0.769971828773186 and parameters: {'n_estimators': 997, 'learning_rate': 0.010605237365303324, 'max_depth': 8, 'num_leaves': 52, 'subsample': 0.7940808958254235, 'colsample_bytree': 0.7383366888749726, 'min_child_samples': 49, 'reg_alpha': 0.30836185551164125, 'reg_lambda': 0.49726431929519493}. Best is trial 3 with value: 0.7700733782017789.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[290]\tvalid_0's binary_logloss: 0.242216\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[202]\tvalid_0's binary_logloss: 0.244315\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[191]\tvalid_0's binary_logloss: 0.242829\n",
      "[I 2025-07-30 12:23:57,257] Trial 15 finished with value: 0.7687447755365243 and parameters: {'n_estimators': 437, 'learning_rate': 0.06197408024098185, 'max_depth': 9, 'num_leaves': 50, 'subsample': 0.7565277127451742, 'colsample_bytree': 0.7340843220121953, 'min_child_samples': 50, 'reg_alpha': 0.32414742732100654, 'reg_lambda': 0.35091916359914244}. Best is trial 3 with value: 0.7700733782017789.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[396]\tvalid_0's binary_logloss: 0.24181\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[324]\tvalid_0's binary_logloss: 0.243685\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[545]\tvalid_0's binary_logloss: 0.241981\n",
      "[I 2025-07-30 12:24:06,878] Trial 16 finished with value: 0.7704153945301222 and parameters: {'n_estimators': 873, 'learning_rate': 0.0452767494059857, 'max_depth': 6, 'num_leaves': 39, 'subsample': 0.8063766710458131, 'colsample_bytree': 0.7786307265897452, 'min_child_samples': 50, 'reg_alpha': 0.3241353991191997, 'reg_lambda': 0.4333915488816361}. Best is trial 16 with value: 0.7704153945301222.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[214]\tvalid_0's binary_logloss: 0.242131\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[176]\tvalid_0's binary_logloss: 0.244416\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[144]\tvalid_0's binary_logloss: 0.242829\n",
      "[I 2025-07-30 12:24:11,733] Trial 17 finished with value: 0.768493741785881 and parameters: {'n_estimators': 664, 'learning_rate': 0.09322913630481267, 'max_depth': 6, 'num_leaves': 31, 'subsample': 0.752041671225605, 'colsample_bytree': 0.8312176235327183, 'min_child_samples': 42, 'reg_alpha': 0.17804515226057274, 'reg_lambda': 0.43016612029471707}. Best is trial 16 with value: 0.7704153945301222.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[247]\tvalid_0's binary_logloss: 0.242332\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[307]\tvalid_0's binary_logloss: 0.243686\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[338]\tvalid_0's binary_logloss: 0.242128\n",
      "[I 2025-07-30 12:24:19,218] Trial 18 finished with value: 0.769754792284392 and parameters: {'n_estimators': 881, 'learning_rate': 0.05303190659055063, 'max_depth': 6, 'num_leaves': 42, 'subsample': 0.8207557276215465, 'colsample_bytree': 0.7796126311591295, 'min_child_samples': 41, 'reg_alpha': 0.36427900904651045, 'reg_lambda': 0.4335578626774024}. Best is trial 16 with value: 0.7704153945301222.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[373]\tvalid_0's binary_logloss: 0.24161\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[308]\tvalid_0's binary_logloss: 0.243871\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[454]\tvalid_0's binary_logloss: 0.242139\n",
      "[I 2025-07-30 12:24:25,936] Trial 19 finished with value: 0.7700952975142218 and parameters: {'n_estimators': 482, 'learning_rate': 0.08284761287583188, 'max_depth': 4, 'num_leaves': 42, 'subsample': 0.7398224857511573, 'colsample_bytree': 0.8156661027418619, 'min_child_samples': 19, 'reg_alpha': 0.1863270933237797, 'reg_lambda': 0.19872574798356923}. Best is trial 16 with value: 0.7704153945301222.\n",
      "Best params: {'n_estimators': 873, 'learning_rate': 0.0452767494059857, 'max_depth': 6, 'num_leaves': 39, 'subsample': 0.8063766710458131, 'colsample_bytree': 0.7786307265897452, 'min_child_samples': 50, 'reg_alpha': 0.3241353991191997, 'reg_lambda': 0.4333915488816361}\n",
      "Best AUC: 0.7704153945301222\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[382]\tvalid_0's binary_logloss: 0.242552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-30 12:24:29,961] A new study created in memory with name: no-name-e57080af-25ad-442c-8977-71da98243b5a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LGBM] Fold 1/5 done.\n",
      "[LGBM] Optuna tuning fold 2/5...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99b50d0ab7da43408c435ab7339d255c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[205]\tvalid_0's binary_logloss: 0.245134\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[207]\tvalid_0's binary_logloss: 0.242183\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[234]\tvalid_0's binary_logloss: 0.243834\n",
      "[I 2025-07-30 12:24:35,576] Trial 0 finished with value: 0.7663216283935682 and parameters: {'n_estimators': 439, 'learning_rate': 0.11049305589820835, 'max_depth': 5, 'num_leaves': 94, 'subsample': 0.7003332955674556, 'colsample_bytree': 0.8290334220338851, 'min_child_samples': 15, 'reg_alpha': 0.23742946495899886, 'reg_lambda': 0.46323087977717703}. Best is trial 0 with value: 0.7663216283935682.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[211]\tvalid_0's binary_logloss: 0.245326\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[241]\tvalid_0's binary_logloss: 0.242277\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[245]\tvalid_0's binary_logloss: 0.244253\n",
      "[I 2025-07-30 12:24:44,143] Trial 1 finished with value: 0.7658681075155127 and parameters: {'n_estimators': 998, 'learning_rate': 0.05221448259841987, 'max_depth': 9, 'num_leaves': 98, 'subsample': 0.8624665911153819, 'colsample_bytree': 0.7549769238755931, 'min_child_samples': 26, 'reg_alpha': 0.23826633416553727, 'reg_lambda': 0.24815290469915052}. Best is trial 0 with value: 0.7663216283935682.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[503]\tvalid_0's binary_logloss: 0.245234\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[503]\tvalid_0's binary_logloss: 0.24235\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[503]\tvalid_0's binary_logloss: 0.244214\n",
      "[I 2025-07-30 12:24:52,679] Trial 2 finished with value: 0.7656775392273727 and parameters: {'n_estimators': 503, 'learning_rate': 0.03306714223531886, 'max_depth': 4, 'num_leaves': 98, 'subsample': 0.7612734527016458, 'colsample_bytree': 0.7207091691167534, 'min_child_samples': 17, 'reg_alpha': 0.1428406130024722, 'reg_lambda': 0.16000515540903648}. Best is trial 0 with value: 0.7663216283935682.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[240]\tvalid_0's binary_logloss: 0.244742\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[279]\tvalid_0's binary_logloss: 0.241855\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[285]\tvalid_0's binary_logloss: 0.243642\n",
      "[I 2025-07-30 12:24:59,544] Trial 3 finished with value: 0.7669633957474685 and parameters: {'n_estimators': 777, 'learning_rate': 0.09511098322511, 'max_depth': 5, 'num_leaves': 115, 'subsample': 0.7372386485465601, 'colsample_bytree': 0.7864424405056856, 'min_child_samples': 15, 'reg_alpha': 0.4314409056161009, 'reg_lambda': 0.012270150010318837}. Best is trial 3 with value: 0.7669633957474685.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[908]\tvalid_0's binary_logloss: 0.244517\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[925]\tvalid_0's binary_logloss: 0.241347\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[925]\tvalid_0's binary_logloss: 0.243594\n",
      "[I 2025-07-30 12:25:25,567] Trial 4 finished with value: 0.7679204259352632 and parameters: {'n_estimators': 925, 'learning_rate': 0.012242084493280063, 'max_depth': 9, 'num_leaves': 74, 'subsample': 0.8058330801368443, 'colsample_bytree': 0.7037227804020092, 'min_child_samples': 36, 'reg_alpha': 0.07145940496765985, 'reg_lambda': 0.29799870176952065}. Best is trial 4 with value: 0.7679204259352632.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[114]\tvalid_0's binary_logloss: 0.245244\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[140]\tvalid_0's binary_logloss: 0.242445\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[122]\tvalid_0's binary_logloss: 0.244171\n",
      "[I 2025-07-30 12:25:29,787] Trial 5 finished with value: 0.76541949878004 and parameters: {'n_estimators': 770, 'learning_rate': 0.10955278122317998, 'max_depth': 6, 'num_leaves': 70, 'subsample': 0.8150867476347726, 'colsample_bytree': 0.7227717065469432, 'min_child_samples': 40, 'reg_alpha': 0.34705930971280463, 'reg_lambda': 0.38899623372666936}. Best is trial 4 with value: 0.7679204259352632.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[144]\tvalid_0's binary_logloss: 0.245619\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[102]\tvalid_0's binary_logloss: 0.24309\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[126]\tvalid_0's binary_logloss: 0.244622\n",
      "[I 2025-07-30 12:25:33,483] Trial 6 finished with value: 0.7646693369912697 and parameters: {'n_estimators': 578, 'learning_rate': 0.18002686710688878, 'max_depth': 5, 'num_leaves': 118, 'subsample': 0.7420373841954416, 'colsample_bytree': 0.8550532722184117, 'min_child_samples': 39, 'reg_alpha': 0.20971777221411464, 'reg_lambda': 0.22858755937804998}. Best is trial 4 with value: 0.7679204259352632.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[395]\tvalid_0's binary_logloss: 0.24413\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[463]\tvalid_0's binary_logloss: 0.241398\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[392]\tvalid_0's binary_logloss: 0.242868\n",
      "[I 2025-07-30 12:25:40,837] Trial 7 finished with value: 0.769158319931814 and parameters: {'n_estimators': 794, 'learning_rate': 0.08170399857404072, 'max_depth': 4, 'num_leaves': 121, 'subsample': 0.780711873829298, 'colsample_bytree': 0.8196604241471779, 'min_child_samples': 41, 'reg_alpha': 0.2531871395418918, 'reg_lambda': 0.22083652003444393}. Best is trial 7 with value: 0.769158319931814.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[261]\tvalid_0's binary_logloss: 0.24486\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[245]\tvalid_0's binary_logloss: 0.241885\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[260]\tvalid_0's binary_logloss: 0.243677\n",
      "[I 2025-07-30 12:25:45,723] Trial 8 finished with value: 0.7671679136121242 and parameters: {'n_estimators': 261, 'learning_rate': 0.10013229778350057, 'max_depth': 4, 'num_leaves': 120, 'subsample': 0.791610563043307, 'colsample_bytree': 0.8424675844680846, 'min_child_samples': 23, 'reg_alpha': 0.3546479810094451, 'reg_lambda': 0.2189239556172185}. Best is trial 7 with value: 0.769158319931814.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[614]\tvalid_0's binary_logloss: 0.24474\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[569]\tvalid_0's binary_logloss: 0.241713\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[647]\tvalid_0's binary_logloss: 0.243543\n",
      "[I 2025-07-30 12:26:02,790] Trial 9 finished with value: 0.7674917643460981 and parameters: {'n_estimators': 942, 'learning_rate': 0.02133045091699598, 'max_depth': 8, 'num_leaves': 58, 'subsample': 0.7052320544954578, 'colsample_bytree': 0.8860464837699812, 'min_child_samples': 30, 'reg_alpha': 0.1967028876816883, 'reg_lambda': 0.15482047507566482}. Best is trial 7 with value: 0.769158319931814.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's binary_logloss: 0.246215\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[89]\tvalid_0's binary_logloss: 0.243151\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's binary_logloss: 0.245067\n",
      "[I 2025-07-30 12:26:06,411] Trial 10 finished with value: 0.7632494799734939 and parameters: {'n_estimators': 720, 'learning_rate': 0.16208842596357587, 'max_depth': 7, 'num_leaves': 39, 'subsample': 0.8992060595242748, 'colsample_bytree': 0.7973561234162414, 'min_child_samples': 50, 'reg_alpha': 0.006250481950120457, 'reg_lambda': 0.04154841767578782}. Best is trial 7 with value: 0.769158319931814.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[195]\tvalid_0's binary_logloss: 0.245329\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[195]\tvalid_0's binary_logloss: 0.242358\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[197]\tvalid_0's binary_logloss: 0.244486\n",
      "[I 2025-07-30 12:26:13,348] Trial 11 finished with value: 0.7653950409322282 and parameters: {'n_estimators': 863, 'learning_rate': 0.06252181588289102, 'max_depth': 10, 'num_leaves': 77, 'subsample': 0.8142769054321407, 'colsample_bytree': 0.7618031552310469, 'min_child_samples': 40, 'reg_alpha': 0.06826034446512197, 'reg_lambda': 0.32674807349672896}. Best is trial 7 with value: 0.769158319931814.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's binary_logloss: 0.246097\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[80]\tvalid_0's binary_logloss: 0.243212\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[94]\tvalid_0's binary_logloss: 0.244846\n",
      "[I 2025-07-30 12:26:17,009] Trial 12 finished with value: 0.7637570651458984 and parameters: {'n_estimators': 852, 'learning_rate': 0.14216373791116477, 'max_depth': 8, 'num_leaves': 53, 'subsample': 0.7778750147793396, 'colsample_bytree': 0.7000887159820295, 'min_child_samples': 48, 'reg_alpha': 0.11276135493324058, 'reg_lambda': 0.33529252569864987}. Best is trial 7 with value: 0.769158319931814.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[633]\tvalid_0's binary_logloss: 0.244758\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[633]\tvalid_0's binary_logloss: 0.241992\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[633]\tvalid_0's binary_logloss: 0.244171\n",
      "[I 2025-07-30 12:26:38,424] Trial 13 finished with value: 0.7664858071074415 and parameters: {'n_estimators': 633, 'learning_rate': 0.011891691391130235, 'max_depth': 10, 'num_leaves': 87, 'subsample': 0.8421734821583058, 'colsample_bytree': 0.8165822342353665, 'min_child_samples': 36, 'reg_alpha': 0.3247139286833821, 'reg_lambda': 0.13295588221621785}. Best is trial 7 with value: 0.769158319931814.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[216]\tvalid_0's binary_logloss: 0.245408\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[226]\tvalid_0's binary_logloss: 0.242308\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[233]\tvalid_0's binary_logloss: 0.244219\n",
      "[I 2025-07-30 12:26:45,548] Trial 14 finished with value: 0.7657933573163986 and parameters: {'n_estimators': 895, 'learning_rate': 0.07187256180483897, 'max_depth': 7, 'num_leaves': 65, 'subsample': 0.841519401137302, 'colsample_bytree': 0.8721330830535882, 'min_child_samples': 33, 'reg_alpha': 0.49477157702120567, 'reg_lambda': 0.327316464780264}. Best is trial 7 with value: 0.769158319931814.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[275]\tvalid_0's binary_logloss: 0.244942\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[281]\tvalid_0's binary_logloss: 0.242068\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[266]\tvalid_0's binary_logloss: 0.244067\n",
      "[I 2025-07-30 12:26:56,008] Trial 15 finished with value: 0.7662014672597949 and parameters: {'n_estimators': 657, 'learning_rate': 0.03675766827044513, 'max_depth': 9, 'num_leaves': 106, 'subsample': 0.7647651714894572, 'colsample_bytree': 0.7646839909275804, 'min_child_samples': 45, 'reg_alpha': 0.0007712495477956716, 'reg_lambda': 0.4069429142652657}. Best is trial 7 with value: 0.769158319931814.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[113]\tvalid_0's binary_logloss: 0.24586\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[156]\tvalid_0's binary_logloss: 0.242981\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[139]\tvalid_0's binary_logloss: 0.245437\n",
      "[I 2025-07-30 12:27:02,785] Trial 16 finished with value: 0.763387965122425 and parameters: {'n_estimators': 996, 'learning_rate': 0.0783669530852883, 'max_depth': 8, 'num_leaves': 127, 'subsample': 0.8060944857110793, 'colsample_bytree': 0.8127324061492415, 'min_child_samples': 44, 'reg_alpha': 0.1618941008193829, 'reg_lambda': 0.08611990463254604}. Best is trial 7 with value: 0.769158319931814.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[136]\tvalid_0's binary_logloss: 0.245622\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[106]\tvalid_0's binary_logloss: 0.243146\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[128]\tvalid_0's binary_logloss: 0.244503\n",
      "[I 2025-07-30 12:27:07,107] Trial 17 finished with value: 0.7641560013924996 and parameters: {'n_estimators': 789, 'learning_rate': 0.13454943626754837, 'max_depth': 6, 'num_leaves': 81, 'subsample': 0.8359707427210966, 'colsample_bytree': 0.7794745785447501, 'min_child_samples': 30, 'reg_alpha': 0.2928052172645229, 'reg_lambda': 0.28771165487214023}. Best is trial 7 with value: 0.769158319931814.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[339]\tvalid_0's binary_logloss: 0.245003\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[234]\tvalid_0's binary_logloss: 0.242218\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[293]\tvalid_0's binary_logloss: 0.24405\n",
      "[I 2025-07-30 12:27:14,342] Trial 18 finished with value: 0.7660914156280597 and parameters: {'n_estimators': 351, 'learning_rate': 0.05119926366910873, 'max_depth': 9, 'num_leaves': 33, 'subsample': 0.7884673480192204, 'colsample_bytree': 0.8996457691664366, 'min_child_samples': 23, 'reg_alpha': 0.07679041278008285, 'reg_lambda': 0.1957574249197643}. Best is trial 7 with value: 0.769158319931814.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[90]\tvalid_0's binary_logloss: 0.245823\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[122]\tvalid_0's binary_logloss: 0.242745\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[113]\tvalid_0's binary_logloss: 0.244319\n",
      "[I 2025-07-30 12:27:18,301] Trial 19 finished with value: 0.7648206201619421 and parameters: {'n_estimators': 672, 'learning_rate': 0.1357746767937428, 'max_depth': 6, 'num_leaves': 50, 'subsample': 0.8744254535541924, 'colsample_bytree': 0.7359248451473946, 'min_child_samples': 10, 'reg_alpha': 0.41297051890966463, 'reg_lambda': 0.2729838743057597}. Best is trial 7 with value: 0.769158319931814.\n",
      "Best params: {'n_estimators': 794, 'learning_rate': 0.08170399857404072, 'max_depth': 4, 'num_leaves': 121, 'subsample': 0.780711873829298, 'colsample_bytree': 0.8196604241471779, 'min_child_samples': 41, 'reg_alpha': 0.2531871395418918, 'reg_lambda': 0.22083652003444393}\n",
      "Best AUC: 0.769158319931814\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[474]\tvalid_0's binary_logloss: 0.239561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-30 12:27:21,958] A new study created in memory with name: no-name-526b24fd-9488-4044-ae04-87ca9cd72f6b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LGBM] Fold 2/5 done.\n",
      "[LGBM] Optuna tuning fold 3/5...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b610c301347420d892a04436c8c9f69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[205]\tvalid_0's binary_logloss: 0.242475\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[160]\tvalid_0's binary_logloss: 0.24353\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[223]\tvalid_0's binary_logloss: 0.242576\n",
      "[I 2025-07-30 12:27:26,934] Trial 0 finished with value: 0.7696574588106424 and parameters: {'n_estimators': 245, 'learning_rate': 0.1167299307609474, 'max_depth': 5, 'num_leaves': 122, 'subsample': 0.7745593045362352, 'colsample_bytree': 0.749192927942734, 'min_child_samples': 41, 'reg_alpha': 0.319148356049288, 'reg_lambda': 0.35706347563719043}. Best is trial 0 with value: 0.7696574588106424.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[84]\tvalid_0's binary_logloss: 0.244134\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[84]\tvalid_0's binary_logloss: 0.244785\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[101]\tvalid_0's binary_logloss: 0.244079\n",
      "[I 2025-07-30 12:27:30,435] Trial 1 finished with value: 0.7653989484701816 and parameters: {'n_estimators': 734, 'learning_rate': 0.1716819382732921, 'max_depth': 6, 'num_leaves': 114, 'subsample': 0.7501422187032057, 'colsample_bytree': 0.7558823740419877, 'min_child_samples': 19, 'reg_alpha': 0.02307977502687225, 'reg_lambda': 0.4010063912207964}. Best is trial 0 with value: 0.7696574588106424.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's binary_logloss: 0.245854\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's binary_logloss: 0.24584\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\tvalid_0's binary_logloss: 0.244595\n",
      "[I 2025-07-30 12:27:33,361] Trial 2 finished with value: 0.7620336759235506 and parameters: {'n_estimators': 881, 'learning_rate': 0.19336802477279313, 'max_depth': 7, 'num_leaves': 77, 'subsample': 0.7626114419016755, 'colsample_bytree': 0.8400445805722939, 'min_child_samples': 44, 'reg_alpha': 0.16857305598484734, 'reg_lambda': 0.04839032795276821}. Best is trial 0 with value: 0.7696574588106424.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[491]\tvalid_0's binary_logloss: 0.241909\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[569]\tvalid_0's binary_logloss: 0.242594\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[540]\tvalid_0's binary_logloss: 0.242103\n",
      "[I 2025-07-30 12:27:46,433] Trial 3 finished with value: 0.771398360482573 and parameters: {'n_estimators': 760, 'learning_rate': 0.032239546880690785, 'max_depth': 6, 'num_leaves': 118, 'subsample': 0.8317163311598493, 'colsample_bytree': 0.7813979367850556, 'min_child_samples': 25, 'reg_alpha': 0.4220241026932634, 'reg_lambda': 0.20126256050416885}. Best is trial 3 with value: 0.771398360482573.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's binary_logloss: 0.244516\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's binary_logloss: 0.245052\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's binary_logloss: 0.244412\n",
      "[I 2025-07-30 12:27:50,369] Trial 4 finished with value: 0.7647150030848175 and parameters: {'n_estimators': 518, 'learning_rate': 0.13317888040188638, 'max_depth': 10, 'num_leaves': 108, 'subsample': 0.7280663247273388, 'colsample_bytree': 0.8472607249202424, 'min_child_samples': 46, 'reg_alpha': 0.4200757689842701, 'reg_lambda': 0.4987467474371642}. Best is trial 3 with value: 0.771398360482573.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[107]\tvalid_0's binary_logloss: 0.243856\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[122]\tvalid_0's binary_logloss: 0.244012\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[149]\tvalid_0's binary_logloss: 0.243777\n",
      "[I 2025-07-30 12:27:54,456] Trial 5 finished with value: 0.7668228686594736 and parameters: {'n_estimators': 283, 'learning_rate': 0.11012871986561495, 'max_depth': 10, 'num_leaves': 42, 'subsample': 0.8931619035926341, 'colsample_bytree': 0.7067938144266718, 'min_child_samples': 10, 'reg_alpha': 0.05512103249537731, 'reg_lambda': 0.13367061873401903}. Best is trial 3 with value: 0.771398360482573.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's binary_logloss: 0.244629\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\tvalid_0's binary_logloss: 0.245124\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\tvalid_0's binary_logloss: 0.245181\n",
      "[I 2025-07-30 12:27:57,272] Trial 6 finished with value: 0.7628769005713542 and parameters: {'n_estimators': 716, 'learning_rate': 0.19706178291450144, 'max_depth': 7, 'num_leaves': 64, 'subsample': 0.7966404514228029, 'colsample_bytree': 0.7252104592054343, 'min_child_samples': 47, 'reg_alpha': 0.25626799085466795, 'reg_lambda': 0.049558891336035804}. Best is trial 3 with value: 0.771398360482573.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[151]\tvalid_0's binary_logloss: 0.242823\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[166]\tvalid_0's binary_logloss: 0.243361\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[237]\tvalid_0's binary_logloss: 0.24243\n",
      "[I 2025-07-30 12:28:01,928] Trial 7 finished with value: 0.7696329555418767 and parameters: {'n_estimators': 514, 'learning_rate': 0.11774615157015987, 'max_depth': 5, 'num_leaves': 68, 'subsample': 0.8867527914804653, 'colsample_bytree': 0.7200319059810555, 'min_child_samples': 20, 'reg_alpha': 0.29928294495470414, 'reg_lambda': 0.149684733263299}. Best is trial 3 with value: 0.771398360482573.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[182]\tvalid_0's binary_logloss: 0.242828\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[178]\tvalid_0's binary_logloss: 0.24363\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[200]\tvalid_0's binary_logloss: 0.242353\n",
      "[I 2025-07-30 12:28:07,253] Trial 8 finished with value: 0.7691557516440483 and parameters: {'n_estimators': 526, 'learning_rate': 0.08079110952634525, 'max_depth': 6, 'num_leaves': 40, 'subsample': 0.7835116127132886, 'colsample_bytree': 0.8163438152797734, 'min_child_samples': 20, 'reg_alpha': 0.35436587739180087, 'reg_lambda': 0.1696874975039659}. Best is trial 3 with value: 0.771398360482573.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[143]\tvalid_0's binary_logloss: 0.242867\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[145]\tvalid_0's binary_logloss: 0.243619\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[152]\tvalid_0's binary_logloss: 0.243172\n",
      "[I 2025-07-30 12:28:11,962] Trial 9 finished with value: 0.7685086393125918 and parameters: {'n_estimators': 327, 'learning_rate': 0.10285467477817002, 'max_depth': 6, 'num_leaves': 75, 'subsample': 0.8160688137574964, 'colsample_bytree': 0.7633176411158553, 'min_child_samples': 11, 'reg_alpha': 0.167105532030968, 'reg_lambda': 0.4670401469308578}. Best is trial 3 with value: 0.771398360482573.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[893]\tvalid_0's binary_logloss: 0.242398\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[891]\tvalid_0's binary_logloss: 0.242983\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[889]\tvalid_0's binary_logloss: 0.242269\n",
      "[I 2025-07-30 12:28:40,667] Trial 10 finished with value: 0.770278444074228 and parameters: {'n_estimators': 893, 'learning_rate': 0.011233433147746701, 'max_depth': 8, 'num_leaves': 94, 'subsample': 0.84409768899587, 'colsample_bytree': 0.8863398669965379, 'min_child_samples': 34, 'reg_alpha': 0.4984760199243206, 'reg_lambda': 0.2598648117320748}. Best is trial 3 with value: 0.771398360482573.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[648]\tvalid_0's binary_logloss: 0.242346\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[585]\tvalid_0's binary_logloss: 0.242914\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[497]\tvalid_0's binary_logloss: 0.242357\n",
      "[I 2025-07-30 12:29:00,425] Trial 11 finished with value: 0.7703428062339831 and parameters: {'n_estimators': 976, 'learning_rate': 0.019744117031580757, 'max_depth': 8, 'num_leaves': 99, 'subsample': 0.8456061479073699, 'colsample_bytree': 0.8921593496363618, 'min_child_samples': 34, 'reg_alpha': 0.49589611924090626, 'reg_lambda': 0.2740481623151162}. Best is trial 3 with value: 0.771398360482573.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[983]\tvalid_0's binary_logloss: 0.241979\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[979]\tvalid_0's binary_logloss: 0.242833\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[978]\tvalid_0's binary_logloss: 0.242071\n",
      "[I 2025-07-30 12:29:30,668] Trial 12 finished with value: 0.7711675625883045 and parameters: {'n_estimators': 983, 'learning_rate': 0.01144396228959095, 'max_depth': 8, 'num_leaves': 97, 'subsample': 0.845388340903788, 'colsample_bytree': 0.7935970048469784, 'min_child_samples': 30, 'reg_alpha': 0.4938762708751398, 'reg_lambda': 0.26503799121414895}. Best is trial 3 with value: 0.771398360482573.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[570]\tvalid_0's binary_logloss: 0.242073\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[717]\tvalid_0's binary_logloss: 0.242427\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[660]\tvalid_0's binary_logloss: 0.241855\n",
      "[I 2025-07-30 12:29:41,518] Trial 13 finished with value: 0.7717347928208014 and parameters: {'n_estimators': 767, 'learning_rate': 0.04869503198138686, 'max_depth': 4, 'num_leaves': 126, 'subsample': 0.8330292965437939, 'colsample_bytree': 0.7893540304182325, 'min_child_samples': 27, 'reg_alpha': 0.4250210485619875, 'reg_lambda': 0.3223895169710969}. Best is trial 13 with value: 0.7717347928208014.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[568]\tvalid_0's binary_logloss: 0.242077\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[706]\tvalid_0's binary_logloss: 0.242441\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[709]\tvalid_0's binary_logloss: 0.241843\n",
      "[I 2025-07-30 12:29:52,283] Trial 14 finished with value: 0.7717636484856875 and parameters: {'n_estimators': 713, 'learning_rate': 0.05136184357869582, 'max_depth': 4, 'num_leaves': 125, 'subsample': 0.8195986357420321, 'colsample_bytree': 0.7904332599189521, 'min_child_samples': 27, 'reg_alpha': 0.3907484302056558, 'reg_lambda': 0.32571575173481027}. Best is trial 14 with value: 0.7717636484856875.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[555]\tvalid_0's binary_logloss: 0.241897\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[510]\tvalid_0's binary_logloss: 0.242541\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[619]\tvalid_0's binary_logloss: 0.241857\n",
      "[I 2025-07-30 12:30:01,729] Trial 15 finished with value: 0.7717136760849286 and parameters: {'n_estimators': 646, 'learning_rate': 0.054818674592790606, 'max_depth': 4, 'num_leaves': 124, 'subsample': 0.8706911460119537, 'colsample_bytree': 0.8190953945493853, 'min_child_samples': 27, 'reg_alpha': 0.4001216182682715, 'reg_lambda': 0.35123951389290153}. Best is trial 14 with value: 0.7717636484856875.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[556]\tvalid_0's binary_logloss: 0.242095\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[724]\tvalid_0's binary_logloss: 0.242165\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[624]\tvalid_0's binary_logloss: 0.241597\n",
      "[I 2025-07-30 12:30:12,145] Trial 16 finished with value: 0.7723010485066532 and parameters: {'n_estimators': 827, 'learning_rate': 0.058391042508767844, 'max_depth': 4, 'num_leaves': 106, 'subsample': 0.8130779672516287, 'colsample_bytree': 0.7739543025326556, 'min_child_samples': 37, 'reg_alpha': 0.3668273391121709, 'reg_lambda': 0.32573462605295267}. Best is trial 16 with value: 0.7723010485066532.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[368]\tvalid_0's binary_logloss: 0.242249\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[350]\tvalid_0's binary_logloss: 0.242613\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[423]\tvalid_0's binary_logloss: 0.241856\n",
      "[I 2025-07-30 12:30:19,113] Trial 17 finished with value: 0.7711147573895184 and parameters: {'n_estimators': 852, 'learning_rate': 0.078265438541038, 'max_depth': 4, 'num_leaves': 107, 'subsample': 0.7029847869214432, 'colsample_bytree': 0.7742906751481319, 'min_child_samples': 39, 'reg_alpha': 0.19705046133500792, 'reg_lambda': 0.4280976919274914}. Best is trial 16 with value: 0.7723010485066532.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[319]\tvalid_0's binary_logloss: 0.242176\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[321]\tvalid_0's binary_logloss: 0.242959\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[375]\tvalid_0's binary_logloss: 0.242037\n",
      "[I 2025-07-30 12:30:26,555] Trial 18 finished with value: 0.7709345156888584 and parameters: {'n_estimators': 411, 'learning_rate': 0.0735564472153569, 'max_depth': 5, 'num_leaves': 88, 'subsample': 0.8093880308869194, 'colsample_bytree': 0.8188659425897635, 'min_child_samples': 36, 'reg_alpha': 0.35965734180865866, 'reg_lambda': 0.30541927556372017}. Best is trial 16 with value: 0.7723010485066532.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[580]\tvalid_0's binary_logloss: 0.242169\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[629]\tvalid_0's binary_logloss: 0.242379\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[626]\tvalid_0's binary_logloss: 0.24183\n",
      "[I 2025-07-30 12:30:36,794] Trial 19 finished with value: 0.7716975062253092 and parameters: {'n_estimators': 629, 'learning_rate': 0.04612997051413929, 'max_depth': 4, 'num_leaves': 107, 'subsample': 0.8626715960851792, 'colsample_bytree': 0.8499143176705888, 'min_child_samples': 32, 'reg_alpha': 0.2563763949410386, 'reg_lambda': 0.21569701511256656}. Best is trial 16 with value: 0.7723010485066532.\n",
      "Best params: {'n_estimators': 827, 'learning_rate': 0.058391042508767844, 'max_depth': 4, 'num_leaves': 106, 'subsample': 0.8130779672516287, 'colsample_bytree': 0.7739543025326556, 'min_child_samples': 37, 'reg_alpha': 0.3668273391121709, 'reg_lambda': 0.32573462605295267}\n",
      "Best AUC: 0.7723010485066532\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[559]\tvalid_0's binary_logloss: 0.242478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-30 12:30:41,077] A new study created in memory with name: no-name-60917197-987e-470a-b7ad-e31c82faa2f3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LGBM] Fold 3/5 done.\n",
      "[LGBM] Optuna tuning fold 4/5...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d56fafdb15fc47f2b8676e06478ded35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[242]\tvalid_0's binary_logloss: 0.243511\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[203]\tvalid_0's binary_logloss: 0.243407\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[242]\tvalid_0's binary_logloss: 0.242919\n",
      "[I 2025-07-30 12:30:45,872] Trial 0 finished with value: 0.7677477307925171 and parameters: {'n_estimators': 686, 'learning_rate': 0.13186183852880767, 'max_depth': 4, 'num_leaves': 83, 'subsample': 0.7165846829582958, 'colsample_bytree': 0.7522641494884817, 'min_child_samples': 30, 'reg_alpha': 0.20933153856027914, 'reg_lambda': 0.22711806825351766}. Best is trial 0 with value: 0.7677477307925171.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[608]\tvalid_0's binary_logloss: 0.243476\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[722]\tvalid_0's binary_logloss: 0.242772\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[684]\tvalid_0's binary_logloss: 0.242554\n",
      "[I 2025-07-30 12:30:57,196] Trial 1 finished with value: 0.7688693932357699 and parameters: {'n_estimators': 959, 'learning_rate': 0.04265466294020539, 'max_depth': 4, 'num_leaves': 72, 'subsample': 0.8808116129729593, 'colsample_bytree': 0.8595005463879315, 'min_child_samples': 24, 'reg_alpha': 0.06419422141278719, 'reg_lambda': 0.07185818297692931}. Best is trial 1 with value: 0.7688693932357699.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[170]\tvalid_0's binary_logloss: 0.244804\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[142]\tvalid_0's binary_logloss: 0.244187\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[175]\tvalid_0's binary_logloss: 0.244176\n",
      "[I 2025-07-30 12:31:03,862] Trial 2 finished with value: 0.7644153309933793 and parameters: {'n_estimators': 800, 'learning_rate': 0.06581263106055234, 'max_depth': 8, 'num_leaves': 120, 'subsample': 0.7040164435930503, 'colsample_bytree': 0.7161875283144158, 'min_child_samples': 19, 'reg_alpha': 0.02497645705880952, 'reg_lambda': 0.2552684820534366}. Best is trial 1 with value: 0.7688693932357699.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[328]\tvalid_0's binary_logloss: 0.243868\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[399]\tvalid_0's binary_logloss: 0.243345\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[454]\tvalid_0's binary_logloss: 0.243064\n",
      "[I 2025-07-30 12:31:15,050] Trial 3 finished with value: 0.7674967653267232 and parameters: {'n_estimators': 874, 'learning_rate': 0.0379157951339483, 'max_depth': 9, 'num_leaves': 61, 'subsample': 0.8438661762688338, 'colsample_bytree': 0.8070477305476025, 'min_child_samples': 42, 'reg_alpha': 0.07324695071118514, 'reg_lambda': 0.0037172100597192004}. Best is trial 1 with value: 0.7688693932357699.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's binary_logloss: 0.245531\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[75]\tvalid_0's binary_logloss: 0.245145\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[96]\tvalid_0's binary_logloss: 0.2444\n",
      "[I 2025-07-30 12:31:18,847] Trial 4 finished with value: 0.762281433868447 and parameters: {'n_estimators': 874, 'learning_rate': 0.13416223480873138, 'max_depth': 7, 'num_leaves': 73, 'subsample': 0.8535351618855174, 'colsample_bytree': 0.7010742800207033, 'min_child_samples': 30, 'reg_alpha': 0.2849274369640424, 'reg_lambda': 0.003928066185481971}. Best is trial 1 with value: 0.7688693932357699.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[312]\tvalid_0's binary_logloss: 0.244081\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[276]\tvalid_0's binary_logloss: 0.243965\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[230]\tvalid_0's binary_logloss: 0.243501\n",
      "[I 2025-07-30 12:31:27,752] Trial 5 finished with value: 0.7658210868088077 and parameters: {'n_estimators': 686, 'learning_rate': 0.050376148406354265, 'max_depth': 7, 'num_leaves': 114, 'subsample': 0.8564141155157516, 'colsample_bytree': 0.8620588138279643, 'min_child_samples': 36, 'reg_alpha': 0.26721246404418725, 'reg_lambda': 0.287726959448767}. Best is trial 1 with value: 0.7688693932357699.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[632]\tvalid_0's binary_logloss: 0.243211\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[523]\tvalid_0's binary_logloss: 0.243117\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[603]\tvalid_0's binary_logloss: 0.242745\n",
      "[I 2025-07-30 12:31:40,009] Trial 6 finished with value: 0.7686350718777913 and parameters: {'n_estimators': 944, 'learning_rate': 0.033371570598101044, 'max_depth': 9, 'num_leaves': 32, 'subsample': 0.8378915220108805, 'colsample_bytree': 0.7217075327936637, 'min_child_samples': 43, 'reg_alpha': 0.36690272316109573, 'reg_lambda': 0.4440871679821938}. Best is trial 1 with value: 0.7688693932357699.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's binary_logloss: 0.246008\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[58]\tvalid_0's binary_logloss: 0.244978\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[92]\tvalid_0's binary_logloss: 0.244794\n",
      "[I 2025-07-30 12:31:43,107] Trial 7 finished with value: 0.7620377891917073 and parameters: {'n_estimators': 517, 'learning_rate': 0.19294335690119258, 'max_depth': 6, 'num_leaves': 114, 'subsample': 0.8513146452049344, 'colsample_bytree': 0.7818448298721563, 'min_child_samples': 32, 'reg_alpha': 0.23337185803688254, 'reg_lambda': 0.13764387640212045}. Best is trial 1 with value: 0.7688693932357699.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's binary_logloss: 0.247266\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's binary_logloss: 0.246057\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's binary_logloss: 0.246268\n",
      "[I 2025-07-30 12:31:46,167] Trial 8 finished with value: 0.7587521288901327 and parameters: {'n_estimators': 336, 'learning_rate': 0.18767014910245688, 'max_depth': 10, 'num_leaves': 81, 'subsample': 0.8652250990127688, 'colsample_bytree': 0.7924918425190294, 'min_child_samples': 11, 'reg_alpha': 0.17726200202804693, 'reg_lambda': 0.4297553497377623}. Best is trial 1 with value: 0.7688693932357699.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's binary_logloss: 0.246097\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's binary_logloss: 0.246008\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's binary_logloss: 0.245133\n",
      "[I 2025-07-30 12:31:50,412] Trial 9 finished with value: 0.7609067747076197 and parameters: {'n_estimators': 441, 'learning_rate': 0.11551808577377443, 'max_depth': 10, 'num_leaves': 123, 'subsample': 0.8677685953060298, 'colsample_bytree': 0.8659562385372889, 'min_child_samples': 21, 'reg_alpha': 0.28337402634119, 'reg_lambda': 0.2446821149428246}. Best is trial 1 with value: 0.7688693932357699.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[247]\tvalid_0's binary_logloss: 0.252193\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[247]\tvalid_0's binary_logloss: 0.251618\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[247]\tvalid_0's binary_logloss: 0.251227\n",
      "[I 2025-07-30 12:31:55,702] Trial 10 finished with value: 0.7457319803152531 and parameters: {'n_estimators': 247, 'learning_rate': 0.011194148247585509, 'max_depth': 4, 'num_leaves': 43, 'subsample': 0.7849580072371304, 'colsample_bytree': 0.8967585034798262, 'min_child_samples': 50, 'reg_alpha': 0.49450349807135136, 'reg_lambda': 0.12772890598990724}. Best is trial 1 with value: 0.7688693932357699.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[247]\tvalid_0's binary_logloss: 0.243654\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[261]\tvalid_0's binary_logloss: 0.243224\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[272]\tvalid_0's binary_logloss: 0.242871\n",
      "[I 2025-07-30 12:32:02,114] Trial 11 finished with value: 0.7679508887003741 and parameters: {'n_estimators': 989, 'learning_rate': 0.07931357848216178, 'max_depth': 5, 'num_leaves': 32, 'subsample': 0.8992526708289856, 'colsample_bytree': 0.8306311287933, 'min_child_samples': 49, 'reg_alpha': 0.4260633415152474, 'reg_lambda': 0.44679300632940205}. Best is trial 1 with value: 0.7688693932357699.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[688]\tvalid_0's binary_logloss: 0.243382\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[722]\tvalid_0's binary_logloss: 0.243006\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[729]\tvalid_0's binary_logloss: 0.242528\n",
      "[I 2025-07-30 12:32:20,533] Trial 12 finished with value: 0.7688808947564567 and parameters: {'n_estimators': 994, 'learning_rate': 0.020997610839750522, 'max_depth': 8, 'num_leaves': 55, 'subsample': 0.8006493966551282, 'colsample_bytree': 0.740740909511232, 'min_child_samples': 22, 'reg_alpha': 0.35868451947823454, 'reg_lambda': 0.3549541155779824}. Best is trial 12 with value: 0.7688808947564567.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[162]\tvalid_0's binary_logloss: 0.244078\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[157]\tvalid_0's binary_logloss: 0.243816\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[205]\tvalid_0's binary_logloss: 0.243435\n",
      "[I 2025-07-30 12:32:26,213] Trial 13 finished with value: 0.7663450729533327 and parameters: {'n_estimators': 778, 'learning_rate': 0.0858229515213658, 'max_depth': 7, 'num_leaves': 58, 'subsample': 0.793740840261328, 'colsample_bytree': 0.7583029426864474, 'min_child_samples': 21, 'reg_alpha': 0.12383834006046962, 'reg_lambda': 0.3593379601649026}. Best is trial 12 with value: 0.7688808947564567.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[944]\tvalid_0's binary_logloss: 0.243436\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[957]\tvalid_0's binary_logloss: 0.243149\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[978]\tvalid_0's binary_logloss: 0.242764\n",
      "[I 2025-07-30 12:32:50,639] Trial 14 finished with value: 0.7682453407218798 and parameters: {'n_estimators': 980, 'learning_rate': 0.016963409814466188, 'max_depth': 6, 'num_leaves': 96, 'subsample': 0.7611322454126386, 'colsample_bytree': 0.8260369941094237, 'min_child_samples': 16, 'reg_alpha': 0.3478233203373348, 'reg_lambda': 0.3430355043796924}. Best is trial 12 with value: 0.7688808947564567.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[188]\tvalid_0's binary_logloss: 0.244076\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[293]\tvalid_0's binary_logloss: 0.243476\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[261]\tvalid_0's binary_logloss: 0.243269\n",
      "[I 2025-07-30 12:32:57,969] Trial 15 finished with value: 0.7668230202853054 and parameters: {'n_estimators': 630, 'learning_rate': 0.05574846784485135, 'max_depth': 8, 'num_leaves': 58, 'subsample': 0.8195359379091989, 'colsample_bytree': 0.7485772349545472, 'min_child_samples': 24, 'reg_alpha': 0.14270462605730896, 'reg_lambda': 0.15144859095424132}. Best is trial 12 with value: 0.7688808947564567.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[220]\tvalid_0's binary_logloss: 0.243648\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[211]\tvalid_0's binary_logloss: 0.243379\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[280]\tvalid_0's binary_logloss: 0.242837\n",
      "[I 2025-07-30 12:33:03,719] Trial 16 finished with value: 0.7678272208017708 and parameters: {'n_estimators': 811, 'learning_rate': 0.08797123403921189, 'max_depth': 5, 'num_leaves': 99, 'subsample': 0.7530649490042087, 'colsample_bytree': 0.8933458313630602, 'min_child_samples': 12, 'reg_alpha': 0.004272736756516848, 'reg_lambda': 0.3433661355095554}. Best is trial 12 with value: 0.7688808947564567.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[577]\tvalid_0's binary_logloss: 0.243539\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[439]\tvalid_0's binary_logloss: 0.243272\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[572]\tvalid_0's binary_logloss: 0.242835\n",
      "[I 2025-07-30 12:33:16,704] Trial 17 finished with value: 0.7681019060248744 and parameters: {'n_estimators': 895, 'learning_rate': 0.031216776271325936, 'max_depth': 8, 'num_leaves': 47, 'subsample': 0.8909019752907411, 'colsample_bytree': 0.8543734743454796, 'min_child_samples': 27, 'reg_alpha': 0.35288994605013957, 'reg_lambda': 0.06365169923430053}. Best is trial 12 with value: 0.7688808947564567.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[726]\tvalid_0's binary_logloss: 0.244394\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[727]\tvalid_0's binary_logloss: 0.24383\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[727]\tvalid_0's binary_logloss: 0.243395\n",
      "[I 2025-07-30 12:33:34,575] Trial 18 finished with value: 0.7661344780322157 and parameters: {'n_estimators': 727, 'learning_rate': 0.0124075722322273, 'max_depth': 6, 'num_leaves': 71, 'subsample': 0.8154294703843976, 'colsample_bytree': 0.7724433714134523, 'min_child_samples': 16, 'reg_alpha': 0.42862632705659487, 'reg_lambda': 0.494557396992759}. Best is trial 12 with value: 0.7688808947564567.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[102]\tvalid_0's binary_logloss: 0.244863\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[97]\tvalid_0's binary_logloss: 0.244568\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[149]\tvalid_0's binary_logloss: 0.24392\n",
      "[I 2025-07-30 12:33:38,146] Trial 19 finished with value: 0.7647106079395639 and parameters: {'n_estimators': 548, 'learning_rate': 0.16509221724133472, 'max_depth': 5, 'num_leaves': 89, 'subsample': 0.7712222995669109, 'colsample_bytree': 0.8100003171073482, 'min_child_samples': 25, 'reg_alpha': 0.09373386479302968, 'reg_lambda': 0.06887227563780467}. Best is trial 12 with value: 0.7688808947564567.\n",
      "Best params: {'n_estimators': 994, 'learning_rate': 0.020997610839750522, 'max_depth': 8, 'num_leaves': 55, 'subsample': 0.8006493966551282, 'colsample_bytree': 0.740740909511232, 'min_child_samples': 22, 'reg_alpha': 0.35868451947823454, 'reg_lambda': 0.3549541155779824}\n",
      "Best AUC: 0.7688808947564567\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[722]\tvalid_0's binary_logloss: 0.240357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-30 12:33:46,466] A new study created in memory with name: no-name-80699286-3234-4c1c-80fd-a61003e37a95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LGBM] Fold 4/5 done.\n",
      "[LGBM] Optuna tuning fold 5/5...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d593838057c410f9ced73d8481206b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[124]\tvalid_0's binary_logloss: 0.241844\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[129]\tvalid_0's binary_logloss: 0.245676\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[183]\tvalid_0's binary_logloss: 0.24328\n",
      "[I 2025-07-30 12:33:52,896] Trial 0 finished with value: 0.7674465377670758 and parameters: {'n_estimators': 642, 'learning_rate': 0.06311134519817464, 'max_depth': 9, 'num_leaves': 111, 'subsample': 0.761319977615848, 'colsample_bytree': 0.7067574212667149, 'min_child_samples': 43, 'reg_alpha': 0.17210193848943006, 'reg_lambda': 0.22478852940111366}. Best is trial 0 with value: 0.7674465377670758.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[209]\tvalid_0's binary_logloss: 0.241105\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[188]\tvalid_0's binary_logloss: 0.245327\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[222]\tvalid_0's binary_logloss: 0.243167\n",
      "[I 2025-07-30 12:33:59,408] Trial 1 finished with value: 0.7684733639302239 and parameters: {'n_estimators': 499, 'learning_rate': 0.06780715103257239, 'max_depth': 7, 'num_leaves': 66, 'subsample': 0.717489495606553, 'colsample_bytree': 0.7893460204734635, 'min_child_samples': 25, 'reg_alpha': 0.02250840571096069, 'reg_lambda': 0.005704542533687851}. Best is trial 1 with value: 0.7684733639302239.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[179]\tvalid_0's binary_logloss: 0.241296\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[148]\tvalid_0's binary_logloss: 0.245363\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[184]\tvalid_0's binary_logloss: 0.243309\n",
      "[I 2025-07-30 12:34:04,614] Trial 2 finished with value: 0.7680586886551107 and parameters: {'n_estimators': 518, 'learning_rate': 0.10507610006023689, 'max_depth': 6, 'num_leaves': 121, 'subsample': 0.8795026040956717, 'colsample_bytree': 0.7782880262671538, 'min_child_samples': 46, 'reg_alpha': 0.3671870104398878, 'reg_lambda': 0.24291420912518608}. Best is trial 1 with value: 0.7684733639302239.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[90]\tvalid_0's binary_logloss: 0.24272\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's binary_logloss: 0.245866\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's binary_logloss: 0.244192\n",
      "[I 2025-07-30 12:34:07,878] Trial 3 finished with value: 0.7654044510851662 and parameters: {'n_estimators': 560, 'learning_rate': 0.1508099419572822, 'max_depth': 7, 'num_leaves': 48, 'subsample': 0.8358965993315272, 'colsample_bytree': 0.7657419115845384, 'min_child_samples': 13, 'reg_alpha': 0.22296761557905276, 'reg_lambda': 0.24168792580232684}. Best is trial 1 with value: 0.7684733639302239.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[339]\tvalid_0's binary_logloss: 0.241497\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[340]\tvalid_0's binary_logloss: 0.245411\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[340]\tvalid_0's binary_logloss: 0.243213\n",
      "[I 2025-07-30 12:34:17,173] Trial 4 finished with value: 0.76794744939902 and parameters: {'n_estimators': 340, 'learning_rate': 0.022112963914253707, 'max_depth': 10, 'num_leaves': 39, 'subsample': 0.7048188469399268, 'colsample_bytree': 0.7763437340111172, 'min_child_samples': 44, 'reg_alpha': 0.3054277045961295, 'reg_lambda': 0.3698009972683899}. Best is trial 1 with value: 0.7684733639302239.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\tvalid_0's binary_logloss: 0.245731\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's binary_logloss: 0.249074\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\tvalid_0's binary_logloss: 0.246478\n",
      "[I 2025-07-30 12:34:20,093] Trial 5 finished with value: 0.7572922626914463 and parameters: {'n_estimators': 361, 'learning_rate': 0.19951477866419756, 'max_depth': 8, 'num_leaves': 124, 'subsample': 0.7989416734712417, 'colsample_bytree': 0.8582499524501163, 'min_child_samples': 15, 'reg_alpha': 0.11677431010614325, 'reg_lambda': 0.21191371756755217}. Best is trial 1 with value: 0.7684733639302239.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[287]\tvalid_0's binary_logloss: 0.24111\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[288]\tvalid_0's binary_logloss: 0.245268\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[287]\tvalid_0's binary_logloss: 0.242881\n",
      "[I 2025-07-30 12:34:27,529] Trial 6 finished with value: 0.7686969151784657 and parameters: {'n_estimators': 288, 'learning_rate': 0.04057473427042964, 'max_depth': 6, 'num_leaves': 101, 'subsample': 0.8886584843406105, 'colsample_bytree': 0.8488245762574917, 'min_child_samples': 34, 'reg_alpha': 0.3505716682304221, 'reg_lambda': 0.3858638383630974}. Best is trial 6 with value: 0.7686969151784657.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[435]\tvalid_0's binary_logloss: 0.240483\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[440]\tvalid_0's binary_logloss: 0.244809\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[465]\tvalid_0's binary_logloss: 0.242356\n",
      "[I 2025-07-30 12:34:38,640] Trial 7 finished with value: 0.7702228241122051 and parameters: {'n_estimators': 730, 'learning_rate': 0.037994299092082996, 'max_depth': 6, 'num_leaves': 111, 'subsample': 0.8666253999837161, 'colsample_bytree': 0.8138963067033828, 'min_child_samples': 38, 'reg_alpha': 0.16341146806057538, 'reg_lambda': 0.33088007219599586}. Best is trial 7 with value: 0.7702228241122051.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[99]\tvalid_0's binary_logloss: 0.242828\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[82]\tvalid_0's binary_logloss: 0.24619\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's binary_logloss: 0.244667\n",
      "[I 2025-07-30 12:34:43,153] Trial 8 finished with value: 0.7644897912999342 and parameters: {'n_estimators': 575, 'learning_rate': 0.10049458975741768, 'max_depth': 8, 'num_leaves': 103, 'subsample': 0.8455640861621497, 'colsample_bytree': 0.8076968242908444, 'min_child_samples': 34, 'reg_alpha': 0.051740965918516624, 'reg_lambda': 0.08318136201964088}. Best is trial 7 with value: 0.7702228241122051.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[394]\tvalid_0's binary_logloss: 0.240721\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[326]\tvalid_0's binary_logloss: 0.245174\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[447]\tvalid_0's binary_logloss: 0.242437\n",
      "[I 2025-07-30 12:34:54,787] Trial 9 finished with value: 0.7695864224424719 and parameters: {'n_estimators': 607, 'learning_rate': 0.03561299549457945, 'max_depth': 7, 'num_leaves': 105, 'subsample': 0.7741369073925082, 'colsample_bytree': 0.7140708863742937, 'min_child_samples': 14, 'reg_alpha': 0.17227052461458214, 'reg_lambda': 0.37295183184569813}. Best is trial 7 with value: 0.7702228241122051.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[284]\tvalid_0's binary_logloss: 0.240703\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[221]\tvalid_0's binary_logloss: 0.244913\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[286]\tvalid_0's binary_logloss: 0.242376\n",
      "[I 2025-07-30 12:35:00,131] Trial 10 finished with value: 0.7700049918964343 and parameters: {'n_estimators': 921, 'learning_rate': 0.11620105529163863, 'max_depth': 4, 'num_leaves': 80, 'subsample': 0.8447018785052353, 'colsample_bytree': 0.897841753460919, 'min_child_samples': 25, 'reg_alpha': 0.2723508637294965, 'reg_lambda': 0.4757542362625264}. Best is trial 7 with value: 0.7702228241122051.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[284]\tvalid_0's binary_logloss: 0.240463\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[268]\tvalid_0's binary_logloss: 0.244763\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[280]\tvalid_0's binary_logloss: 0.242352\n",
      "[I 2025-07-30 12:35:06,345] Trial 11 finished with value: 0.7704460874717535 and parameters: {'n_estimators': 903, 'learning_rate': 0.12346532644393099, 'max_depth': 4, 'num_leaves': 81, 'subsample': 0.8461431321060489, 'colsample_bytree': 0.8934391881552978, 'min_child_samples': 25, 'reg_alpha': 0.4945201371717329, 'reg_lambda': 0.4794286751436877}. Best is trial 11 with value: 0.7704460874717535.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[224]\tvalid_0's binary_logloss: 0.240962\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[213]\tvalid_0's binary_logloss: 0.245351\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[174]\tvalid_0's binary_logloss: 0.242804\n",
      "[I 2025-07-30 12:35:10,797] Trial 12 finished with value: 0.7690811497309897 and parameters: {'n_estimators': 865, 'learning_rate': 0.15685287917825794, 'max_depth': 4, 'num_leaves': 84, 'subsample': 0.8608328379639393, 'colsample_bytree': 0.8996866346990389, 'min_child_samples': 27, 'reg_alpha': 0.4945797543293077, 'reg_lambda': 0.49907622584954714}. Best is trial 11 with value: 0.7704460874717535.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[175]\tvalid_0's binary_logloss: 0.241468\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[187]\tvalid_0's binary_logloss: 0.245336\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[144]\tvalid_0's binary_logloss: 0.243664\n",
      "[I 2025-07-30 12:35:15,249] Trial 13 finished with value: 0.7681180611894795 and parameters: {'n_estimators': 776, 'learning_rate': 0.138151516926606, 'max_depth': 5, 'num_leaves': 62, 'subsample': 0.8157387974122744, 'colsample_bytree': 0.8354816414619796, 'min_child_samples': 37, 'reg_alpha': 0.4928586791116655, 'reg_lambda': 0.3225724959349958}. Best is trial 11 with value: 0.7704460874717535.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[263]\tvalid_0's binary_logloss: 0.240677\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[315]\tvalid_0's binary_logloss: 0.244721\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[296]\tvalid_0's binary_logloss: 0.242437\n",
      "[I 2025-07-30 12:35:21,713] Trial 14 finished with value: 0.7702343316444887 and parameters: {'n_estimators': 762, 'learning_rate': 0.07972379742588104, 'max_depth': 5, 'num_leaves': 90, 'subsample': 0.867955842871806, 'colsample_bytree': 0.737715829748184, 'min_child_samples': 20, 'reg_alpha': 0.41417822074374444, 'reg_lambda': 0.4318075269969124}. Best is trial 11 with value: 0.7704460874717535.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[280]\tvalid_0's binary_logloss: 0.240412\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[236]\tvalid_0's binary_logloss: 0.244835\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[277]\tvalid_0's binary_logloss: 0.242339\n",
      "[I 2025-07-30 12:35:27,683] Trial 15 finished with value: 0.7702599383752543 and parameters: {'n_estimators': 994, 'learning_rate': 0.08051902667808315, 'max_depth': 5, 'num_leaves': 91, 'subsample': 0.895340692332771, 'colsample_bytree': 0.723683168528594, 'min_child_samples': 20, 'reg_alpha': 0.43392717902226335, 'reg_lambda': 0.4437405476854717}. Best is trial 11 with value: 0.7704460874717535.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[196]\tvalid_0's binary_logloss: 0.241265\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[211]\tvalid_0's binary_logloss: 0.245213\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[179]\tvalid_0's binary_logloss: 0.242867\n",
      "[I 2025-07-30 12:35:31,916] Trial 16 finished with value: 0.7691650856500926 and parameters: {'n_estimators': 998, 'learning_rate': 0.17650092841880125, 'max_depth': 4, 'num_leaves': 69, 'subsample': 0.8904593829452719, 'colsample_bytree': 0.7437272877737928, 'min_child_samples': 19, 'reg_alpha': 0.41663807132665825, 'reg_lambda': 0.4435490550582907}. Best is trial 11 with value: 0.7704460874717535.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[156]\tvalid_0's binary_logloss: 0.241158\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[201]\tvalid_0's binary_logloss: 0.245585\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[136]\tvalid_0's binary_logloss: 0.243398\n",
      "[I 2025-07-30 12:35:36,354] Trial 17 finished with value: 0.7684314417256041 and parameters: {'n_estimators': 970, 'learning_rate': 0.12582382497209665, 'max_depth': 5, 'num_leaves': 91, 'subsample': 0.8991502407163837, 'colsample_bytree': 0.8712257764641199, 'min_child_samples': 19, 'reg_alpha': 0.4412955115421567, 'reg_lambda': 0.1525631475760696}. Best is trial 11 with value: 0.7704460874717535.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[292]\tvalid_0's binary_logloss: 0.240574\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[284]\tvalid_0's binary_logloss: 0.245269\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[313]\tvalid_0's binary_logloss: 0.242375\n",
      "[I 2025-07-30 12:35:42,878] Trial 18 finished with value: 0.7700203909357465 and parameters: {'n_estimators': 866, 'learning_rate': 0.08795417230169875, 'max_depth': 5, 'num_leaves': 54, 'subsample': 0.8186814017535373, 'colsample_bytree': 0.7503551944282194, 'min_child_samples': 10, 'reg_alpha': 0.3510938836186502, 'reg_lambda': 0.30270018015082184}. Best is trial 11 with value: 0.7704460874717535.\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[574]\tvalid_0's binary_logloss: 0.240349\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[444]\tvalid_0's binary_logloss: 0.244636\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[655]\tvalid_0's binary_logloss: 0.241864\n",
      "[I 2025-07-30 12:35:52,377] Trial 19 finished with value: 0.7710758429871897 and parameters: {'n_estimators': 855, 'learning_rate': 0.05683875685911456, 'max_depth': 4, 'num_leaves': 75, 'subsample': 0.7873625455587442, 'colsample_bytree': 0.8315630010979433, 'min_child_samples': 30, 'reg_alpha': 0.45011483336838615, 'reg_lambda': 0.4233383050681605}. Best is trial 19 with value: 0.7710758429871897.\n",
      "Best params: {'n_estimators': 855, 'learning_rate': 0.05683875685911456, 'max_depth': 4, 'num_leaves': 75, 'subsample': 0.7873625455587442, 'colsample_bytree': 0.8315630010979433, 'min_child_samples': 30, 'reg_alpha': 0.45011483336838615, 'reg_lambda': 0.4233383050681605}\n",
      "Best AUC: 0.7710758429871897\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[788]\tvalid_0's binary_logloss: 0.242541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-30 12:35:58,142] A new study created in memory with name: no-name-05f17423-e3dd-4511-a49e-4a692030077c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LGBM] Fold 5/5 done.\n",
      "[LGBM] OOF and test predictions generated for lgbm.\n",
      "Running catboost ...\n",
      "[CatBoost] Optuna tuning fold 1/5...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f6a546d8909499cba419048f8b600cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-30 12:36:14,945] Trial 0 finished with value: 0.7675943853698968 and parameters: {'iterations': 275, 'learning_rate': 0.1173899079931078, 'depth': 5, 'l2_leaf_reg': 1.4022962482646122}. Best is trial 0 with value: 0.7675943853698968.\n",
      "[I 2025-07-30 12:36:37,856] Trial 1 finished with value: 0.7686583832151653 and parameters: {'iterations': 386, 'learning_rate': 0.08980550690140689, 'depth': 5, 'l2_leaf_reg': 8.07267491186142}. Best is trial 1 with value: 0.7686583832151653.\n",
      "[I 2025-07-30 12:37:12,289] Trial 2 finished with value: 0.7599594232191992 and parameters: {'iterations': 604, 'learning_rate': 0.1743972548349362, 'depth': 10, 'l2_leaf_reg': 7.998986348535569}. Best is trial 1 with value: 0.7686583832151653.\n",
      "[I 2025-07-30 12:37:38,909] Trial 3 finished with value: 0.7691922737131129 and parameters: {'iterations': 677, 'learning_rate': 0.11138687220665938, 'depth': 5, 'l2_leaf_reg': 2.428370897770711}. Best is trial 3 with value: 0.7691922737131129.\n",
      "[I 2025-07-30 12:37:57,962] Trial 4 finished with value: 0.7702665955899239 and parameters: {'iterations': 361, 'learning_rate': 0.18774388612482085, 'depth': 4, 'l2_leaf_reg': 9.67181582155085}. Best is trial 4 with value: 0.7702665955899239.\n",
      "[I 2025-07-30 12:38:23,777] Trial 5 finished with value: 0.7693161734705561 and parameters: {'iterations': 720, 'learning_rate': 0.11388505768088025, 'depth': 5, 'l2_leaf_reg': 9.809435088352553}. Best is trial 4 with value: 0.7702665955899239.\n",
      "[I 2025-07-30 12:39:20,156] Trial 6 finished with value: 0.7689510723334797 and parameters: {'iterations': 588, 'learning_rate': 0.04305791868171666, 'depth': 8, 'l2_leaf_reg': 5.523190057588443}. Best is trial 4 with value: 0.7702665955899239.\n",
      "[I 2025-07-30 12:39:37,127] Trial 7 finished with value: 0.76567393286065 and parameters: {'iterations': 316, 'learning_rate': 0.16371011628658388, 'depth': 8, 'l2_leaf_reg': 8.26115559589587}. Best is trial 4 with value: 0.7702665955899239.\n",
      "[I 2025-07-30 12:39:56,602] Trial 8 finished with value: 0.7689152873505831 and parameters: {'iterations': 363, 'learning_rate': 0.12300637793009697, 'depth': 4, 'l2_leaf_reg': 5.954478914794831}. Best is trial 4 with value: 0.7702665955899239.\n",
      "[I 2025-07-30 12:40:12,523] Trial 9 finished with value: 0.7607448728349305 and parameters: {'iterations': 725, 'learning_rate': 0.19815630290210287, 'depth': 9, 'l2_leaf_reg': 4.333873433438566}. Best is trial 4 with value: 0.7702665955899239.\n",
      "[I 2025-07-30 12:41:26,880] Trial 10 finished with value: 0.7647159140262074 and parameters: {'iterations': 973, 'learning_rate': 0.012271888585951046, 'depth': 7, 'l2_leaf_reg': 9.45007767438762}. Best is trial 4 with value: 0.7702665955899239.\n",
      "[I 2025-07-30 12:41:52,571] Trial 11 finished with value: 0.7699115273863977 and parameters: {'iterations': 884, 'learning_rate': 0.15027298117596383, 'depth': 4, 'l2_leaf_reg': 9.008236228930123}. Best is trial 4 with value: 0.7702665955899239.\n",
      "[I 2025-07-30 12:42:17,748] Trial 12 finished with value: 0.7698184465541306 and parameters: {'iterations': 1000, 'learning_rate': 0.15524855813302138, 'depth': 4, 'l2_leaf_reg': 6.910011601134816}. Best is trial 4 with value: 0.7702665955899239.\n",
      "[I 2025-07-30 12:42:32,227] Trial 13 finished with value: 0.7669258682504781 and parameters: {'iterations': 818, 'learning_rate': 0.1953189098587833, 'depth': 6, 'l2_leaf_reg': 9.700514995012643}. Best is trial 4 with value: 0.7702665955899239.\n",
      "[I 2025-07-30 12:42:55,237] Trial 14 finished with value: 0.7699404375831956 and parameters: {'iterations': 460, 'learning_rate': 0.14971549843473514, 'depth': 4, 'l2_leaf_reg': 3.8364502062117065}. Best is trial 4 with value: 0.7702665955899239.\n",
      "[I 2025-07-30 12:43:27,473] Trial 15 finished with value: 0.7694563019352506 and parameters: {'iterations': 492, 'learning_rate': 0.07973300272701425, 'depth': 6, 'l2_leaf_reg': 3.9097907510387384}. Best is trial 4 with value: 0.7702665955899239.\n",
      "[I 2025-07-30 12:43:41,123] Trial 16 finished with value: 0.7674851761938161 and parameters: {'iterations': 201, 'learning_rate': 0.14437900839359402, 'depth': 6, 'l2_leaf_reg': 3.9147403788447424}. Best is trial 4 with value: 0.7702665955899239.\n",
      "[I 2025-07-30 12:44:04,396] Trial 17 finished with value: 0.7697670917161347 and parameters: {'iterations': 464, 'learning_rate': 0.18007721153901882, 'depth': 4, 'l2_leaf_reg': 2.2967465433609684}. Best is trial 4 with value: 0.7702665955899239.\n",
      "[I 2025-07-30 12:44:20,862] Trial 18 finished with value: 0.7664907257304975 and parameters: {'iterations': 470, 'learning_rate': 0.13955941564350782, 'depth': 7, 'l2_leaf_reg': 6.634930702321796}. Best is trial 4 with value: 0.7702665955899239.\n",
      "[I 2025-07-30 12:44:44,240] Trial 19 finished with value: 0.7695471660840548 and parameters: {'iterations': 524, 'learning_rate': 0.17761301681387157, 'depth': 4, 'l2_leaf_reg': 4.75110439773037}. Best is trial 4 with value: 0.7702665955899239.\n",
      "Best params: {'iterations': 361, 'learning_rate': 0.18774388612482085, 'depth': 4, 'l2_leaf_reg': 9.67181582155085}\n",
      "Best AUC: 0.7702665955899239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-30 12:44:51,551] A new study created in memory with name: no-name-b901aeb7-be9d-4549-8056-c54b71af4cf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CatBoost] Fold 1/5 done.\n",
      "[CatBoost] Optuna tuning fold 2/5...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76f89610f7e74266bc523dd280e6ea4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-30 12:45:35,514] Trial 0 finished with value: 0.7584805349637213 and parameters: {'iterations': 487, 'learning_rate': 0.12943285029675755, 'depth': 10, 'l2_leaf_reg': 2.4101462659208996}. Best is trial 0 with value: 0.7584805349637213.\n",
      "[I 2025-07-30 12:46:35,603] Trial 1 finished with value: 0.7673886227109659 and parameters: {'iterations': 786, 'learning_rate': 0.03458872243871832, 'depth': 7, 'l2_leaf_reg': 7.106955009821596}. Best is trial 1 with value: 0.7673886227109659.\n",
      "[I 2025-07-30 12:46:59,755] Trial 2 finished with value: 0.7661264278360767 and parameters: {'iterations': 790, 'learning_rate': 0.10417644800891955, 'depth': 7, 'l2_leaf_reg': 2.7414883252879507}. Best is trial 1 with value: 0.7673886227109659.\n",
      "[I 2025-07-30 12:48:28,284] Trial 3 finished with value: 0.7627879923937003 and parameters: {'iterations': 664, 'learning_rate': 0.015862378887597485, 'depth': 9, 'l2_leaf_reg': 3.011003283474896}. Best is trial 1 with value: 0.7673886227109659.\n",
      "[I 2025-07-30 12:48:47,507] Trial 4 finished with value: 0.7629519707210118 and parameters: {'iterations': 734, 'learning_rate': 0.15939202824300405, 'depth': 8, 'l2_leaf_reg': 4.909972888950189}. Best is trial 1 with value: 0.7673886227109659.\n",
      "[I 2025-07-30 12:49:12,664] Trial 5 finished with value: 0.7645247874770261 and parameters: {'iterations': 431, 'learning_rate': 0.052810319618843686, 'depth': 5, 'l2_leaf_reg': 4.209266488330154}. Best is trial 1 with value: 0.7673886227109659.\n",
      "[I 2025-07-30 12:49:26,430] Trial 6 finished with value: 0.764307499644748 and parameters: {'iterations': 767, 'learning_rate': 0.19077946511402932, 'depth': 6, 'l2_leaf_reg': 2.009477975253477}. Best is trial 1 with value: 0.7673886227109659.\n",
      "[I 2025-07-30 12:49:54,724] Trial 7 finished with value: 0.7671910188506444 and parameters: {'iterations': 508, 'learning_rate': 0.10150239937721837, 'depth': 6, 'l2_leaf_reg': 6.89657290003881}. Best is trial 1 with value: 0.7673886227109659.\n",
      "[I 2025-07-30 12:50:21,973] Trial 8 finished with value: 0.7612386535952108 and parameters: {'iterations': 414, 'learning_rate': 0.029650566690374046, 'depth': 6, 'l2_leaf_reg': 4.809709407447365}. Best is trial 1 with value: 0.7673886227109659.\n",
      "[I 2025-07-30 12:51:13,849] Trial 9 finished with value: 0.7611256282269 and parameters: {'iterations': 248, 'learning_rate': 0.13422374383173352, 'depth': 10, 'l2_leaf_reg': 8.113417150725313}. Best is trial 1 with value: 0.7673886227109659.\n",
      "[I 2025-07-30 12:51:54,484] Trial 10 finished with value: 0.76805227294536 and parameters: {'iterations': 991, 'learning_rate': 0.06932382880549826, 'depth': 4, 'l2_leaf_reg': 9.801472322399121}. Best is trial 10 with value: 0.76805227294536.\n",
      "[I 2025-07-30 12:52:40,765] Trial 11 finished with value: 0.7684477705585625 and parameters: {'iterations': 990, 'learning_rate': 0.0676285256588458, 'depth': 4, 'l2_leaf_reg': 9.814794161366752}. Best is trial 11 with value: 0.7684477705585625.\n",
      "[I 2025-07-30 12:53:30,641] Trial 12 finished with value: 0.7688807150765066 and parameters: {'iterations': 997, 'learning_rate': 0.07008287987744287, 'depth': 4, 'l2_leaf_reg': 9.601289590546749}. Best is trial 12 with value: 0.7688807150765066.\n",
      "[I 2025-07-30 12:54:18,071] Trial 13 finished with value: 0.7684050528192925 and parameters: {'iterations': 965, 'learning_rate': 0.06724591324602029, 'depth': 4, 'l2_leaf_reg': 9.591832611382516}. Best is trial 12 with value: 0.7688807150765066.\n",
      "[I 2025-07-30 12:54:57,564] Trial 14 finished with value: 0.7683212711978423 and parameters: {'iterations': 903, 'learning_rate': 0.0835412184917643, 'depth': 4, 'l2_leaf_reg': 8.580024630323926}. Best is trial 12 with value: 0.7688807150765066.\n",
      "[I 2025-07-30 12:55:48,302] Trial 15 finished with value: 0.7680778375949476 and parameters: {'iterations': 884, 'learning_rate': 0.050297233253652554, 'depth': 5, 'l2_leaf_reg': 6.880404515002262}. Best is trial 12 with value: 0.7688807150765066.\n",
      "[I 2025-07-30 12:56:25,455] Trial 16 finished with value: 0.7683687988825483 and parameters: {'iterations': 900, 'learning_rate': 0.0873065665586222, 'depth': 5, 'l2_leaf_reg': 8.780276911262503}. Best is trial 12 with value: 0.7688807150765066.\n",
      "[I 2025-07-30 12:56:54,215] Trial 17 finished with value: 0.7672394195528044 and parameters: {'iterations': 994, 'learning_rate': 0.132043101984846, 'depth': 4, 'l2_leaf_reg': 5.962853226090752}. Best is trial 12 with value: 0.7688807150765066.\n",
      "[I 2025-07-30 12:57:30,310] Trial 18 finished with value: 0.7674335674128915 and parameters: {'iterations': 625, 'learning_rate': 0.05454514028426764, 'depth': 5, 'l2_leaf_reg': 7.867248530439204}. Best is trial 12 with value: 0.7688807150765066.\n",
      "[I 2025-07-30 12:57:47,517] Trial 19 finished with value: 0.7646663271851128 and parameters: {'iterations': 221, 'learning_rate': 0.08398584973771611, 'depth': 7, 'l2_leaf_reg': 9.90239153131495}. Best is trial 12 with value: 0.7688807150765066.\n",
      "Best params: {'iterations': 997, 'learning_rate': 0.07008287987744287, 'depth': 4, 'l2_leaf_reg': 9.601289590546749}\n",
      "Best AUC: 0.7688807150765066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-30 12:58:07,022] A new study created in memory with name: no-name-5ad9013f-4ecc-4be9-bd40-25280a4d48e0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CatBoost] Fold 2/5 done.\n",
      "[CatBoost] Optuna tuning fold 3/5...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b04ee0b0e774e8f86b1410be6517c81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-30 12:59:03,719] Trial 0 finished with value: 0.7673458929485024 and parameters: {'iterations': 532, 'learning_rate': 0.054656915730943854, 'depth': 9, 'l2_leaf_reg': 3.6058883409401936}. Best is trial 0 with value: 0.7673458929485024.\n",
      "[I 2025-07-30 12:59:26,241] Trial 1 finished with value: 0.7707417852297175 and parameters: {'iterations': 457, 'learning_rate': 0.1518121564633962, 'depth': 4, 'l2_leaf_reg': 4.12346699704008}. Best is trial 1 with value: 0.7707417852297175.\n",
      "[I 2025-07-30 12:59:53,887] Trial 2 finished with value: 0.7706109782258759 and parameters: {'iterations': 945, 'learning_rate': 0.16958338223731637, 'depth': 4, 'l2_leaf_reg': 4.828681983676722}. Best is trial 1 with value: 0.7707417852297175.\n",
      "[I 2025-07-30 13:00:12,756] Trial 3 finished with value: 0.7686340358792675 and parameters: {'iterations': 799, 'learning_rate': 0.16168709859818975, 'depth': 6, 'l2_leaf_reg': 5.437235070199771}. Best is trial 1 with value: 0.7707417852297175.\n",
      "[I 2025-07-30 13:00:29,787] Trial 4 finished with value: 0.7668980443460538 and parameters: {'iterations': 561, 'learning_rate': 0.14154969269156234, 'depth': 7, 'l2_leaf_reg': 1.042468114176573}. Best is trial 1 with value: 0.7707417852297175.\n",
      "[I 2025-07-30 13:00:48,293] Trial 5 finished with value: 0.7694619423103387 and parameters: {'iterations': 509, 'learning_rate': 0.18060539286094335, 'depth': 5, 'l2_leaf_reg': 6.949076278591842}. Best is trial 1 with value: 0.7707417852297175.\n",
      "[I 2025-07-30 13:01:03,440] Trial 6 finished with value: 0.7680340664903186 and parameters: {'iterations': 574, 'learning_rate': 0.19335740467153395, 'depth': 6, 'l2_leaf_reg': 3.3655993012754255}. Best is trial 1 with value: 0.7707417852297175.\n",
      "[I 2025-07-30 13:01:38,779] Trial 7 finished with value: 0.770688559219152 and parameters: {'iterations': 647, 'learning_rate': 0.09189117346155577, 'depth': 5, 'l2_leaf_reg': 8.959048276114359}. Best is trial 1 with value: 0.7707417852297175.\n",
      "[I 2025-07-30 13:02:32,998] Trial 8 finished with value: 0.770733057727 and parameters: {'iterations': 998, 'learning_rate': 0.05876106405692775, 'depth': 4, 'l2_leaf_reg': 8.93595081479284}. Best is trial 1 with value: 0.7707417852297175.\n",
      "[I 2025-07-30 13:02:52,444] Trial 9 finished with value: 0.7695631462074192 and parameters: {'iterations': 967, 'learning_rate': 0.17243613450092937, 'depth': 5, 'l2_leaf_reg': 8.012066070290054}. Best is trial 1 with value: 0.7707417852297175.\n",
      "[I 2025-07-30 13:03:16,256] Trial 10 finished with value: 0.762713840014495 and parameters: {'iterations': 240, 'learning_rate': 0.11842831400818736, 'depth': 9, 'l2_leaf_reg': 1.3156000172812474}. Best is trial 1 with value: 0.7707417852297175.\n",
      "[I 2025-07-30 13:03:32,342] Trial 11 finished with value: 0.7563423809602629 and parameters: {'iterations': 296, 'learning_rate': 0.025129653027048213, 'depth': 4, 'l2_leaf_reg': 9.97647428185487}. Best is trial 1 with value: 0.7707417852297175.\n",
      "[I 2025-07-30 13:03:53,678] Trial 12 finished with value: 0.7678226366251942 and parameters: {'iterations': 394, 'learning_rate': 0.07892139483998752, 'depth': 4, 'l2_leaf_reg': 6.77977753648715}. Best is trial 1 with value: 0.7707417852297175.\n",
      "[I 2025-07-30 13:04:51,113] Trial 13 finished with value: 0.7635867606148334 and parameters: {'iterations': 754, 'learning_rate': 0.01282415885902917, 'depth': 7, 'l2_leaf_reg': 3.4476001445012106}. Best is trial 1 with value: 0.7707417852297175.\n",
      "[I 2025-07-30 13:05:41,950] Trial 14 finished with value: 0.7634330467551678 and parameters: {'iterations': 409, 'learning_rate': 0.12468908701699419, 'depth': 10, 'l2_leaf_reg': 6.6091526871712905}. Best is trial 1 with value: 0.7707417852297175.\n",
      "[I 2025-07-30 13:06:29,917] Trial 15 finished with value: 0.7707794211657825 and parameters: {'iterations': 824, 'learning_rate': 0.060901998688505155, 'depth': 6, 'l2_leaf_reg': 2.517737954182275}. Best is trial 15 with value: 0.7707794211657825.\n",
      "[I 2025-07-30 13:06:48,980] Trial 16 finished with value: 0.767336766676527 and parameters: {'iterations': 715, 'learning_rate': 0.1477848878978588, 'depth': 7, 'l2_leaf_reg': 2.383794345901614}. Best is trial 15 with value: 0.7707794211657825.\n",
      "[I 2025-07-30 13:07:43,744] Trial 17 finished with value: 0.770683792690804 and parameters: {'iterations': 865, 'learning_rate': 0.04369757576172716, 'depth': 6, 'l2_leaf_reg': 4.480364828368016}. Best is trial 15 with value: 0.7707794211657825.\n",
      "[I 2025-07-30 13:08:09,053] Trial 18 finished with value: 0.7668885894401171 and parameters: {'iterations': 440, 'learning_rate': 0.1050754449706518, 'depth': 8, 'l2_leaf_reg': 2.2762914982195763}. Best is trial 15 with value: 0.7707794211657825.\n",
      "[I 2025-07-30 13:08:43,525] Trial 19 finished with value: 0.7701549251296358 and parameters: {'iterations': 697, 'learning_rate': 0.0826349560766372, 'depth': 5, 'l2_leaf_reg': 2.501747853267329}. Best is trial 15 with value: 0.7707794211657825.\n",
      "Best params: {'iterations': 824, 'learning_rate': 0.060901998688505155, 'depth': 6, 'l2_leaf_reg': 2.517737954182275}\n",
      "Best AUC: 0.7707794211657825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-30 13:09:01,533] A new study created in memory with name: no-name-d9a9fc37-f6aa-4d27-8576-631e0da7e375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CatBoost] Fold 3/5 done.\n",
      "[CatBoost] Optuna tuning fold 4/5...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf0d7d4454d74e52ac2cd862206ac6cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-30 13:09:20,295] Trial 0 finished with value: 0.7674818438753831 and parameters: {'iterations': 332, 'learning_rate': 0.153182288098582, 'depth': 5, 'l2_leaf_reg': 8.337955556295807}. Best is trial 0 with value: 0.7674818438753831.\n",
      "[I 2025-07-30 13:10:09,051] Trial 1 finished with value: 0.7679741762906654 and parameters: {'iterations': 771, 'learning_rate': 0.04060906650067831, 'depth': 6, 'l2_leaf_reg': 3.037307866370119}. Best is trial 1 with value: 0.7679741762906654.\n",
      "[I 2025-07-30 13:10:22,015] Trial 2 finished with value: 0.763472233015265 and parameters: {'iterations': 793, 'learning_rate': 0.19450584266319362, 'depth': 7, 'l2_leaf_reg': 4.916701279464111}. Best is trial 1 with value: 0.7679741762906654.\n",
      "[I 2025-07-30 13:10:55,197] Trial 3 finished with value: 0.7577971172629697 and parameters: {'iterations': 627, 'learning_rate': 0.18878169380661838, 'depth': 10, 'l2_leaf_reg': 7.12202672644174}. Best is trial 1 with value: 0.7679741762906654.\n",
      "[I 2025-07-30 13:11:11,087] Trial 4 finished with value: 0.7638004728828957 and parameters: {'iterations': 231, 'learning_rate': 0.07077431339489205, 'depth': 6, 'l2_leaf_reg': 8.416883266005375}. Best is trial 1 with value: 0.7679741762906654.\n",
      "[I 2025-07-30 13:11:27,741] Trial 5 finished with value: 0.7667059978730437 and parameters: {'iterations': 362, 'learning_rate': 0.1924073556318535, 'depth': 5, 'l2_leaf_reg': 3.126334349667831}. Best is trial 1 with value: 0.7679741762906654.\n",
      "[I 2025-07-30 13:11:49,799] Trial 6 finished with value: 0.7616535432839449 and parameters: {'iterations': 422, 'learning_rate': 0.04093436207994268, 'depth': 4, 'l2_leaf_reg': 7.386361006209375}. Best is trial 1 with value: 0.7679741762906654.\n",
      "[I 2025-07-30 13:12:32,719] Trial 7 finished with value: 0.7671836700074713 and parameters: {'iterations': 819, 'learning_rate': 0.07165782443076081, 'depth': 8, 'l2_leaf_reg': 7.469594937297533}. Best is trial 1 with value: 0.7679741762906654.\n",
      "[I 2025-07-30 13:12:54,288] Trial 8 finished with value: 0.766471332518134 and parameters: {'iterations': 719, 'learning_rate': 0.13793876529706975, 'depth': 7, 'l2_leaf_reg': 8.003303464865144}. Best is trial 1 with value: 0.7679741762906654.\n",
      "[I 2025-07-30 13:13:24,421] Trial 9 finished with value: 0.7639527553145555 and parameters: {'iterations': 602, 'learning_rate': 0.10596433649840141, 'depth': 9, 'l2_leaf_reg': 5.136415605045022}. Best is trial 1 with value: 0.7679741762906654.\n",
      "[I 2025-07-30 13:14:13,425] Trial 10 finished with value: 0.7618660913060834 and parameters: {'iterations': 968, 'learning_rate': 0.018402190700062142, 'depth': 4, 'l2_leaf_reg': 1.7676837086361212}. Best is trial 1 with value: 0.7679741762906654.\n",
      "[I 2025-07-30 13:14:34,512] Trial 11 finished with value: 0.7671499843584929 and parameters: {'iterations': 399, 'learning_rate': 0.1467285590512647, 'depth': 6, 'l2_leaf_reg': 9.751042430081613}. Best is trial 1 with value: 0.7679741762906654.\n",
      "[I 2025-07-30 13:14:47,653] Trial 12 finished with value: 0.7658939493665106 and parameters: {'iterations': 223, 'learning_rate': 0.1473162862682436, 'depth': 5, 'l2_leaf_reg': 3.458756248296206}. Best is trial 1 with value: 0.7679741762906654.\n",
      "[I 2025-07-30 13:15:12,102] Trial 13 finished with value: 0.7664629904255701 and parameters: {'iterations': 497, 'learning_rate': 0.1068395182974976, 'depth': 6, 'l2_leaf_reg': 1.3084047117082989}. Best is trial 1 with value: 0.7679741762906654.\n",
      "[I 2025-07-30 13:16:00,748] Trial 14 finished with value: 0.7691427191700299 and parameters: {'iterations': 968, 'learning_rate': 0.06945374377781402, 'depth': 5, 'l2_leaf_reg': 6.004154956083219}. Best is trial 14 with value: 0.7691427191700299.\n",
      "[I 2025-07-30 13:16:49,788] Trial 15 finished with value: 0.7672891154201079 and parameters: {'iterations': 995, 'learning_rate': 0.060779521813926075, 'depth': 8, 'l2_leaf_reg': 6.158873928297867}. Best is trial 14 with value: 0.7691427191700299.\n",
      "[I 2025-07-30 13:17:39,747] Trial 16 finished with value: 0.760424011418614 and parameters: {'iterations': 881, 'learning_rate': 0.01323366132168979, 'depth': 5, 'l2_leaf_reg': 3.8414162010752038}. Best is trial 14 with value: 0.7691427191700299.\n",
      "[I 2025-07-30 13:18:28,462] Trial 17 finished with value: 0.7677524178341956 and parameters: {'iterations': 879, 'learning_rate': 0.04873169758431225, 'depth': 6, 'l2_leaf_reg': 2.5489248645211595}. Best is trial 14 with value: 0.7691427191700299.\n",
      "[I 2025-07-30 13:19:04,414] Trial 18 finished with value: 0.7686991501565842 and parameters: {'iterations': 723, 'learning_rate': 0.08903542675232876, 'depth': 4, 'l2_leaf_reg': 5.995460948132557}. Best is trial 14 with value: 0.7691427191700299.\n",
      "[I 2025-07-30 13:19:40,786] Trial 19 finished with value: 0.7686244286795438 and parameters: {'iterations': 705, 'learning_rate': 0.09430368399512833, 'depth': 4, 'l2_leaf_reg': 5.882111231508224}. Best is trial 14 with value: 0.7691427191700299.\n",
      "Best params: {'iterations': 968, 'learning_rate': 0.06945374377781402, 'depth': 5, 'l2_leaf_reg': 6.004154956083219}\n",
      "Best AUC: 0.7691427191700299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-30 13:20:01,835] A new study created in memory with name: no-name-99de2241-5720-45cf-9206-af39a35612d2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CatBoost] Fold 4/5 done.\n",
      "[CatBoost] Optuna tuning fold 5/5...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c71bed831244ba9019df4904627fdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-30 13:22:35,429] Trial 0 finished with value: 0.7633585396917485 and parameters: {'iterations': 511, 'learning_rate': 0.014802291357811633, 'depth': 10, 'l2_leaf_reg': 8.90972792191168}. Best is trial 0 with value: 0.7633585396917485.\n",
      "[I 2025-07-30 13:22:56,340] Trial 1 finished with value: 0.7687763203574084 and parameters: {'iterations': 990, 'learning_rate': 0.17428395978511094, 'depth': 5, 'l2_leaf_reg': 5.264473140702048}. Best is trial 1 with value: 0.7687763203574084.\n",
      "[I 2025-07-30 13:23:16,443] Trial 2 finished with value: 0.7670578512931058 and parameters: {'iterations': 675, 'learning_rate': 0.14160506332647244, 'depth': 7, 'l2_leaf_reg': 2.8186830106345697}. Best is trial 1 with value: 0.7687763203574084.\n",
      "[I 2025-07-30 13:23:55,730] Trial 3 finished with value: 0.7700379414587758 and parameters: {'iterations': 712, 'learning_rate': 0.0981153180840278, 'depth': 4, 'l2_leaf_reg': 9.479412303290273}. Best is trial 3 with value: 0.7700379414587758.\n",
      "[I 2025-07-30 13:24:23,666] Trial 4 finished with value: 0.7671523308851306 and parameters: {'iterations': 296, 'learning_rate': 0.1069335723618438, 'depth': 8, 'l2_leaf_reg': 7.417708291424765}. Best is trial 3 with value: 0.7700379414587758.\n",
      "[I 2025-07-30 13:24:37,819] Trial 5 finished with value: 0.7659031638085732 and parameters: {'iterations': 971, 'learning_rate': 0.19800241227808155, 'depth': 7, 'l2_leaf_reg': 6.470674689609061}. Best is trial 3 with value: 0.7700379414587758.\n",
      "[I 2025-07-30 13:24:54,691] Trial 6 finished with value: 0.7685067757175679 and parameters: {'iterations': 670, 'learning_rate': 0.19333243289941668, 'depth': 5, 'l2_leaf_reg': 3.9701262630655085}. Best is trial 3 with value: 0.7700379414587758.\n",
      "[I 2025-07-30 13:25:34,767] Trial 7 finished with value: 0.7601152805186763 and parameters: {'iterations': 873, 'learning_rate': 0.1346939076316303, 'depth': 10, 'l2_leaf_reg': 3.185694634866186}. Best is trial 3 with value: 0.7700379414587758.\n",
      "[I 2025-07-30 13:25:52,759] Trial 8 finished with value: 0.7626897061249581 and parameters: {'iterations': 643, 'learning_rate': 0.16836549811971535, 'depth': 9, 'l2_leaf_reg': 5.644432966627613}. Best is trial 3 with value: 0.7700379414587758.\n",
      "[I 2025-07-30 13:26:47,703] Trial 9 finished with value: 0.7668975714337681 and parameters: {'iterations': 523, 'learning_rate': 0.07138066110760545, 'depth': 9, 'l2_leaf_reg': 5.358619409934006}. Best is trial 3 with value: 0.7700379414587758.\n",
      "[I 2025-07-30 13:27:00,997] Trial 10 finished with value: 0.7609956615107071 and parameters: {'iterations': 231, 'learning_rate': 0.0596329008217828, 'depth': 4, 'l2_leaf_reg': 9.80209536103398}. Best is trial 3 with value: 0.7700379414587758.\n",
      "[I 2025-07-30 13:27:36,363] Trial 11 finished with value: 0.7693639011811572 and parameters: {'iterations': 809, 'learning_rate': 0.09355694786886949, 'depth': 5, 'l2_leaf_reg': 1.2343791489168412}. Best is trial 3 with value: 0.7700379414587758.\n",
      "[I 2025-07-30 13:28:17,833] Trial 12 finished with value: 0.7701099383465322 and parameters: {'iterations': 805, 'learning_rate': 0.08347471596395123, 'depth': 4, 'l2_leaf_reg': 1.2694828647825602}. Best is trial 12 with value: 0.7701099383465322.\n",
      "[I 2025-07-30 13:28:59,778] Trial 13 finished with value: 0.7676250514676185 and parameters: {'iterations': 781, 'learning_rate': 0.04652054257359097, 'depth': 4, 'l2_leaf_reg': 1.4180950727543635}. Best is trial 12 with value: 0.7701099383465322.\n",
      "[I 2025-07-30 13:29:27,599] Trial 14 finished with value: 0.7691761823899248 and parameters: {'iterations': 412, 'learning_rate': 0.10307779859035805, 'depth': 6, 'l2_leaf_reg': 8.192272313684667}. Best is trial 12 with value: 0.7701099383465322.\n",
      "[I 2025-07-30 13:30:09,104] Trial 15 finished with value: 0.7650243284648884 and parameters: {'iterations': 760, 'learning_rate': 0.030048626916171578, 'depth': 4, 'l2_leaf_reg': 9.921747569335917}. Best is trial 12 with value: 0.7701099383465322.\n",
      "[I 2025-07-30 13:30:41,509] Trial 16 finished with value: 0.769181609525971 and parameters: {'iterations': 880, 'learning_rate': 0.08485684125960039, 'depth': 6, 'l2_leaf_reg': 7.123315558751058}. Best is trial 12 with value: 0.7701099383465322.\n",
      "[I 2025-07-30 13:31:03,529] Trial 17 finished with value: 0.768100427172049 and parameters: {'iterations': 570, 'learning_rate': 0.12562944287049096, 'depth': 6, 'l2_leaf_reg': 4.023754098076102}. Best is trial 12 with value: 0.7701099383465322.\n",
      "[I 2025-07-30 13:31:35,141] Trial 18 finished with value: 0.7696787692535249 and parameters: {'iterations': 721, 'learning_rate': 0.120116266151577, 'depth': 4, 'l2_leaf_reg': 2.269146138862704}. Best is trial 12 with value: 0.7701099383465322.\n",
      "[I 2025-07-30 13:32:14,405] Trial 19 finished with value: 0.7697037193843234 and parameters: {'iterations': 863, 'learning_rate': 0.07430538308341934, 'depth': 5, 'l2_leaf_reg': 8.554658724671341}. Best is trial 12 with value: 0.7701099383465322.\n",
      "Best params: {'iterations': 805, 'learning_rate': 0.08347471596395123, 'depth': 4, 'l2_leaf_reg': 1.2694828647825602}\n",
      "Best AUC: 0.7701099383465322\n",
      "[CatBoost] Fold 5/5 done.\n",
      "[CatBoost] OOF and test predictions generated for catboost.\n",
      "=== L1 OOF predictions generated ===\n",
      "\n",
      "\n",
      "L1 models saved to temp_results/models/l1_stacking/\n",
      "L1 Model Performance:\n",
      "L1 Stacking - done in 9501s\n"
     ]
    }
   ],
   "source": [
    "with timer(\"L1 Stacking\"):\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"LEVEL 1 STACKING - BASE MODELS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    models_l1, oof_preds_l1, test_preds_l1, metrics_l1 = run_l1_stacking(\n",
    "        X_train_selected, y_train, X_test_selected, TUNE_HYPERPARAMS\n",
    "    )\n",
    "    \n",
    "    # Save L1 models and predictions\n",
    "    l1_dir = MODELS_L1_DIR\n",
    "    os.makedirs(l1_dir, exist_ok=True)\n",
    "    expected_l1_models = ['xgb', 'lgbm', 'catboost']\n",
    "    \n",
    "    for name in expected_l1_models:\n",
    "        # Save model\n",
    "        if name in models_l1 and models_l1[name] is not None:\n",
    "            with open(f'{l1_dir}/l1_{name}_model.pkl', 'wb') as f:\n",
    "                pickle.dump(models_l1[name], f)\n",
    "        \n",
    "        # Save OOF predictions\n",
    "        if name in oof_preds_l1:\n",
    "            pd.DataFrame({'oof_preds': oof_preds_l1[name]}).to_csv(\n",
    "                f'{l1_dir}/l1_{name}_oof_predictions.csv', index=False\n",
    "            )\n",
    "        \n",
    "        # Save test predictions\n",
    "        if name in test_preds_l1:\n",
    "            pd.DataFrame({'test_preds': test_preds_l1[name]}).to_csv(\n",
    "                f'{l1_dir}/l1_{name}_test_predictions.csv', index=False\n",
    "            )\n",
    "    \n",
    "    # Save metrics summary\n",
    "    with open(f'{l1_dir}/l1_model_summary.json', 'w') as f:\n",
    "        json.dump(metrics_l1, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nL1 models saved to {l1_dir}/\")\n",
    "    print(\"L1 Model Performance:\")\n",
    "    for name, metric in metrics_l1.items():\n",
    "        if isinstance(metric, dict) and 'auc' in metric:\n",
    "            print(f\"  - {name}: AUC = {metric['auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ebe5ed",
   "metadata": {},
   "source": [
    "## 12. Level 2 Stacking (Meta Models)\n",
    "\n",
    "### Intelligence Layer - Meta-Learning from Base Predictions:\n",
    "Level 2 models learn how to optimally combine the Level 1 predictions, acting as intelligent arbitrators that understand when each base model performs best.\n",
    "\n",
    "**Meta-Learning Architecture:**\n",
    "\n",
    "### ExtraTrees (Extremely Randomized Trees):\n",
    "- **Meta-Learning Strength**: Captures non-linear combinations of base predictions\n",
    "- **Ensemble Intelligence**: Learns complex interaction patterns between L1 models\n",
    "- **Overfitting Resistance**: High randomness reduces overfitting to L1 patterns\n",
    "- **Feature Handling**: Can incorporate both L1 predictions and original features\n",
    "\n",
    "**Why ExtraTrees for Meta-Learning:**\n",
    "- **Stability**: Less sensitive to small changes in base predictions\n",
    "- **Interpretability**: Can analyze which base models contribute most\n",
    "- **Performance**: Often excels at combining diverse predictions\n",
    "\n",
    "### Logistic Regression:\n",
    "- **Meta-Learning Strength**: Linear combination of base predictions with clear weights\n",
    "- **Interpretability**: Coefficients show relative importance of each base model\n",
    "- **Calibration**: Excellent probability calibration for credit risk scores\n",
    "- **Simplicity**: Stable, interpretable baseline meta-learner\n",
    "\n",
    "**Why Logistic Regression for Meta-Learning:**\n",
    "- **Probability Focus**: Natural for credit risk probability estimation\n",
    "- **Regulatory Friendly**: Highly interpretable for compliance requirements\n",
    "- **Calibration**: Well-calibrated probabilities crucial for credit decisions\n",
    "\n",
    "### Meta-Learning Strategy:\n",
    "**Input Features for L2 Models:**\n",
    "1. **L1 Predictions**: Out-of-fold predictions from XGBoost, LightGBM, CatBoost\n",
    "2. **Original Features**: Selected raw features for additional context\n",
    "3. **Prediction Confidence**: Variance measures from L1 models (optional)\n",
    "\n",
    "**Training Process:**\n",
    "- **Clean Training Data**: Use OOF predictions to avoid overfitting\n",
    "- **Feature Engineering**: Create interaction terms between L1 predictions\n",
    "- **Cross-Validation**: Generate L2 OOF predictions for L3 training\n",
    "\n",
    "### Expected Meta-Learning Benefits:\n",
    "- **Model Selection**: Learn when each L1 model is most reliable\n",
    "- **Prediction Refinement**: Correct systematic errors from L1 models\n",
    "- **Uncertainty Quantification**: Better calibrated probability estimates\n",
    "- **Performance Gain**: Typically 1-3% AUC improvement over best single model\n",
    "\n",
    "### Ensemble Intelligence:\n",
    "The L2 layer creates an intelligent voting system that:\n",
    "- **Adapts to Data Regions**: Different weights for different input patterns\n",
    "- **Handles Model Bias**: Corrects for individual model weaknesses  \n",
    "- **Improves Calibration**: Better probability estimates for business use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9921eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "LEVEL 2 STACKING - META MODELS\n",
      "==================================================\n",
      "\n",
      "=== Generating L2 OOF predictions for stacking ===\n",
      "Running extratree ...\n",
      "Running logistic ...\n",
      "=== L2 OOF predictions generated ===\n",
      "\n",
      "OK: L2 model 'extratree' OOF predictions found, length = 307511\n",
      "OK: L2 model 'logistic' OOF predictions found, length = 307511\n",
      "\n",
      "L2 models saved to temp_results/models/l2_stacking/\n",
      "L2 Model Performance:\n",
      "L2 Stacking - done in 13s\n"
     ]
    }
   ],
   "source": [
    "with timer(\"L2 Stacking\"):\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"LEVEL 2 STACKING - META MODELS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    models_l2, oof_preds_l2, test_preds_l2, metrics_l2 = run_l2_stacking(\n",
    "        y_train, X_train_selected, X_test_selected\n",
    "    )\n",
    "    \n",
    "    # Save L2 models and predictions\n",
    "    l2_dir = MODELS_L2_DIR\n",
    "    os.makedirs(l2_dir, exist_ok=True)\n",
    "    expected_l2_models = ['extratree', 'logistic']\n",
    "    \n",
    "    for name in expected_l2_models:\n",
    "        # Save model\n",
    "        if name in models_l2 and models_l2[name] is not None:\n",
    "            with open(f'{l2_dir}/l2_{name}_model.pkl', 'wb') as f:\n",
    "                pickle.dump(models_l2[name], f)\n",
    "        \n",
    "        # Save OOF predictions\n",
    "        if name in oof_preds_l2:\n",
    "            pd.DataFrame({'oof_preds': oof_preds_l2[name]}).to_csv(\n",
    "                f'{l2_dir}/l2_{name}_oof_predictions.csv', index=False\n",
    "            )\n",
    "        \n",
    "        # Save test predictions\n",
    "        if name in test_preds_l2:\n",
    "            pd.DataFrame({'test_preds': test_preds_l2[name]}).to_csv(\n",
    "                f'{l2_dir}/l2_{name}_test_predictions.csv', index=False\n",
    "            )\n",
    "    \n",
    "    # Save metrics\n",
    "    with open(f'{l2_dir}/l2_model_summary.json', 'w') as f:\n",
    "        json.dump(metrics_l2, f, indent=2)\n",
    "    \n",
    "    # Check predictions\n",
    "    for name in expected_l2_models:\n",
    "        if name not in oof_preds_l2:\n",
    "            print(f\"WARNING: L2 model '{name}' did NOT produce OOF predictions!\")\n",
    "        else:\n",
    "            print(f\"OK: L2 model '{name}' OOF predictions found, length = {len(oof_preds_l2[name])}\")\n",
    "    \n",
    "    # Blend test predictions\n",
    "    blended_test_pred_l2 = np.mean([v for v in test_preds_l2.values()], axis=0)\n",
    "    pd.DataFrame({'blended_test_pred': blended_test_pred_l2}).to_csv(\n",
    "        f'{l2_dir}/l2_blended_test_predictions.csv', index=False\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nL2 models saved to {l2_dir}/\")\n",
    "    print(\"L2 Model Performance:\")\n",
    "    for name, metric in metrics_l2.items():\n",
    "        if isinstance(metric, dict) and 'auc' in metric:\n",
    "            print(f\"  - {name}: AUC = {metric['auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c292f59",
   "metadata": {},
   "source": [
    "## 13. Level 3 Stacking (Final Ensemble)\n",
    "\n",
    "### Supreme Decision Layer - Ultimate Model Synthesis:\n",
    "Level 3 represents the pinnacle of our stacking approach, combining the intelligent meta-predictions from L2 with carefully selected raw features to create the final, most sophisticated model.\n",
    "\n",
    "**Final Ensemble Architecture:**\n",
    "\n",
    "### ExtraTrees as Final Arbiter:\n",
    "**Why ExtraTrees for L3:**\n",
    "- **Complex Pattern Recognition**: Captures intricate relationships between L2 predictions\n",
    "- **Feature Integration**: Seamlessly combines meta-predictions with raw features\n",
    "- **Overfitting Resistance**: Random feature selection reduces overfitting risk\n",
    "- **Non-Linear Mastery**: Learns complex decision boundaries for final classification\n",
    "\n",
    "### Multi-Source Input Strategy:\n",
    "**L3 Model Input Features:**\n",
    "\n",
    "1. **L2 Meta-Predictions:**\n",
    "   - ExtraTrees probability scores (L2 model 1)\n",
    "   - Logistic Regression probability scores (L2 model 2)\n",
    "   - These capture the refined intelligence from base model combinations\n",
    "\n",
    "2. **Strategic Raw Features:**\n",
    "   - `AMT_INCOME_TOTAL`: Fundamental creditworthiness indicator\n",
    "   - Additional key features that provide direct business insight\n",
    "   - Features that complement meta-predictions with raw signal\n",
    "\n",
    "3. **Feature Interaction Potential:**\n",
    "   - L3 can learn interactions between meta-predictions and raw features\n",
    "   - Example: Income level might moderate the reliability of certain model predictions\n",
    "\n",
    "### Advanced Learning Capabilities:\n",
    "**L3 Intelligence Beyond L2:**\n",
    "- **Meta-Meta Learning**: Learns when L2 models are most reliable\n",
    "- **Context Awareness**: Adjusts predictions based on raw feature context\n",
    "- **Boundary Refinement**: Fine-tunes decision boundaries using all available information\n",
    "- **Confidence Calibration**: Final probability calibration for business use\n",
    "\n",
    "### Expected Performance Benefits:\n",
    "- **Incremental Improvement**: Additional 0.5-1% AUC gain over L2\n",
    "- **Enhanced Stability**: More robust predictions across different data segments\n",
    "- **Business Alignment**: Incorporates both model intelligence and domain features\n",
    "- **Regulatory Compliance**: Maintains interpretability through feature transparency\n",
    "\n",
    "### Final Model Characteristics:\n",
    "- **Ensemble Depth**: Three levels of model sophistication\n",
    "- **Feature Diversity**: Meta-predictions + raw business features\n",
    "- **Risk Calibration**: Well-calibrated probabilities for credit decisions\n",
    "- **Production Ready**: Single model file for deployment\n",
    "\n",
    "### Business Value:\n",
    "The L3 final ensemble represents the culmination of advanced machine learning techniques while maintaining business interpretability and regulatory compliance requirements for credit risk assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d9da78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "LEVEL 3 STACKING - FINAL ENSEMBLE\n",
      "==================================================\n",
      "Final L3 stacking completed.\n",
      "OK: L3 model OOF predictions found, length = 307511\n",
      "\n",
      "L3 model saved to temp_results/models/l3_stacking/\n",
      "Final submission saved to temp_results/models/l3_stacking/submission_l3.csv\n",
      "L3 Final Model AUC: 0.7749\n",
      "L3 Stacking - done in 12s\n"
     ]
    }
   ],
   "source": [
    "with timer(\"L3 Stacking\"):\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"LEVEL 3 STACKING - FINAL ENSEMBLE\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    l3_dir = MODELS_L3_DIR\n",
    "    os.makedirs(l3_dir, exist_ok=True)\n",
    "    l2_model_names = ['extratree', 'logistic']\n",
    "    raw_feature_names = []\n",
    "    \n",
    "    if 'AMT_INCOME_TOTAL' in X_train_selected.columns:\n",
    "        raw_feature_names.append('AMT_INCOME_TOTAL')\n",
    "    \n",
    "    # Run L3 stacking\n",
    "    model_l3, oof_preds_l3, test_preds_l3, metrics_l3 = run_l3_stacking(\n",
    "        y_train,\n",
    "        test_df,\n",
    "        l2_model_names,\n",
    "        X_train_selected,\n",
    "        X_test_selected,\n",
    "        raw_feature_names\n",
    "    )\n",
    "    \n",
    "    # Save L3 model and predictions\n",
    "    with open(f'{l3_dir}/l3_extratree_model.pkl', 'wb') as f:\n",
    "        pickle.dump(model_l3, f)\n",
    "    \n",
    "    pd.DataFrame({'oof_preds': oof_preds_l3}).to_csv(\n",
    "        f'{l3_dir}/l3_extratree_oof_predictions.csv', index=False\n",
    "    )\n",
    "    pd.DataFrame({'test_preds': test_preds_l3}).to_csv(\n",
    "        f'{l3_dir}/l3_extratree_test_predictions.csv', index=False\n",
    "    )\n",
    "    \n",
    "    with open(f'{l3_dir}/l3_model_summary.json', 'w') as f:\n",
    "        json.dump(metrics_l3, f, indent=2)\n",
    "    \n",
    "    # Check L3 predictions\n",
    "    if oof_preds_l3 is None or len(oof_preds_l3) == 0:\n",
    "        print(\"WARNING: L3 model did NOT produce OOF predictions!\")\n",
    "    else:\n",
    "        print(f\"OK: L3 model OOF predictions found, length = {len(oof_preds_l3)}\")\n",
    "    \n",
    "    # Save final submission\n",
    "    submission_df = pd.DataFrame({\n",
    "        'SK_ID_CURR': test_df['SK_ID_CURR'].reset_index(drop=True), \n",
    "        'TARGET': test_preds_l3\n",
    "    })\n",
    "    submission_df.to_csv(f'{l3_dir}/submission_l3.csv', index=False)\n",
    "    \n",
    "    print(f\"\\nL3 model saved to {l3_dir}/\")\n",
    "    print(f\"Final submission saved to {l3_dir}/submission_l3.csv\")\n",
    "    \n",
    "    if isinstance(metrics_l3, dict) and 'auc' in metrics_l3:\n",
    "        print(f\"L3 Final Model AUC: {metrics_l3['auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164f5e44",
   "metadata": {},
   "source": [
    "## 14. Final Performance Summary\n",
    "\n",
    "### Comprehensive Model Evaluation & Business Impact:\n",
    "This section provides a complete performance overview across all model levels and delivers the final business outcomes.\n",
    "\n",
    "**Performance Analysis Hierarchy:**\n",
    "\n",
    "### Model Performance Comparison:\n",
    "**Individual Model Assessment:**\n",
    "- **L1 Base Models**: XGBoost, LightGBM, CatBoost individual AUC scores\n",
    "- **L2 Meta Models**: ExtraTrees, Logistic Regression meta-learning performance  \n",
    "- **L3 Final Ensemble**: Ultimate model performance with all optimizations\n",
    "\n",
    "**Key Performance Metrics:**\n",
    "- **AUC-ROC**: Primary metric for ranking and discrimination ability\n",
    "- **Precision/Recall**: Business-relevant performance for different thresholds\n",
    "- **Calibration Quality**: How well predicted probabilities match actual default rates\n",
    "- **Stability**: Performance consistency across different data segments\n",
    "\n",
    "### Complete Artifact Inventory:\n",
    "**Data Assets:**\n",
    "- **Interim Data**: Encoded datasets for reproducibility\n",
    "- **Processed Data**: Final model-ready datasets\n",
    "- **Feature Engineering**: Comprehensive feature transformation record\n",
    "\n",
    "**Model Assets:**\n",
    "- **L1 Models**: Three base models with individual predictions\n",
    "- **L2 Models**: Two meta-models with ensemble predictions  \n",
    "- **L3 Model**: Final ensemble model for production deployment\n",
    "\n",
    "**Prediction Assets:**\n",
    "- **Training Predictions**: Out-of-fold predictions for model validation\n",
    "- **Test Predictions**: Final submission-ready predictions\n",
    "- **Model Summaries**: Performance metrics and hyperparameters\n",
    "\n",
    "### Business Delivery:\n",
    "**Primary Deliverable**: `submission_l3.csv`\n",
    "- **Format**: SK_ID_CURR (Customer ID) + TARGET (Default Probability)\n",
    "- **Quality**: Sophisticated ensemble predictions with advanced feature engineering\n",
    "- **Calibration**: Well-calibrated probabilities for business decision-making\n",
    "- **Coverage**: Complete test set predictions ready for submission\n",
    "\n",
    "### Production Readiness:\n",
    "**Model Deployment Assets:**\n",
    "- **Trained Models**: Complete pipeline with all preprocessing and models\n",
    "- **Feature Pipeline**: Reproducible feature engineering and selection\n",
    "- **Prediction Pipeline**: End-to-end inference capability\n",
    "- **Performance Benchmarks**: Established baselines for monitoring\n",
    "\n",
    "### Success Metrics:\n",
    "- **Technical Success**: Pipeline completion without errors\n",
    "- **Performance Success**: Competitive AUC scores across all model levels\n",
    "- **Business Success**: Interpretable, well-calibrated risk predictions\n",
    "- **Operational Success**: Production-ready model artifacts and documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7049c67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PIPELINE EXECUTION COMPLETED\n",
      "============================================================\n",
      "\n",
      "FINAL PERFORMANCE SUMMARY:\n",
      "L1 XGB OOF AUC: 0.77469\n",
      "L1 LGBM OOF AUC: 0.77399\n",
      "L1 CATBOOST OOF AUC: 0.77162\n",
      "L2 extratree OOF AUC: 0.77486\n",
      "L2 logistic OOF AUC: 0.77524\n",
      "L3 extratree OOF AUC: 0.77491\n",
      "\n",
      "OUTPUT FILES GENERATED:\n",
      "├── temp_results/data/interim/\n",
      "│   ├── train_encoded.csv\n",
      "│   └── test_encoded.csv\n",
      "├── temp_results/data/processed/\n",
      "│   ├── train_processed.csv\n",
      "│   └── test_processed.csv\n",
      "├── temp_results/models/l1_stacking/\n",
      "│   ├── Model files and predictions for XGB, LGBM, CatBoost\n",
      "├── temp_results/models/l2_stacking/\n",
      "│   ├── Model files and predictions for ExtraTrees, Logistic\n",
      "└── temp_results/models/l3_stacking/\n",
      "    ├── l3_extratree_model.pkl\n",
      "    └── submission_l3.csv (FINAL SUBMISSION)\n",
      "\n",
      "SUBMISSION FILE: temp_results/models/l3_stacking/submission_l3.csv\n",
      "Number of test predictions: 48,744\n",
      "Prediction range: [0.036065, 0.415449]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PIPELINE EXECUTION COMPLETED\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nFINAL PERFORMANCE SUMMARY:\")\n",
    "print_all_auc(y_train)\n",
    "\n",
    "print(f\"\\nOUTPUT FILES GENERATED:\")\n",
    "print(f\"├── {DATA_INTERIM_DIR}/\")\n",
    "print(f\"│   ├── train_encoded.csv\")\n",
    "print(f\"│   └── test_encoded.csv\")\n",
    "print(f\"├── {DATA_PROCESSED_DIR}/\")\n",
    "print(f\"│   ├── train_processed.csv\")\n",
    "print(f\"│   └── test_processed.csv\")\n",
    "print(f\"├── {MODELS_L1_DIR}/\")\n",
    "print(f\"│   ├── Model files and predictions for XGB, LGBM, CatBoost\")\n",
    "print(f\"├── {MODELS_L2_DIR}/\")\n",
    "print(f\"│   ├── Model files and predictions for ExtraTrees, Logistic\")\n",
    "print(f\"└── {MODELS_L3_DIR}/\")\n",
    "print(f\"    ├── l3_extratree_model.pkl\")\n",
    "print(f\"    └── submission_l3.csv (FINAL SUBMISSION)\")\n",
    "\n",
    "print(f\"\\nSUBMISSION FILE: {MODELS_L3_DIR}/submission_l3.csv\")\n",
    "print(f\"Number of test predictions: {len(test_preds_l3):,}\")\n",
    "print(f\"Prediction range: [{np.min(test_preds_l3):.6f}, {np.max(test_preds_l3):.6f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d4862b",
   "metadata": {},
   "source": [
    "### Pipeline Execution Complete!\n",
    "\n",
    "### Mission Accomplished - Advanced Credit Risk Modeling Pipeline\n",
    "The sophisticated three-level stacking pipeline has been successfully executed, delivering state-of-the-art credit risk predictions through advanced machine learning techniques.\n",
    "\n",
    "---\n",
    "\n",
    "## **Key Achievements:**\n",
    "\n",
    "### **Technical Excellence:**\n",
    "- **Complete Data Pipeline**: From raw data to production-ready predictions\n",
    "- **Advanced Feature Engineering**: Sophisticated feature creation and selection  \n",
    "- **Three-Level Stacking**: Hierarchical ensemble for maximum performance\n",
    "- **Model Diversity**: Multiple algorithms capturing different data patterns\n",
    "- **Quality Assurance**: Comprehensive validation and error checking\n",
    "\n",
    "### **Business Value Delivered:**\n",
    "- **High-Quality Predictions**: Well-calibrated default probability estimates\n",
    "- **Model Interpretability**: Clear feature importance and model explanations\n",
    "- **Production Ready**: Complete pipeline ready for deployment\n",
    "- **Performance Optimized**: Advanced ensemble techniques for superior accuracy\n",
    "- **Regulatory Compliant**: Transparent and auditable modeling approach\n",
    "\n",
    "---\n",
    "\n",
    "## **Complete Output Inventory:**\n",
    "\n",
    "### **Data Assets:**\n",
    "- `data/interim/`: Encoded and preprocessed datasets for reproducibility\n",
    "- `data/processed/`: Final model-ready datasets with optimal feature selection\n",
    "\n",
    "### **Model Hierarchy:**\n",
    "- `models/l1_stacking/`: **Base Models** (XGBoost, LightGBM, CatBoost)\n",
    "- `models/l2_stacking/`: **Meta Models** (ExtraTrees, Logistic Regression)  \n",
    "- `models/l3_stacking/`: **Final Ensemble** (Ultimate stacking model)\n",
    "\n",
    "### **Business Deliverables:**\n",
    "- **`submission_l3.csv`**: **PRIMARY DELIVERABLE** - Final credit risk predictions\n",
    "- **Performance Reports**: Comprehensive model evaluation metrics\n",
    "- **Model Artifacts**: Trained models ready for production deployment\n",
    "\n",
    "---\n",
    "\n",
    "## **Next Steps & Recommendations:**\n",
    "\n",
    "### **Immediate Actions:**\n",
    "1. **Review Performance Metrics**: Analyze AUC scores and model comparisons\n",
    "2. **Validate Predictions**: Spot-check prediction quality and calibration\n",
    "3. **Submit Results**: Deploy `submission_l3.csv` for final evaluation\n",
    "4. **Document Insights**: Capture key learnings and feature importance\n",
    "\n",
    "### **Advanced Extensions:**\n",
    "1. **Hyperparameter Optimization**: Fine-tune individual model parameters\n",
    "2. **Feature Engineering++**: Explore additional feature interactions\n",
    "3. **Model Interpretability**: Deep-dive into SHAP explanations\n",
    "4. **Production Pipeline**: Set up automated retraining and monitoring\n",
    "\n",
    "### **Business Applications:**\n",
    "1. **Risk Assessment**: Use predictions for loan approval decisions\n",
    "2. **Portfolio Analysis**: Analyze risk distribution across customer segments  \n",
    "3. **Pricing Strategy**: Incorporate risk scores into loan pricing models\n",
    "4. **Performance Monitoring**: Track model performance over time\n",
    "\n",
    "---\n",
    "\n",
    "## **Excellence Delivered:**\n",
    "This pipeline represents a comprehensive, production-grade credit risk modeling solution that combines:\n",
    "- **Advanced Machine Learning**: State-of-the-art ensemble techniques\n",
    "- **Business Intelligence**: Domain-aware feature engineering and selection\n",
    "- **Operational Excellence**: Complete, reproducible, and scalable pipeline\n",
    "- **Regulatory Compliance**: Transparent and interpretable modeling approach\n",
    "\n",
    "**Final Submission Ready**: The final submission file is saved to the temporary directory and contains sophisticated, well-calibrated credit risk predictions ready for business deployment!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
